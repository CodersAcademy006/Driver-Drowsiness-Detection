<!DOCTYPE html>
<!-- saved from url=(0053)https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link rel="stylesheet" type="text/css" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/jig.min.css">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile properties -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
    <!-- Stylesheets -->
    <link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.cc84172e9e16.css" type="text/css">
  
  <link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.b634933a977d.css" type="text/css"><link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.913c7dcab8ff.css" type="text/css"><link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.3766d7ad0d2d.css" type="text/css"><link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.e3c3c2c84eb3.css" type="text/css">

  
    <link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/font-awesome.min.css">
  
<link type="text/css" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/base.a2ef7ca69e4b20dff539.css" rel="stylesheet">


    <link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/stixfonts.css" type="text/css"><link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/pmcrefs2.min.css" type="text/css"><link rel="stylesheet" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/ncbi_web.min.css" type="text/css"><style type="text/css">.pmc-wm {background:transparent repeat-y top left;background-image:url(/corehtml/pmc/pmcgifs/wm-journal.gif);background-size: auto, contain}</style><style type="text/css">.print-view{display:block}</style>

    <link type="text/css" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/article.3c5d12ff2e4beea20136.css" rel="stylesheet">
    <link type="text/css" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/cite-box.css" rel="stylesheet">


    <title>A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC</title>

  
  <!-- Favicons -->
  <link rel="shortcut icon" type="image/ico" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico">
  <link rel="icon" type="image/png" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.png">

  <!-- 192x192, as recommended for Android
  http://updates.html5rocks.com/2014/11/Support-for-theme-color-in-Chrome-39-for-Android
  -->
  <link rel="icon" type="image/png" sizes="192x192" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-192.png">

  <!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
  <link rel="apple-touch-icon-precomposed" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-57.png">
  <!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-72.png">
  <!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-114.png">
  <!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-144.png">



    
        <!-- Logging params: Pinger defaults -->

<meta name="ncbi_app" content="pmc-frontend">

<meta name="ncbi_db" content="pmc">

<meta name="ncbi_phid" content="939BB44382FE242500005B79EA47AD9A.1.m_2">


        <!-- Logging params: Pinger custom -->

<meta name="ncbi_pdid" content="article">

<meta name="ncbi_op" content="retrieved">

<meta name="ncbi_app_version" content="0.0">

<meta name="ncbi_domain" content="sensors">

<meta name="ncbi_type" content="fulltext">

<meta name="ncbi_pcid" content="/articles/PMC8914892/">


    


    <script type="text/javascript" async="" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/js"></script><script async="" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/gtm.js.download" id="pingerInjectedGTM"></script><script>
        
            var ncbiBaseUrl = "https://www.ncbi.nlm.nih.gov";
        
        var useOfficialGovtHeader = true;
    </script>


    <meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE"><link rel="canonical" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/"><link rel="schema.DC" href="http://purl.org/DC/elements/1.0/"><meta name="citation_journal_title" content="Sensors (Basel, Switzerland)"><meta name="citation_title" content="A Review of Recent Developments in Driver Drowsiness Detection Systems"><meta name="citation_author" content="Yaman Albadawi"><meta name="citation_author_institution" content="Department of Computer Science and Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates; ea.ca.karua@iwadabla.namay (Y.A.); ea.ca.karua@dawa.demmahom (M.A.)"><meta name="citation_author" content="Maen Takruri"><meta name="citation_author_institution" content="Department of Electrical, Electronics and Communications Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates"><meta name="citation_author" content="Mohammed Awad"><meta name="citation_author_institution" content="Department of Computer Science and Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates; ea.ca.karua@iwadabla.namay (Y.A.); ea.ca.karua@dawa.demmahom (M.A.)"><meta name="citation_publication_date" content="2022/03"><meta name="citation_issue" content="5"><meta name="citation_volume" content="22"><meta name="citation_doi" content="10.3390/s22052069"><meta name="citation_abstract_html_url" content="/pmc/articles/PMC8914892/?report=abstract"><meta name="citation_fulltext_html_url" content="/pmc/articles/PMC8914892/"><meta name="citation_pmid" content="35271215"><meta name="DC.Title" content="A Review of Recent Developments in Driver Drowsiness Detection Systems"><meta name="DC.Type" content="Text"><meta name="DC.Publisher" content="Multidisciplinary Digital Publishing Institute  (MDPI)"><meta name="DC.Contributor" content="Yaman Albadawi"><meta name="DC.Contributor" content="Maen Takruri"><meta name="DC.Contributor" content="Mohammed Awad"><meta name="DC.Date" content="2022 Mar"><meta name="DC.Identifier" content="10.3390/s22052069"><meta name="DC.Language" content="en"><meta property="og:title" content="A Review of Recent Developments in Driver Drowsiness Detection Systems"><meta property="og:type" content="article"><meta property="og:description" content="Continuous advancements in computing technology and artificial intelligence in the past decade have led to improvements in driver monitoring systems. Numerous experimental studies have collected real driver drowsiness data and applied various artificial ..."><meta property="og:url" content="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/"><meta property="og:site_name" content="PubMed Central (PMC)"><meta property="og:image" content="https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@ncbi">


<meta name="ncbi_nwds_ver" content="1.1.9-2"><meta name="ncbi_nwds" content="yes"><script async="1" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/analytics.js.download"></script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/js(1)"></script><style type="text/css">.MathJax_Preview {color: #888; display: contents}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><script charset="utf-8" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/12.f83656fbc6c9f02061b2.chunk.js.download"></script><script charset="utf-8" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/7.50a5e5384da9a5f8074a.chunk.js.download"></script><script charset="utf-8" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/1.54b5112e10a3bab30834.chunk.js.download"></script><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none; box-sizing: content-box}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_test.mjx-test-display {display: table!important}
.MathJax_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_test.mjx-test-default {display: block!important; clear: both}
.MathJax_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.MathJax_em_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60em}
.mjx-test-inline .MathJax_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.9') format('opentype')}
</style></head>
<body id="ui-ncbiexternallink-3" data-new-gr-c-s-check-loaded="14.1186.0" data-gr-ext-installed="" data-new-gr-c-s-loaded="14.1186.0"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

   
    
        <button class="back-to-top back-to-top--bottom visible" data-ga-category="pagination" data-ga-action="back_to_top">
          Back to Top
        </button>
    

    <a class="usa-skipnav" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#main-content">Skip to main content</a>
    <!-- ========== BEGIN HEADER ========== -->
<section class="usa-banner" style="">
  <div class="usa-accordion">
    <header class="usa-banner-header">
      <div class="usa-grid usa-banner-inner">
        <img src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/favicon-57.png" alt="U.S. flag">
        <p>An official website of the United States government</p>
        <button class="usa-accordion-button usa-banner-button" aria-expanded="false" aria-controls="gov-banner-top">
          <span class="usa-banner-button-text">Here's how you know</span>
        </button>
      </div>
    </header>
    <div class="usa-banner-content usa-grid usa-accordion-content" id="gov-banner-top" aria-hidden="true">
      <div class="usa-banner-guidance-gov usa-width-one-half">
        <img class="usa-banner-icon usa-media_block-img" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/icon-dot-gov.svg" alt="Dot gov">
        <div class="usa-media_block-body">
          <p>
            <strong>The .gov means it’s official.</strong>
            <br>
            Federal government websites often end in .gov or .mil. Before
            sharing sensitive information, make sure you’re on a federal
            government site.
          </p>
        </div>
      </div>
      <div class="usa-banner-guidance-ssl usa-width-one-half">
        <img class="usa-banner-icon usa-media_block-img" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/icon-https.svg" alt="Https">
        <div class="usa-media_block-body">
          <p>
            <strong>The site is secure.</strong>
            <br>
            The <strong>https://</strong> ensures that you are connecting to the
            official website and that any information you provide is encrypted
            and transmitted securely.
          </p>
        </div>
      </div>
    </div>
  </div>
</section><section data-section="Alerts">
	<div class="ncbi-alerts-placeholder"></div>
</section>
<div class="usa-overlay"></div>
<header class="ncbi-header" role="banner" data-section="Header">

	<div class="usa-grid">
		<div class="usa-width-one-whole">

            <div class="ncbi-header__logo">
                <a href="https://www.ncbi.nlm.nih.gov/" class="logo" aria-label="NCBI Logo" data-ga-action="click_image" data-ga-label="NIH NLM Logo">
                  <img src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/AgencyLogo.svg" alt="NIH NLM Logo">
                </a>
            </div>

			<div class="ncbi-header__account">
				<a id="account_login" href="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F" class="usa-button header-button" style="" data-ga-action="open_menu" data-ga-label="account_menu">Log in</a>
				<button id="account_info" class="header-button" style="display:none" aria-controls="account_popup" aria-haspopup="true" aria-expanded="false">
					<span class="fa fa-user" aria-hidden="true"></span>
					<span class="username desktop-only" aria-hidden="true" id="uname_short"></span>
					<span class="sr-only">Show account info</span>
				</button>
			</div>

			<div class="ncbi-popup-anchor">
				<div class="ncbi-popup account-popup" id="account_popup" aria-hidden="true" tabindex="-1" aria-modal="true" style="display: none;">
					<div class="ncbi-popup-head">
						<button class="ncbi-close-button" data-ga-action="close_menu" data-ga-label="account_menu"><span class="fa fa-times"></span><span class="usa-sr-only">Close</span></button>
						<h4>Account</h4>
					</div>
					<div class="account-user-info">
						Logged in as:<br>
						<b><span class="username" id="uname_long">username</span></b>
					</div>
					<div class="account-links">
						<ul class="usa-unstyled-list">
							<li><a id="account_myncbi" href="https://www.ncbi.nlm.nih.gov/myncbi/" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_myncbi">Dashboard</a></li>
							<li><a id="account_pubs" href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_pubs">Publications</a></li>
							<li><a id="account_settings" href="https://www.ncbi.nlm.nih.gov/account/settings/" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_settings">Account settings</a></li>
							<li><a id="account_logout" href="https://www.ncbi.nlm.nih.gov/account/signout/?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_logout">Log out</a></li>
						</ul>
					</div>
				</div>
			</div>

		</div>
	</div>
</header>
<div role="navigation" aria-label="access keys">
<a id="nws_header_accesskey_0" href="https://www.ncbi.nlm.nih.gov/guide/browsers/#ncbi_accesskeys" class="usa-sr-only" accesskey="0" tabindex="-1">Access keys</a>
<a id="nws_header_accesskey_1" href="https://www.ncbi.nlm.nih.gov/" class="usa-sr-only" accesskey="1" tabindex="-1">NCBI Homepage</a>
<a id="nws_header_accesskey_2" href="https://www.ncbi.nlm.nih.gov/myncbi/" class="set-base-url usa-sr-only" accesskey="2" tabindex="-1">MyNCBI Homepage</a>
<a id="nws_header_accesskey_3" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#maincontent" class="usa-sr-only" accesskey="3" tabindex="-1">Main Content</a>
<a id="nws_header_accesskey_4" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" class="usa-sr-only" accesskey="4" tabindex="-1">Main Navigation</a>
</div>

<!-- ========== END HEADER ========== -->

    
    


    
        

<section class="pmc-alerts">
    
    <div role="alert" class="pmc-alert pmc-alert--info" aria-label="Alert" aria-hidden="false" data-key="pmc-alert-welcome">
        <div class="pmc-alert__body pmc-alert--ncbi-icon">
            <div class="pmc-alert__content">
                <p>
                    <strong>
                        Preview improvements coming to the PMC website in October 2024.
                        <a href="https://ncbiinsights.ncbi.nlm.nih.gov/2024/03/14/preview-pmc-improvements/" data-ga-category="cloud_beta_banner" data-ga-label="learn_more" data-ga-action="on_pmc2020">Learn More</a> or
                        <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8914892/" data-ga-category="cloud_beta_banner" data-ga-action="on_pmc2020" data-ga-label="go_to_cloud">Try it out now</a>.
                    </strong>
                </p>
            </div>
        </div>
    </div>
    
</section>
    

    
    
        
        <header class="pmc-header usa-header-extended" role="banner">
    <div class="pmc-header__bar">
        <div class="pmc-header__control usa-accordion">
            
                <button class="usa-menu-btn pmc-header--button pmc-header--left">
                    <i class="fa fa-ellipsis-v" aria-hidden="true"></i>
                </button>
            

            <div class="usa-logo pmc-header__logo pmc-header--stretch
                
               " id="extended-mega-logo">
                <div class="usa-logo-text">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/" title="Home" aria-label="Home"></a>
                </div>
            </div>
            <button class="usa-accordion-button pmc-header--right pmc-header--button pmc-header__search--control pmc-header--right" aria-expanded="false" aria-controls="a1">
                <i class="fa fa-search" aria-hidden="true"></i>
                <i class="fa fa-times" aria-hidden="true"></i>
            </button>
        </div>
        <div class="pmc-header__search usa-accordion-content" id="a1" aria-hidden="true">
            <div role="search" class="pmc-header--stretch">
    <form class="usa-search " autocomplete="off">
        <div>
              <label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
              <span class="clearable">
                <span class="twitter-typeahead ncbi-autocomplete"><input required="required" autocomplete-url="/pmc/autocomplete/pmc/" placeholder="Search PMC Full-Text Archive" id="pmc-search" type="search" name="term" class="tt-input" spellcheck="false" dir="auto" aria-owns="pmc-search_listbox" role="combobox" aria-autocomplete="list" aria-expanded="false" style="position: relative; vertical-align: top;"><span role="status" aria-live="polite" style="position: absolute; padding: 0px; border: 0px; height: 1px; width: 1px; margin-bottom: -1px; margin-right: -1px; overflow: hidden; clip: rect(0px, 0px, 0px, 0px); white-space: nowrap;"></span><pre aria-hidden="true" style="position: absolute; visibility: hidden; white-space: pre; font-family: Roboto, &quot;Helvetica Neue&quot;, Arial, Tahoma; font-size: 16px; font-style: normal; font-variant: normal; font-weight: 400; word-spacing: 0px; letter-spacing: 0px; text-indent: 0px; text-rendering: auto; text-transform: none;"></pre><div role="listbox" class="tt-menu" id="pmc-search_listbox" style="position: absolute; top: 100%; left: 0px; z-index: 100; display: none;"><div role="presentation" class="tt-dataset tt-dataset-0"></div></div></span>
                  <i class="clear-btn"></i>
              </span>
              <button type="submit" formaction="/pmc/">
                <span class="usa-search-submit-text">Search in PMC</span>
              </button>
        </div>
    </form>
</div>


            <ul class="usa-unstyled-list usa-nav-secondary-links pmc-header--offset-two">
                    <li>
                        <a href="https://www.ncbi.nlm.nih.gov/pmc/advanced" data-ga-action="featured_link" data-ga-label="advanced_search">
                            Advanced Search
                        </a>
                    </li>
                    <li>
                        <a href="https://www.ncbi.nlm.nih.gov/pmc/about/userguide/" data-ga-action="featured_link" data-ga-label="user guide">
                            User Guide
                        </a>
                    </li>
            </ul>
        </div>
    </div>
     <nav role="navigation" class="usa-nav ">
        <button class="usa-nav-close">
            <i class="fa fa-times" aria-hidden="true"></i>
        </button>
        <div class="usa-breadcrumb usa-breadcrumb--wrap usa-breadcrumb--hack">
             
    <ul class="usa-breadcrumb__list">
            
                <li class="usa-breadcrumb__list-item">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/" class="navlink">Journal List</a>
                </li>
            
                <li class="usa-breadcrumb__list-item">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sensors%20(Basel)%22[journal]" class="navlink">Sensors (Basel)</a>
                </li>
            
                <li class="usa-breadcrumb__list-item" aria-current="page">
                    PMC8914892
                </li>
            
    </ul>
 

        </div>
        
        
            <div class="pmc-sidebar pmc-sidebar-hack">
                

<div class="scroller">

    
        <section>
                <h6>Other Formats</h6>
                <ul class="pmc-sidebar__formats">
                  <li class="pdf-link other_item"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/pdf/sensors-22-02069.pdf" class="int-view">PDF (1.5M)</a></li>
                </ul>
        </section>
    
    <section>
        <h6>Actions</h6>
        <ul class="pmc-sidebar__actions">
            <li>
                <button role="button" class="citation-button citation-dialog-trigger ctxp" aria-label="Open dialog with citation text in different styles" data-ga-category="save_share" data-ga-action="cite" data-ga-label="open" data-all-citations-url="/pmc/resources/citations/8914892/" data-citation-style="nlm" data-download-format-link="/pmc/resources/citations/8914892/export/">
                    <span class="button-label">Cite</span>
                </button>
            </li>
            <li>
                
                    

<link type="text/css" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/overlay-block.css">
<div class="collections-button-container" data-article-id="8914892" data-article-db="pmc">
  <button class="collections-button collections-dialog-trigger collections-button-empty" aria-label="Save article in MyNCBI collections." data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_button" data-collections-open-dialog-enabled="false" data-collections-open-dialog-url="https://www.ncbi.nlm.nih.gov/account?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F%23open-collections-dialog" data-in-collections="false">
      <span class="button-label">Collections</span>
  </button>
  <div class="overlay collections-dialog-overlay" role="dialog">
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true" role="document">
    <div class="title">Add to Collections</div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form" class="collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors" data-existing-collections-url="/pmc/list-existing-collections/" data-add-to-existing-collection-url="/pmc/add-to-existing-collection/" data-create-and-add-to-new-collection-url="/pmc/create-and-add-to-new-collection/" data-myncbi-max-collection-name-length="100" data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

  <input type="hidden" name="csrfmiddlewaretoken" value="HCWL2GAfmC2WnH2jRYA8utMhSQWf2vdItBFHdVmdco7ExVsLpNZjxQHq4h9TCIWX">

  

  <div class="choice-group" role="radiogroup">
    <ul class="radio-group-items">
      <li>
        <input type="radio" id="collections-action-dialog-new-header " class="collections-new" name="collections" value="new" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_new">
        <label for="collections-action-dialog-new-header ">Create a new collection</label>
      </li>
      <li>
        <input type="radio" id="collections-action-dialog-existing-header " class="collections-existing" name="collections" value="existing" checked="true" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_existing">
        <label for="collections-action-dialog-existing-header ">Add to an existing collection</label>
      </li>
    </ul>
  </div>

  <div class="controls-wrapper">
    <div class="action-panel-control-wrap new-collections-controls">
      <label for="collections-action-dialog-add-to-new" class="action-panel-label required-field-asterisk">
        Name your collection:
      </label>
      <input type="text" name="add-to-new-collection" id="collections-action-dialog-add-to-new" class="collections-action-add-to-new" pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/" maxlength="" data-ga-category="collections_button" data-ga-action="create_collection" data-ga-label="non_favorties_collection">
      <div class="collections-new-name-too-long usa-input-error-message selection-validation-message">
        Name must be less than  characters
      </div>
    </div>
    <div class="action-panel-control-wrap existing-collections-controls">
      <label for="collections-action-dialog-add-to-existing" class="action-panel-label">
        Choose a collection:
      </label>
      <select id="collections-action-dialog-add-to-existing" class="action-panel-selector collections-action-add-to-existing" data-ga-category="collections_button" data-ga-action="select_collection" data-ga-label="($(&#39;.collections-action-add-to-existing&#39;).val() === &#39;Favorites&#39;) ? &#39;Favorites&#39; : &#39;non_favorites_collection&#39;">
      </select>
      <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
        Unable to load your collection due to an error<br>
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#">Please try again</a>
      </div>
    </div>
  </div>

  <div class="action-panel-actions">
    <button class="action-panel-submit" type="submit" data-loading-label="Adding..." data-pinger-ignore="" data-ga-category="collections_button" data-ga-action="click" data-ga-label="add">
      Add
    </button>
    <button class="action-panel-cancel" aria-label="Close &#39;Add to Collections&#39; panel" ref="linksrc=close_collections_panel" aria-controls="collections-action-panel" aria-expanded="false" data-ga-category="collections_button" data-ga-action="click" data-ga-label="cancel">
      Cancel
    </button>
  </div>
</form>
    </div>
  </div>
</div>
</div>
                
            </li>

        </ul>
    </section>
    
        <section class="social-sharing">
            <h6>Share</h6>
            <ul class="pmc-sidebar__share">
                <li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F&amp;text=A%20Review%20of%20Recent%20Developments%20in%20Driver%20Drowsiness%20Detection%20Systems" alt="Share on Twitter" aria-expanded="false" aria-haspopup="true"><i class="fa fa-twitter fa-stack-1x">&nbsp;</i></a></li> 
<li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F" alt="Share on Facebook" aria-expanded="false" aria-haspopup="true"><i class="fa fa-facebook fa-stack-1x">&nbsp;</i></a></li>
                <li>
                    <div class="share-permalink dropdown-block">
                        <button class="trigger" alt="Show article permalink" aria-expanded="false" aria-haspopup="true">
                            <i class="fa-stack fa-lg">
                                <i class="fa fa-link fa-stack-1x">&nbsp;</i>
                            </i>
                        </button>
                        <div class="dropdown dropdown-container" aria-hidden="true">
                              <div class="title">
                                Permalink
                              </div>
                              <div class="content">
                                  <input type="text" class="permalink-text" value="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/" aria-label="Article permalink"><button class="permalink-copy-button usa-button-primary" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                                      <span class="button-title">Copy</span>
                                  </button>
                              </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    
    <section>
        <h6>RESOURCES</h6>
        <ul class="pmc-sidebar__resources">
        
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_similar_articles" data-ga-label="/pmc/articles/PMC8914892/" class="usa-accordion-button" aria-controls="similar-articles-accordion-header" aria-expanded="false" data-action-open="open_similar_articles" data-action-close="close_similar_articles">
                        Similar articles
                    </button>
                    <div data-source-url="/pmc/resources/similar-article-links/35271215/" class="usa-accordion-content pmc-sidebar__resources--citations" id="similar-articles-accordion-header" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_cited_by" data-ga-label="/pmc/articles/PMC8914892/" class="usa-accordion-button" aria-controls="cited-by-accordion-header" aria-expanded="false" data-action-open="open_cited_by" data-action-close="close_cited_by">
                        Cited by other articles
                    </button>
                    <div data-source-url="/pmc/resources/cited-by-links/35271215/" class="usa-accordion-content pmc-sidebar__resources--citations" id="cited-by-accordion-header" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_NCBI_links" data-ga-label="/pmc/articles/PMC8914892/" class="usa-accordion-button" aria-controls="links-accordion-header" aria-expanded="false" data-action-open="open_NCBI_links" data-action-close="close_NCBI_link">
                        Links to NCBI Databases
                    </button>
                    <div data-source-url="/pmc/resources/db-links/8914892/" class="usa-accordion-content" id="links-accordion-header" aria-hidden="true"></div>
                </div>
            </li>

            
        
        </ul>
    </section>

 </div>
            </div>
        

    </nav>

</header>

    
    

    <div class="usa-overlay"></div>
    
<main id="main-content" class="usa-grid usa-layout-docs pmc-main">
    <article class="usa-width-three-fourths usa-layout-docs-main_content pmc-article">
        <section class="usa-breadcrumb usa-breadcrumb--wrap">
         
    <ul class="usa-breadcrumb__list">
            
                <li class="usa-breadcrumb__list-item">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/" class="navlink">Journal List</a>
                </li>
            
                <li class="usa-breadcrumb__list-item">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sensors%20(Basel)%22[journal]" class="navlink">Sensors (Basel)</a>
                </li>
            
                <li class="usa-breadcrumb__list-item" aria-current="page">
                    PMC8914892
                </li>
            
    </ul>
 

        </section>
        
  <div class="pmc-article__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br>
    Learn more:
    <a data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="https://www.ncbi.nlm.nih.gov/pmc/about/disclaimer/">PMC Disclaimer</a>
    |
    <a data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="https://www.ncbi.nlm.nih.gov/pmc/about/copyright/">
        PMC Copyright Notice
    </a>
</div>

        <section class="pmc-page-banner" role="banner">
            
                
                    <div><img src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/logo-sensors.png" alt="Logo of sensors" usemap="#logo-imagemap"><map id="logo-imagemap" name="logo-imagemap"><area alt="Link to Publisher&#39;s site" title="Link to Publisher&#39;s site" shape="default" coords="0,0,499,74" href="http://www.mdpi.com/journal/sensors" target="_blank" rel="noopener noreferrer" ref="reftype=publisher&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A"></map></div> 
                
            
        </section>
        <section role="document">
            
                <div id="mc" class=" article lit-style content pmc-wm slang-all page-box"><!--main-content--><div class="jig-ncbiinpagenav" data-jigconfig="smoothScroll: false, allHeadingLevels: [&#39;h2&#39;], headingExclude: &#39;:hidden,.nomenu&#39;" id="ui-ncbiinpagenav-1"><div class="fm-sec half_rhythm no_top_margin"><div class="fm-flexbox"><div class="fm-citation"><div class="citation-default"><div class="part1"><span role="menubar"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" role="menuitem" aria-expanded="false" aria-haspopup="true">Sensors (Basel).</a></span> 2022 Mar; 22(5): 2069. </div><div class="part2"><span class="fm-vol-iss-date">Published online 2022 Mar 7. </span>  <span class="doi"><span>doi:&nbsp;</span><a href="https://doi.org/10.3390%2Fs22052069" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CCrosslink%7CDOI">10.3390/s22052069</a></span></div></div></div><div class="fm-ids"><div class="fm-citation-pmcid"><span class="fm-citation-ids-label">PMCID: </span><span>PMC8914892</span></div><div class="fm-citation-pmid">PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/35271215">35271215</a></div></div></div><h1 class="content-title">A Review of Recent Developments in Driver Drowsiness Detection Systems</h1><div class="half_rhythm"><div class="contrib-group fm-author"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Albadawi%20Y%5BAuthor%5D" class="affpopup" co-rid="_co_idm140253539897744" co-class="co-affbox">Yaman Albadawi</a>,<sup>1</sup> <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Takruri%20M%5BAuthor%5D" class="affpopup" co-rid="_co_idm140253578168096" co-class="co-affbox">Maen Takruri</a>,<sup>2,</sup><sup>*</sup> and  <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Awad%20M%5BAuthor%5D" class="affpopup" co-rid="_co_idm140253538454544" co-class="co-affbox">Mohammed Awad</a><sup>1</sup></div><div style="display:none" class="contrib-group aff-tip"><div id="_co_idm140253539897744"><h3 class="no_margin">Yaman Albadawi</h3><p><sup>1</sup>Department of Computer Science and Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates; <a href="mailto:dev@null" data-email="ea.ca.karua@iwadabla.namay" class="oemail">ea.ca.karua@iwadabla.namay</a> (Y.A.); <a href="mailto:dev@null" data-email="ea.ca.karua@dawa.demmahom" class="oemail">ea.ca.karua@dawa.demmahom</a> (M.A.)</p><div>Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Albadawi%20Y%5BAuthor%5D">Yaman Albadawi</a></div></div><div id="_co_idm140253578168096"><h3 class="no_margin">Maen Takruri</h3><p><sup>2</sup>Department of Electrical, Electronics and Communications Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates</p><div>Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Takruri%20M%5BAuthor%5D">Maen Takruri</a></div></div><div id="_co_idm140253538454544"><h3 class="no_margin">Mohammed Awad</h3><p><sup>1</sup>Department of Computer Science and Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates; <a href="mailto:dev@null" data-email="ea.ca.karua@iwadabla.namay" class="oemail">ea.ca.karua@iwadabla.namay</a> (Y.A.); <a href="mailto:dev@null" data-email="ea.ca.karua@dawa.demmahom" class="oemail">ea.ca.karua@dawa.demmahom</a> (M.A.)</p><div>Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Awad%20M%5BAuthor%5D">Mohammed Awad</a></div></div></div></div><div class="contrib-group half_rhythm fm-editor">Annie Lanzolla, <span class="fm-role">Academic Editor</span></div><div class="half_rhythm"><div class="togglers fm-copyright-license"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" class="pmctoggle" rid="idm140253541983040_ai idm140253539897872_ai idm140253538452560_ai">Author information</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" class="pmctoggle" rid="idm140253541983040_an">Article notes</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" class="pmctoggle" rid="idm140253541983040_cpl">Copyright and License information</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/about/disclaimer/" style="margin-left: 1em">PMC Disclaimer</a></div><div class="fm-authors-info hide half_rhythm" id="idm140253541983040_ai" style="display:none"><div class="fm-affl" id="af1-sensors-22-02069"><sup>1</sup>Department of Computer Science and Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates; <a href="mailto:dev@null" data-email="ea.ca.karua@iwadabla.namay" class="oemail">ea.ca.karua@iwadabla.namay</a> (Y.A.); <a href="mailto:dev@null" data-email="ea.ca.karua@dawa.demmahom" class="oemail">ea.ca.karua@dawa.demmahom</a> (M.A.)</div><div class="fm-affl" id="af2-sensors-22-02069"><sup>2</sup>Department of Electrical, Electronics and Communications Engineering, American University of Ras Al Khaimah, Ras Al Khaimah 72603, United Arab Emirates</div><div id="c1-sensors-22-02069"><sup>*</sup>Correspondence: <a href="mailto:dev@null" data-email="ea.ca.karua@irurkat.neam" class="oemail">ea.ca.karua@irurkat.neam</a></div></div><div class="fm-article-notes hide half_rhythm" id="idm140253541983040_an" style="display:none"><div class="fm-pubdate half_rhythm">Received 2022 Feb 2; Accepted 2022 Mar 4.</div></div><div class="permissions half_rhythm hide" id="idm140253541983040_cpl" style="display:none"><div class="fm-copyright half_rhythm"><a href="https://www.ncbi.nlm.nih.gov/pmc/about/copyright/">Copyright</a> © 2022 by the authors.</div><div class="license half_rhythm">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<a href="https://creativecommons.org/licenses/by/4.0/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CFront%20Matter&amp;TO=External%7CLink%7CURI" target="_blank">https://creativecommons.org/licenses/by/4.0/</a>).</div></div></div><div id="pmclinksbox" class="links-box whole_rhythm hidden" role="complementary" aria-label="Related or updated information about this article."></div></div><div class="sec"></div><div id="abstract-a.y.b.r" lang="en" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><span role="menubar"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="menuitem" aria-expanded="false" aria-haspopup="true">Go to:</a></span></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="abstract-a.y.b.rtitle">Abstract</h2><!--article-meta--><div><p class="p p-first-last">Continuous advancements in computing technology and artificial intelligence in the past decade have led to improvements in driver monitoring systems. Numerous experimental studies have collected real driver drowsiness data and applied various artificial intelligence algorithms and feature combinations with the goal of significantly enhancing the performance of these systems in real-time. This paper presents an up-to-date review of the driver drowsiness detection systems implemented over the last decade. The paper illustrates and reviews recent systems using different measures to track and detect drowsiness. Each system falls under one of four possible categories, based on the information used. Each system presented in this paper is associated with a detailed description of the features, classification algorithms, and used datasets. In addition, an evaluation of these systems is presented, in terms of the final classification accuracy, sensitivity, and precision. Furthermore, the paper highlights the recent challenges in the area of driver drowsiness detection, discusses the practicality and reliability of each of the four system types, and presents some of the future trends in the field.</p></div><div class="sec"><strong class="kwd-title">Keywords: </strong><span class="kwd-text">biological-based measures, driver drowsiness detection, hybrid-based measures, image-based measures, vehicle-based measures</span></div></div><div id="sec1-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec1-sensors-22-02069title">1. Introduction</h2><p class="p p-first">Based on 2017 police and hospital reports, the National Highway Traffic Safety Administration (NHTSA) identified 91,000 car accidents as being caused by drowsy drivers. These accidents resulted in 50,000 injuries. In 2019, 697 fatalities involved a drowsy driver. However, NHTSA admits that it is hard to determine the precise number of drowsy-driving accidents, injuries, or deaths and that the reported numbers are underestimates [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B1-sensors-22-02069" rid="B1-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">1</a>]. For example, a study by the American Automobile Association’s foundation for traffic safety estimated that more than 320,000 drowsy driving accidents happen each year, including 6400 fatal crashes [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B2-sensors-22-02069" rid="B2-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">2</a>]. The high numbers indicate that drowsy driving is a serious concern that needs to be addressed to mitigate its impact.</p><p>Drowsiness refers to sleepiness, often in inappropriate situations [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B3-sensors-22-02069" rid="B3-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">3</a>]. Although the state of drowsiness may only last for a few minutes, its consequences can be disastrous. The reason for entering such a state is usually attributed to fatigue, which diminishes attention and alertness levels [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B4-sensors-22-02069" rid="B4-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">4</a>]. Drowsiness may happen either by driving for long distances without enough sleep or driving at a time when the driver would typically be asleep [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B5-sensors-22-02069" rid="B5-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">5</a>]. In such cases, the main problem is the drowsy driver’s lack of concentration, resulting in a delayed response to any event on the road [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B6-sensors-22-02069" rid="B6-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">6</a>].</p><p>Fortunately, it is possible to detect driver drowsiness in its early stages and alarm the driver to avoid any potential accident. Drowsy drivers exhibit various signs, which include repeated yawning, frequent eye closure, and repeatedly departing street lanes [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B6-sensors-22-02069" rid="B6-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">6</a>]. In fact, driver drowsiness detection (DDD) techniques have been researched intensively in recent years [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B7-sensors-22-02069" rid="B7-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">7</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B8-sensors-22-02069" rid="B8-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">8</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B9-sensors-22-02069" rid="B9-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B10-sensors-22-02069" rid="B10-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">10</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B11-sensors-22-02069" rid="B11-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">11</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B12-sensors-22-02069" rid="B12-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">12</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B13-sensors-22-02069" rid="B13-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>]. Researchers have proposed various measures to detect these drowsiness signs as early as possible, in order to avoid accidents. These measures can be divided into four main categories: firstly, image-based measures that are obtained using a camera to analyze the driver’s movements and facial expressions; secondly, biological-based measures that relate to the driver’s bio-signals and can be recorded by placing special sensors on the driver’s body; thirdly, vehicle-based measures, which depend on monitoring the behavior and movement of the vehicle; finally, hybrid-based measures, using two or more measures. According to the literature, in 2019, Ramzan et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B9-sensors-22-02069" rid="B9-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>] presented a comprehensive analysis for the existing DDD methods, as well as a detailed analysis for the commonly used classification techniques in this sector. Ramzan et al. classified the DDD techniques into three categories: behavioral, physiological, and vehicular parameter-based techniques. Then, they reviewed the top supervised learning techniques used in detecting drowsiness. In the end, they discussed the pros and cons of the three DDD in a comparative study. On the other hand, Sikander and Anwar [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B10-sensors-22-02069" rid="B10-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">10</a>] presented an in-depth review of the recent advancements in the field of driver fatigue detection. In this review, the DDD methods were categorized into five groups, depending on the extracted fatigue features, including physical features, vehicular features, biological features, subjective reporting, and hybrid features. Furthermore, the fatigue effect on driving performance was discussed, along with the existing commercial products for fatigue detection available on the market. Additionally, Dong et al. presented a review of driver inattention monitoring technologies. Inattention consists of distraction and fatigue [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B12-sensors-22-02069" rid="B12-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">12</a>]. Dong et al. summarized the detection measure into five groups, similar to Sikander and Anwar’s work [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B10-sensors-22-02069" rid="B10-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">10</a>]. In their review, Dong et al. introduced the concept of driver inattention and its effect on driving performance. Additionally, they covered some of the commercial products related to inattention detection, along with a detailed review of previous research on inattention detection.</p><p>This review contributes to the literature by covering the recently implemented DDD systems, especially those published over the past three years. Our paper classifies these systems into four categories, based on the measures used to determine the state of drowsiness. From our perspective, these measures can be image-, biological-, vehicle-, or hybrid-based.</p><p>Moreover, the review lists and tabulates the used parameters, sensors, extracted features, methods and classifiers, and quality metrics (including accuracy, sensitivity, and precision), in addition to the datasets for each system. Additionally, a comparison between the practicality and reliability of each of the four DDD categories is presented. Additionally, the paper covers the recent challenges in the DDD area. Furthermore, we discuss the DDD’s future trends and research directions that utilize smartphones, edge computing, and the Internet of Things (IoT).</p><p class="p p-last">This paper is organized as follows: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec2-sensors-22-02069" rid="sec2-sensors-22-02069" class=" sec">Section 2</a> discusses drowsiness stages and signs. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec3-sensors-22-02069" rid="sec3-sensors-22-02069" class=" sec">Section 3</a> provides a detailed investigation of driver drowsiness measures. These measures are categorized as image-, biological-, vehicle-, and hybrid-based. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec4-sensors-22-02069" rid="sec4-sensors-22-02069" class=" sec">Section 4</a> covers a list of the challenges facing DDD. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec5-sensors-22-02069" rid="sec5-sensors-22-02069" class=" sec">Section 5</a> compares the practicality and reliability of the four DDD system types and discusses the measures and methods, as presented in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec3-sensors-22-02069" rid="sec3-sensors-22-02069" class=" sec">Section 3</a>. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec6-sensors-22-02069" rid="sec6-sensors-22-02069" class=" sec">Section 6</a> discusses some of the future trends in drowsiness detection systems. Finally, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec7-sensors-22-02069" rid="sec7-sensors-22-02069" class=" sec">Section 7</a> concludes the paper.</p></div><div id="sec2-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec2-sensors-22-02069title">2. Drowsiness Signs and Stages</h2><p class="p p-first">In the literature concerning the design of drowsiness detection systems, different terms of reference are used. Although “drowsiness” is the commonly mentioned term, “fatigue” is also used. Despite their difference, fatigue and drowsiness are interchangeably utilized [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B14-sensors-22-02069" rid="B14-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">14</a>]. Fatigue refers to “the reluctance to continue a task as a result of physical or mental exertion or a prolonged period of performing the same task” [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B15-sensors-22-02069" rid="B15-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>]. However, sleepiness or drowsiness is defined as the urge to fall asleep. Basically, drowsiness is the result of a captivating biological need to sleep [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B15-sensors-22-02069" rid="B15-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>]. Drowsiness can happen due to many reasons, such as medication, working for long hours, sleep disorders, poor quality (or not having enough) sleep, and being awake for long periods [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B15-sensors-22-02069" rid="B15-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>]. Thus, their relationship is evident, as fatigue directly contributes to drowsiness. Although they are different concepts, some researchers considered drowsiness and fatigue alike, due to their similar consequences, such as [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B15-sensors-22-02069" rid="B15-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B16-sensors-22-02069" rid="B16-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">16</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B17-sensors-22-02069" rid="B17-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">17</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B18-sensors-22-02069" rid="B18-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">18</a>]. In our work, we refer to these systems as drowsiness detection systems.</p><p>A driver does not become drowsy suddenly, without showing some signs. Examples of such signs include [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B6-sensors-22-02069" rid="B6-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">6</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B13-sensors-22-02069" rid="B13-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>]:</p><ul class="unordered" style="list-style-type:disc"><li><div>Difficulty keeping eyes open;</div></li><li><div>Yawning;</div></li><li><div>Frequent blinking;</div></li><li><div>Difficulty concentrating;</div></li><li><div>Swerving out of the lane and delayed reaction to traffic;</div></li><li><div>Nodding;</div></li><li><div>Unjustifiable variations in speed.</div></li></ul><p></p><p>These signs gradually become more apparent as drowsiness deepens and, as such, can serve as indicators for the level of driver drowsiness. </p><p>To systematically evaluate stages of drowsiness and facilitate the development of automatic early drowsiness detection systems, a precise measurement scale for drowsiness levels is necessary. Many methods have been proposed in that direction. One of the widely used scales in the literature is the Karolinska sleepiness scale (KSS) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B19-sensors-22-02069" rid="B19-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">19</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B20-sensors-22-02069" rid="B20-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">20</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B21-sensors-22-02069" rid="B21-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">21</a>]. Shahid et al. define KSS as “a scale that measures the subjective levels of sleepiness at a particular time during the day” [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B22-sensors-22-02069" rid="B22-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">22</a>] (p. 209). KSS is a nine-point scale that measures drowsiness through verbal descriptions of drivers [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B19-sensors-22-02069" rid="B19-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">19</a>]. The nine KSS scores are summarized in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t001/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t001" rid-ob="ob-sensors-22-02069-t001" co-legend-rid=""><span>Table 1</span></a>. </p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t001"><h3>Table 1</h3><!--caption a7--><div class="caption"><p>Karolinska sleepiness scale, adapted from [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B19-sensors-22-02069" rid="B19-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">19</a>].</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Scale</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Verbal Description</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">Extremely alert</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">Very alert</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">Alert</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">Fairly alert</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">Neither alert nor sleepy</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">Some signs of sleepiness</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">Sleepy, but no effort to keep alert</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">Sleepy, some effort to keep alert</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Very sleepy, great effort to keep alert</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253541475152"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t001/?report=objectonly">Open in a separate window</a></div></div><p>Wierwille and Ellsworth proposed another drowsiness evaluation scale [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B23-sensors-22-02069" rid="B23-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">23</a>]. They define drowsiness stages on a five-level scale, as shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t002/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t002" rid-ob="ob-sensors-22-02069-t002" co-legend-rid=""><span>Table 2</span></a>. According to Saito et al., at level one, rapid eye movement and a stable eye blinking period can be observed [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069" rid="B24-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>]. At level two, slow eye movement occurs. The driver may touch his face at level three, as well as yawn and slowly blink. As for level four, the driver’s unnecessary movements are observed; he frequently yawns, blinks more, and breathes deeply. Finally, the eyes are almost closed at the fifth level, and the head nods. </p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t002"><h3>Table 2</h3><!--caption a7--><div class="caption"><p>Wierwille and Ellsworth drowsiness scale.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Levels</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Verbal Description</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">Not drowsy</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">Slightly drowsy</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">Moderately drowsy</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">Significantly drowsy</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Extremely drowsy</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253578120176"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t002/?report=objectonly">Open in a separate window</a></div></div><p class="p p-last">This scale is also widely used because these levels are determined based on analyzing the driver’s facial expressions. When comparing this scale results with the subjective reports of the drivers, they show a high correlation, which indicates that this evaluation scale could be an alternative to the KSS scale [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069" rid="B24-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B25-sensors-22-02069" rid="B25-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>].</p></div><div id="sec3-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec3-sensors-22-02069title">3. Drowsiness Detection Measures</h2><p class="p p-first">In order to detect the different stages of drowsiness, researchers have studied driver responses and vehicle driving patterns. In this section, we provide a review of the four widely used measures for DDD. The diagram in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f001/" target="figure" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-f001" rid-ob="ob-sensors-22-02069-f001" co-legend-rid="lgnd_sensors-22-02069-f001"><span>Figure 1</span></a> illustrates all the currently used measures for classifying driver drowsiness levels. Two of these measures are observed in the drivers themselves: image- and biological-based. The third measure is extracted from the car itself and referred to as the vehicle-based measure. The fourth measure considered is the hybrid measure, which combines at least two of the previously mentioned ones.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="sensors-22-02069-f001" co-legend-rid="lgnd_sensors-22-02069-f001"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f001/" target="figure" rid-figpopup="sensors-22-02069-f001" rid-ob="ob-sensors-22-02069-f001"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140253531260656"><img loading="lazy" class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is sensors-22-02069-g001.jpg" title="An external file that holds a picture, illustration, etc.
Object name is sensors-22-02069-g001.jpg" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/sensors-22-02069-g001.jpg"></div></a><div class="largeobj-link align_right" id="largeobj_idm140253531260656" style="display: none;"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f001/" target="figure" rid-figpopup="sensors-22-02069-f001" rid-ob="ob-sensors-22-02069-f001"></a><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f001/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_sensors-22-02069-f001"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f001/" target="figure" rid-figpopup="sensors-22-02069-f001" rid-ob="ob-sensors-22-02069-f001">Figure 1</a></div><!--caption a7--><div class="caption"><p>Driver drowsiness detection measures.</p></div></div></div><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f002/" target="figure" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-f002" rid-ob="ob-sensors-22-02069-f002" co-legend-rid="lgnd_sensors-22-02069-f002"><span>Figure 2</span></a> illustrates a DDD system’s general block diagram and data flow that can employ any of the four measures mentioned above. Initially, data are captured using a suitable sensing device; then, the target features are extracted from the captured signals. This step is essential because it simplifies the system input by discarding irrelevant information and extracting useful ones. Next, some systems may employ feature transformation or dimensionality reduction, in order to project the data in another domain, where it is easier to analyze or reduce the computational load. The fourth step selects the features that best correlate to drowsiness, using different feature selection algorithms, such as backward selection or wrapper feature selection methods. After that, machine learning (ML) or deep learning is utilized to generate a model in the training phase that is used to classify the driver’s status. The trained model is used in the testing phase to detect the driver’s drowsiness level and, if required, take action, such as activating an alarm or alerting the driver to take a break. </p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="sensors-22-02069-f002" co-legend-rid="lgnd_sensors-22-02069-f002"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f002/" target="figure" rid-figpopup="sensors-22-02069-f002" rid-ob="ob-sensors-22-02069-f002"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140253531258064"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f002/" target="figure" rid-figpopup="sensors-22-02069-f002" rid-ob="ob-sensors-22-02069-f002"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8914892_sensors-22-02069-g002.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is sensors-22-02069-g002.jpg" title="Click on image to zoom" class="tileshop" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/sensors-22-02069-g002.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140253531258064" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f002/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_sensors-22-02069-f002"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/figure/sensors-22-02069-f002/" target="figure" rid-figpopup="sensors-22-02069-f002" rid-ob="ob-sensors-22-02069-f002">Figure 2</a></div><!--caption a7--><div class="caption"><p>Driver drowsiness detection systems data flow.</p></div></div></div><p>Various metrics have been used to evaluate the ability of the system to detect drowsy subjects. These include accuracy, precision, and sensitivity. The equations for three metrics are listed below (1)–(3) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B26-sensors-22-02069" rid="B26-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">26</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B27-sensors-22-02069" rid="B27-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">27</a>].
</p><div class="disp-formula" id="FD1-sensors-22-02069"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-1-Frame" tabindex="0" style=""><nobr><span class="math" id="mm1" overflow="scroll" style="width: 100%; display: inline-block; min-width: 25.002em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(4.156em, 1019.23em, 9.04em, -999.998em); top: -5.652em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-2"><span style="display: inline-block; position: relative; width: 100%; height: 0px;"><span style="position: absolute; clip: rect(2.502em, 1019.23em, 4.81em, -999.998em); top: -3.998em; left: 50%; margin-left: -9.613em;"><span class="mrow" id="MathJax-Span-3"><span class="mrow" id="MathJax-Span-4"><span class="mi" id="MathJax-Span-5" style="font-family: MathJax_Main;">Accuracy</span><span class="mo" id="MathJax-Span-6" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mfrac" id="MathJax-Span-7" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 13.617em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.194em, 1013.46em, 4.31em, -999.998em); top: -4.69em; left: 50%; margin-left: -6.729em;"><span class="mrow" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10" style="font-family: MathJax_Main;">Number</span><span class="mo" id="MathJax-Span-11" style="font-family: MathJax_Main; padding-left: 0.156em;">&nbsp;</span><span class="mi" id="MathJax-Span-12" style="font-family: MathJax_Main; padding-left: 0.156em;">of</span><span class="mo" id="MathJax-Span-13" style="font-family: MathJax_Main; padding-left: 0.156em;">&nbsp;</span><span class="mi" id="MathJax-Span-14" style="font-family: MathJax_Main; padding-left: 0.156em;">correct</span><span class="mo" id="MathJax-Span-15" style="font-family: MathJax_Main; padding-left: 0.156em;">&nbsp;</span><span class="mi" id="MathJax-Span-16" style="font-family: MathJax_Main; padding-left: 0.156em;">predectins</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1012.58em, 4.117em, -999.998em); top: -3.306em; left: 50%; margin-left: -6.306em;"><span class="mrow" id="MathJax-Span-17"><span class="mrow" id="MathJax-Span-18"><span class="mi" id="MathJax-Span-19" style="font-family: MathJax_Main;">Total</span><span class="mo" id="MathJax-Span-20" style="font-family: MathJax_Main; padding-left: 0.156em;">&nbsp;</span><span class="mi" id="MathJax-Span-21" style="font-family: MathJax_Main; padding-left: 0.156em;">number</span><span class="mo" id="MathJax-Span-22" style="font-family: MathJax_Main; padding-left: 0.156em;">&nbsp;</span><span class="mi" id="MathJax-Span-23" style="font-family: MathJax_Main; padding-left: 0.156em;">of</span><span class="mo" id="MathJax-Span-24" style="font-family: MathJax_Main; padding-left: 0.156em;">&nbsp;</span><span class="mi" id="MathJax-Span-25" style="font-family: MathJax_Main; padding-left: 0.156em;">redections</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1013.62em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 13.617em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(2.54em, 1010.77em, 4.887em, -999.998em); top: -1.498em; left: 50%; margin-left: -5.383em;"><span class="mrow" id="MathJax-Span-3-MathJax-Continue-1"><span class="mrow" id="MathJax-Span-4-MathJax-Continue-1"><span class="mo" id="MathJax-Span-26" style="font-family: MathJax_Main;">=</span><span class="mfrac" id="MathJax-Span-27" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 9.463em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.194em, 1004.08em, 4.194em, -999.998em); top: -4.69em; left: 50%; margin-left: -2.075em;"><span class="mrow" id="MathJax-Span-28"><span class="mi" id="MathJax-Span-29" style="font-family: MathJax_Main;">TP</span><span class="mo" id="MathJax-Span-30" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mi" id="MathJax-Span-31" style="font-family: MathJax_Main; padding-left: 0.233em;">TN</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1009.31em, 4.194em, -999.998em); top: -3.306em; left: 50%; margin-left: -4.652em;"><span class="mrow" id="MathJax-Span-32"><span class="mi" id="MathJax-Span-33" style="font-family: MathJax_Main;">TP</span><span class="mo" id="MathJax-Span-34" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mi" id="MathJax-Span-35" style="font-family: MathJax_Main; padding-left: 0.233em;">TN</span><span class="mo" id="MathJax-Span-36" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mi" id="MathJax-Span-37" style="font-family: MathJax_Main; padding-left: 0.233em;">FP</span><span class="mo" id="MathJax-Span-38" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mi" id="MathJax-Span-39" style="font-family: MathJax_Main; padding-left: 0.233em;">FN</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1009.46em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 9.463em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 5.656em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -4.298em; border-left: 0px solid; width: 0px; height: 6.152em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-1"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="mm1" display="block" overflow="scroll"><mrow><mrow><mi>Accuracy</mi><mo>=</mo><mfrac><mrow><mrow><mi>Number</mi><mo> </mo><mi>of</mi><mo> </mo><mi>correct</mi><mo> </mo><mi>predectins</mi></mrow></mrow><mrow><mrow><mi>Total</mi><mo> </mo><mi>number</mi><mo> </mo><mi>of</mi><mo> </mo><mi>redections</mi></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>TP</mi><mo>+</mo><mi>TN</mi></mrow><mrow><mi>TP</mi><mo>+</mo><mi>TN</mi><mo>+</mo><mi>FP</mi><mo>+</mo><mi>FN</mi></mrow></mfrac></mrow></mrow></math></script></div><div class="l">(1)</div></div><p>
</p><div class="disp-formula" id="FD2-sensors-22-02069"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="mm2" overflow="scroll" style="width: 12.579em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.656em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(0.771em, 1009.66em, 3.117em, -999.998em); top: -2.229em; left: 0em;"><span class="mrow" id="MathJax-Span-41"><span class="mrow" id="MathJax-Span-42"><span class="mrow" id="MathJax-Span-43"><span class="mi" id="MathJax-Span-44" style="font-family: MathJax_Main;">Precision</span><span class="mo" id="MathJax-Span-45" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mfrac" id="MathJax-Span-46" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 4.117em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.194em, 1001.35em, 4.117em, -999.998em); top: -4.69em; left: 50%; margin-left: -0.69em;"><span class="mrow" id="MathJax-Span-47"><span class="mi" id="MathJax-Span-48" style="font-family: MathJax_Main;">TP</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1003.92em, 4.194em, -999.998em); top: -3.306em; left: 50%; margin-left: -1.998em;"><span class="mrow" id="MathJax-Span-49"><span class="mi" id="MathJax-Span-50" style="font-family: MathJax_Main;">TP</span><span class="mo" id="MathJax-Span-51" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mi" id="MathJax-Span-52" style="font-family: MathJax_Main; padding-left: 0.233em;">FP</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1004.12em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 4.117em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.233em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.047em; border-left: 0px solid; width: 0px; height: 2.853em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-2"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="mm2" display="block" overflow="scroll"><mrow><mrow><mi>Precision</mi><mo>=</mo><mfrac><mrow><mi>TP</mi></mrow><mrow><mi>TP</mi><mo>+</mo><mi>FP</mi></mrow></mfrac></mrow></mrow></math></script></div><div class="l">(2)</div></div><p>
</p><div class="disp-formula" id="FD3-sensors-22-02069"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="mm3" overflow="scroll" style="width: 13.425em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.31em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(0.771em, 1010.31em, 3.117em, -999.998em); top: -2.229em; left: 0em;"><span class="mrow" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="mrow" id="MathJax-Span-56"><span class="mi" id="MathJax-Span-57" style="font-family: MathJax_Main;">Sensitivity</span><span class="mo" id="MathJax-Span-58" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mfrac" id="MathJax-Span-59" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 4.156em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.194em, 1001.35em, 4.117em, -999.998em); top: -4.69em; left: 50%; margin-left: -0.69em;"><span class="mrow" id="MathJax-Span-60"><span class="mi" id="MathJax-Span-61" style="font-family: MathJax_Main;">TP</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1004.04em, 4.194em, -999.998em); top: -3.306em; left: 50%; margin-left: -2.037em;"><span class="mrow" id="MathJax-Span-62"><span class="mi" id="MathJax-Span-63" style="font-family: MathJax_Main;">TP</span><span class="mo" id="MathJax-Span-64" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mi" id="MathJax-Span-65" style="font-family: MathJax_Main; padding-left: 0.233em;">FN</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1004.16em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 4.156em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.233em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.047em; border-left: 0px solid; width: 0px; height: 2.853em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-3"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="mm3" display="block" overflow="scroll"><mrow><mrow><mi>Sensitivity</mi><mo>=</mo><mfrac><mrow><mi>TP</mi></mrow><mrow><mi>TP</mi><mo>+</mo><mi>FN</mi></mrow></mfrac></mrow></mrow></math></script></div><div class="l">(3)</div></div><p></p><p>TP (true positive) is the number of drowsy drivers that the system has correctly identified as drowsy, and TN (true negative) is the number of alert drivers that the system has correctly identified as alert. On the other hand, FP (false positive) is the number of alert drivers that the system has wrongly identified as drowsy, and FN (false negative) is the number of drowsy drivers that the system has wrongly identified as alert. </p><p>Accuracy, which is the most commonly used metric, is a good indicator of how well the system can identify both TP and TN. However, it is more suitable when the data are balanced, i.e., when the number of drowsy drivers in an experiment equals the number of alert drivers in the same experiment. Otherwise, accuracy will be biased towards the class with more samples or data points. In many cases, it is easier to obtain awake driver data than it is to get drowsy driver data. In a real-life scenario, more awake drivers are on the road than drowsy ones. Therefore, to avoid bias, precision and sensitivity, also known as recall, are better alternatives for unbalanced datasets. </p><p>Precision shows a proportion of the correctly identified drowsy drivers to those labeled as drowsy, while they are, in reality, alert. In contrast, sensitivity shows a proportion of the correctly identified drowsy drivers to those labeled as alert, while, in reality, they are drowsy. Low precision indicates that the system may identify alert drivers as drowsy and take actions to alert them. In contrast, low sensitivity means that the system may not be able to identify drowsy drivers, which could lead to serious accidents. It is, therefore, essential to have high sensitivity in DDD systems.</p><p class="p">Other factors that are considered in the comparison of the four system types are cost, invasiveness, intrusiveness, and ease of use. Ease of use refers to the complexity of setting up the system at the beginning of each trip. All of these factors are covered here, under the umbrella of practicality. Generally, a trade-off between the system’s performance and cost must be weighed.</p><div id="sec3dot1-sensors-22-02069" class="sec"><h3 id="sec3dot1-sensors-22-02069title">3.1. Image-Based Measures</h3><p class="p p-first">Some drowsiness signs are visible and can be recorded by cameras or visual sensors. They include the driver’s facial expressions and movements, especially the head movements. The literature refers to these signs as visual [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B8-sensors-22-02069" rid="B8-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">8</a>] or image-based measures [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B7-sensors-22-02069" rid="B7-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">7</a>]. Our work refers to them as image-based measures to highlight that these measures usually lead to features extracted from images or videos. Additionally, it is important to note here that image-based measures are a subcategory of the physical [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B10-sensors-22-02069" rid="B10-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">10</a>] or behavioral measures [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B9-sensors-22-02069" rid="B9-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>]. Physical and behavioral measures refer to the body movements captured either from videos or using motion sensors, such as a gyroscope and accelerometer [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B28-sensors-22-02069" rid="B28-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">28</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B29-sensors-22-02069" rid="B29-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">29</a>]. </p><p>Image-based DDD systems can be broadly categorized into three techniques, based on whether movements of the mouth, head, or eyes are observed. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t003/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t003" rid-ob="ob-sensors-22-02069-t003" co-legend-rid=""><span>Table 3</span></a> lists some of the image-based measures.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t003"><h3>Table 3</h3><!--caption a7--><div class="caption"><p>Some of the image-based measures.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Features</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Blink frequency [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B30-sensors-22-02069" rid="B30-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">30</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The number of times an eye closes over a specific period of time.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Maximum closure duration of the eyes [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B30-sensors-22-02069" rid="B30-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">30</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The maximum time the eye was closed. However, it can be risky to delay detecting an extended eye closure that indicates a drowsy driver.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Percentage of eyelid closure (PERCLOS) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B31-sensors-22-02069" rid="B31-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">31</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The percentage of time (per minute) in which the eye is 80% closed or more.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye aspect ratio (EAR) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B32-sensors-22-02069" rid="B32-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">32</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EAR reflects the eye’s openness degree. The EAR value drops down to zero when the eyes are closed. On the other hand, it remains approximately constant when the eye is open. Thus, the EAR detects the eye closure at that time.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Yawning frequency [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B33-sensors-22-02069" rid="B33-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">33</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The number of times the mouth opens over a specific period of time.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Head pose [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B34-sensors-22-02069" rid="B34-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">34</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Is a figure that describes the driver’s head movements. It is determined by counting the video segments that show a large deviation of three Euler angles of head poses from their regular positions. These three angles are nodding, shaking, and tilting.</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253536016704"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t003/?report=objectonly">Open in a separate window</a></div></div><p>One widely used dataset among the Image-based DDD systems is the National Tsing Hua University Drowsy Driver Detection (NTHUDDD) public dataset by the Computer Vision Lab of National Tsing Hua University [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]. This dataset gained popularity due to the various scenarios and drowsiness features it covers. The dataset includes training, evaluation, and testing datasets and contains recorded videos for 36 subjects from different ethnicities. Additionally, it considers the cases when the driver is wearing sunglasses/glasses, day and night illumination conditions, and a variety of simulation scenarios, including: </p><ul class="unordered" style="list-style-type:disc"><li><div>Normal driving;</div></li><li><div>Yawning;</div></li><li><div>Slow blink rate;</div></li><li><div>Falling asleep;</div></li><li><div>Burst out laughing.</div></li></ul><p></p><p>The training dataset includes videos for 18 subjects in five different scenarios, including subjects with (1) bare face, (2) glasses, (3) bare face at night, (4) glasses at night, and (5) sunglasses. The videos include the two most important scenarios. Firstly, a combination of drowsiness symptoms, such as slow blink rate, yawning, and nodding. Secondly, a variety of non-drowsiness actions, such as talking, looking at both sides, and laughing. On the other hand, the testing and evaluation datasets contain videos from the remaining 18 subjects. These videos include drowsy and non-drowsy features, mixed under multiple scenarios.</p><p>Below, we discuss some image-based detection systems that have been introduced over the past decade. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t004/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t004" rid-ob="ob-sensors-22-02069-t004" co-legend-rid=""><span>Table 4</span></a> provides a summary of those systems.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t004"><h3>Table 4</h3><!--caption a7--><div class="caption"><p>Image-based drowsiness detection systems.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Ref.</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Image-Based<br>Parameters</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Extracted Features</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Classification Method</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Quality Metric</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Dataset</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B16-sensors-22-02069" rid="B16-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">16</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Yawning</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Cold and hot voxels [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B37-sensors-22-02069" rid="B37-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A fatigue detection method based on yawning detection using thermal imaging. The cold and hot voxels were used to detect yawning.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>Cold voxels: 71%,<br>Hot voxels: 87%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B36-sensors-22-02069" rid="B36-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">36</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B38-sensors-22-02069" rid="B38-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">38</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiration (using thermal camera)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Standard deviation and the mean of respiration rate, as well as the inspiration-to-expiration time ratio</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM and KNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used facial thermal imaging to study the driver’s respiration and relate it to drowsiness.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br> SVM: 90%,<br>KNN: 83%<br>Sensitivity:<br>SVM: 92%, KNN: 82%<br>Precision: SVM: 91%, KNN: 90%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">New thermal image dataset was prepared</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B39-sensors-22-02069" rid="B39-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">39</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eyelids’ curvature</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Classification based on the period of eye closure</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Based on the eyelid’s curvature’s concavity, the system determined if the eye is opened or closed. Then, it detected drowsiness based on the eye closure period.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>Dataset 1: 95%,<br>Dataset 2: 70%,<br>Dataset 3: &gt;95%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dataset1: Prepared their own image dataset<br>Dataset2: Benchmark dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B40-sensors-22-02069" rid="B40-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">40</a>]<br>Dataset3: Prepared their own video dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B41-sensors-22-02069" rid="B41-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">41</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye state (open/closed)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Proposed optical correlation with deformed filter</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used optical Vander Lugt correlator to precisely estimate the eye’s location in the Fourier plane of the Vander Lugt correlator.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Different accuracies for different datasets</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">FEI [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B44-sensors-22-02069" rid="B44-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">44</a>], ICPR [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B45-sensors-22-02069" rid="B45-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">45</a>], BioID [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B46-sensors-22-02069" rid="B46-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">46</a>], GI4E [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B47-sensors-22-02069" rid="B47-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">47</a>], and SHRP2 [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B48-sensors-22-02069" rid="B48-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">48</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B49-sensors-22-02069" rid="B49-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">49</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The eyes’ EAR value</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Multilayer perceptron, RF, and SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Tracked eye blinking duration in video streams, as an indicator of drowsiness using the EAR. Overall, the SVM showed the best performance.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>SVM: 94.9%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B30-sensors-22-02069" rid="B30-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">30</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Face and eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PERCLOS, blink frequency, and maximum closure duration of the eyes.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">KNN, SVM, logistic regression, and ANN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A nonintrusive system based on face and eye state tracking. The final results revealed that the best models were the KNN and ANN.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>KNN: 72.25%<br>ANN: 71.61%<br>Sensitivity:<br>KNN: 83.33%<br>ANN: 85.56%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B50-sensors-22-02069" rid="B50-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">50</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye closure</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">FD-NN, TL-VGG16, and TL-VGG19</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Applied real-time system based on the area of eye closure using CNN. For eye closure classification, three networks were introduced: FD-NN, TL-VGG16, and TL-VGG19.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>FD-NN: 98.15%,<br>TL-VGG16: 95.45%, TL-VGG19: 95%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ZJU gallery and prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B51-sensors-22-02069" rid="B51-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">51</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">34 eye–eye tracking features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF and non-linear SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used 34 eye-tracking signals’ features to detect drowsiness. These features were extracted from overlapping eye signals’ epochs of different lengths. The labels were extracted from EEG signals.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>RF: 88.37% to 91.18%<br>SVM: 77.1% to 82.62%<br>Sensitivity for 10s epoch:<br>RF: 88.1%<br>SVM: 79.1% </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B52-sensors-22-02069" rid="B52-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">52</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye and Mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PERCLOS, eye closing duration, and average mouth opening time</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mamdani fuzzy inference system</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The state of the extracted parameters is determined through a cascade of regression tree algorithms. A Mamdani fuzzy inference system then estimates the driver state.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 95.5%<br>Precision: 93.3%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">300-W dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B53-sensors-22-02069" rid="B53-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">53</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B54-sensors-22-02069" rid="B54-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">54</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye and Mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye closure and mouth openness for a duration of time</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Circular Hough transform</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The circular Hough transform method is applied to check whether the mouth is open or iris is detected. Based on these two measures, the driver’s state is determined.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 94%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B55-sensors-22-02069" rid="B55-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">55</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye and Head</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Frequency of eyes blinking and frequency of head tilting</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Templet matching to detect the eyes and calculating the frequency of head tilting and eye blinking to detect the drowsiness level</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">By calculating the frequency of head tilting and eye blinking, the drowsiness level is determined, on a scale of 0-100. If drowsiness reached 100, a loud audible warning would be triggered.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 99.59%<br>Precision: 97.86%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B56-sensors-22-02069" rid="B56-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">56</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mouth and Eye</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Proportion of the number of closed-eye frames to the total number of frames in 1min, continuous-time of eye closure, blinking frequency, and number of yawns in 1-min</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">For face tracking: multiple CNNs-kernelized correlation filters method<br>For drowsiness detection: newly proposed algorithm</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The multiple CNNs-kernelized correlation filters method is used for face tracking and to extract the image-based parameters. If found drowsy, the driver is alerted.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 92%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CelebA dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B57-sensors-22-02069" rid="B57-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">57</a>], YawDD dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B58-sensors-22-02069" rid="B58-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">58</a>], and new video data were prepared</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B59-sensors-22-02069" rid="B59-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">59</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Facial, hand, Behavioral (head, eyes, or mouth movements)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Facial expression, behavioral features, head gestures, and hand gestures</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SoftMax classifier</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">This system introduced an architecture that uses four deep learning models to extract four different types of features.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 85%<br>Sensitivity: 82%<br>Precision: 86.3%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B17-sensors-22-02069" rid="B17-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">17</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye, head, and mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye closure duration, head nodding, and yawning</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A two-stream CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used multi-task cascaded CNNs to find the positions of the mouth and eyes. Then, it extracted the static and dynamic features from a partial facial image and partial facial optical flow, respectively. Lastly, it combined the features to classify the image data.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 97.06%<br>Sensitivity: 96.74%<br>Precision: 97.03%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B63-sensors-22-02069" rid="B63-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">63</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye, mouth, head, and scene conditions</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Facial changes in eye, mouth, and head, illumination condition of driving, and wearing glasses</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3D-deep CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The framework contained four models to recognize the drivers’ alertness status, using the condition-adaptive representation.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 76.2%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B33-sensors-22-02069" rid="B33-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">33</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye, head, and mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Blinking rate, head-nodding, and yawning frequency</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Fisher score for feature selection and non-linear SVM for classification</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The system is based on a hand-crafted compact face texture descriptor that can capture the most discriminant drowsy features.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 79.84%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B18-sensors-22-02069" rid="B18-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">18</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Facial features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Face feature vectors</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used facial motion information entropy, extracted from real-time videos. The algorithm contained four modules.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 94.32%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">YawDD dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B58-sensors-22-02069" rid="B58-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">58</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069" rid="B68-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">68</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Facial features, head movements</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Implicitly decides the important features like eye closure, mouth position, chin or brow raises, frowning, and nose wrinkles</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3D CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DDD was performed, based on activity prediction, through a depth-wise separable 3D CNN, using real-time face video. An advantage of this method was that it implicitly decided the important features, rather than pre-specifying a set of features beforehand.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 73.9%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B69-sensors-22-02069" rid="B69-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">69</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye and mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Temporal facial feature vectors formed from spatial features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LSTM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A method that applied real-time DDD, based on a combination of CNN and LSTM. It consisted of two parts: spatial and temporal.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 84.85%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B70-sensors-22-02069" rid="B70-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">70</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye, head, and mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Yawning, eye closure, and head nodding</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Multi-layer model-based 3D convolutional networks</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used a repetitive neural network architecture, based on an RNN model, called multi-layer model-based 3D convolutional networks, to detect fatigue.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 97.3%<br>Sensitivity: 92%<br>Precision: 72%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B72-sensors-22-02069" rid="B72-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">72</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye and mouth</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PERCLOS and mouth opening degree</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eye and mouth CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Applied face detection and feature points location, using multi-task cascaded CNNs architecture and EM-CNN to detect the mouth and eye state from the ROI.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 93.62%<br>Sensitivity: 93.64%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Driving images dataset from Biteda company</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253537125040"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t004/?report=objectonly">Open in a separate window</a></div></div><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">1.</div><div>Fatigue detection, based on awning in thermal images</div></li></ul><p>In their paper, Knapik and Cyganek presented a novel approach for driver fatigue detection, based on yawning detection, using long-range infrared thermal imaging [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B16-sensors-22-02069" rid="B16-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">16</a>]. A special dataset was created for this research [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B36-sensors-22-02069" rid="B36-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">36</a>]. The system works as follows. First, images are acquired from a thermal video. Then, three cascaded detection modules are applied for the face area, eye corners, and yawn. Since the mouth area is sometimes hard to detect in thermal images, due to the temperature difference in that area, information about other face regions’ relative temperatures is used to detect the yawn reflex. Thus, the authors used the eye corners as an indicator for yawning. Cold and hot thermal voxel sum methods were used to detect yawning [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B37-sensors-22-02069" rid="B37-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>]. Finally, based on the proposed algorithm’s results and assumed constraints, an alarm is initiated when fatigue is detected. The system showed accuracies of 71% for cold voxels detection and 87% for hot voxels detection.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">2.</div><div>Drowsiness detection using respiration in thermal imaging</div></li></ul><p>Kiashari et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B38-sensors-22-02069" rid="B38-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">38</a>] introduced a non-intrusive system that detects drowsiness using facial thermal imaging to analyze the driver’s respiration signal. Thirty subjects participated in their study, which was conducted in a car simulator. A thermal camera was used to capture the driver’s thermal images. From the obtained thermal signals, the standard deviation and mean of both the respiration rate and inspiration-to-expiration time ratio were calculated and used as input features, in order to train two machine learning classifiers, namely, support vector machine (SVM) and k-nearest neighbor (KNN). Both classifiers were able to detect drowsiness. However, SVM outperformed the KNN, with 90% accuracy, 85% specificity, 92% sensitivity, and 91% precision.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">3.</div><div>Drowsiness detection using eye features</div></li></ul><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Eyelid closure analysis</div></li></ul>
</div></li></ul><p>Khan et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B39-sensors-22-02069" rid="B39-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">39</a>] proposed a real-time DDD system based on eyelid closure. The system was implemented on hardware that used surveillance videos to detect whether the drivers’ eyes were open or closed. The system started by detecting the face of the driver. Then, using an extended Sobel operator, the eyes were localized and filtered to detect the eyelids’ curvature. After that, the curvature’s concavity was measured. Based on the measured concavity value, the eyelid was classified as open (concave up) or closed (concave down). If the eyes were deemed closed for a certain period, a sound alarm is initiated. The system used three datasets. The authors generated two of them, and the third was acquired from [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B40-sensors-22-02069" rid="B40-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">40</a>]. The first dataset, which contained simple images, with a homogenous background, showed an accuracy of 95%. The second set, which included a complex benchmark image dataset, achieved an accuracy of 70%; the third one, which used two real-time surveillance videos, showed an accuracy that exceeded 95%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Optical correlator based DDD algorithm</div></li></ul>
</div></li></ul><p>Ouabida et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B41-sensors-22-02069" rid="B41-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">41</a>] proposed a fast method for DDD that depends on an optical correlator to detect the eye and then estimates its state using optical correlation with a deformed filter. This method was the first to use a numerical simulation of the optical Vander Lugt correlator [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B42-sensors-22-02069" rid="B42-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">42</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B43-sensors-22-02069" rid="B43-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">43</a>] to detect the eye center automatically. The proposed DDD method precisely estimates the eye’s location and state (open or closed), using a specific filter in the Fourier plane of the optical Vander Lugt correlator. In this method, the eyes are initially detected in non-zoomed facial images. Using the simulated optical correlator, the eye state is estimated under different lighting, head orientations, and with or without eyeglasses. The researchers evaluated the proposed method on five international databases: FEI [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B44-sensors-22-02069" rid="B44-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">44</a>], ICPR [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B45-sensors-22-02069" rid="B45-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">45</a>], BioID [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B46-sensors-22-02069" rid="B46-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">46</a>], GI4E [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B47-sensors-22-02069" rid="B47-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">47</a>], and the second Strategic Highway Research Program results (SHRP2) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B48-sensors-22-02069" rid="B48-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">48</a>]. Additionally, a group of correlation filters was proposed and designed to recognize eyes’ states in noisy and cluttering environments. The proposed optical correlation, with a deformed eye filter, showed the best performance.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Real-time DDD using eye aspect ratio</div></li></ul>
</div></li></ul><p>In this work, Maior et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B49-sensors-22-02069" rid="B49-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">49</a>] developed a drowsiness detection method based on eye patterns monitored by video streams using a simple web camera. The method tracks the blinking duration using the EAR metric. The proportion between the eye’s height and width is calculated to evaluate the EAR value. A high EAR value indicates that the eye is open, while a low value indicates that it is closed. The proposed method consists of three main parts: eye detection, EAR calculation and blink classification, and real-time drowsiness detection. An experiment was conducted to generate a training database. After obtaining the images from the web camera, the EAR values were calculated and stored for each frame. Then, a specific number of consecutive values were used as input for the machine learning algorithms. Drowsiness is detected if the blink duration is longer, compared to a standard blink. Three classification methods were employed: multilayer perceptron, random forest (RF), and SVM. Overall, SVM showed the best performance, with an average test accuracy of 94.9%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>DDD using face and eye features</div></li></ul>
</div></li></ul><p>In [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B30-sensors-22-02069" rid="B30-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">30</a>], Bamidele et al. presented a nonintrusive DDD system, based on face and eye state tracking. The research utilized the NTHUDDD Computer Vision Lab’s video dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]. The proposed system starts by acquiring and pre-processing the required data. Then, it extracts the targeted features, including the PERCLOS, maximum closure duration of the eyes, and blink frequency. The extracted features are then fed to various classifiers to decide whether they belong to a drowsy or awake person. These classifiers include KNN, SVM, logistic regression, and artificial neural networks (ANN). The final results revealed that the best models were the KNN and ANN, with accuracies of 72.25% and 71.61%, respectively.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Detection of driver drowsiness with CNN</div></li></ul>
</div></li></ul><p>Hashemi et al. proposed a real-time DDD system based on the area of eye closure and use of the convolutional neural network (CNN) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B50-sensors-22-02069" rid="B50-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">50</a>]. Three networks were introduced for eye closure classification: fully designed neural network (FD-NN), transfer learning in VGG16 (TL-VGG16), and transfer learning in VGG19 (TL-VGG19), with extra designed layers. The authors used the ZJU gallery dataset, in addition to 4157 new images. The experiment resulted in the following network accuracies: 98.15%, 95.45%, and 95%, respectively.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Eye signal analysis</div></li></ul>
</div></li></ul><p>Zandi et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B51-sensors-22-02069" rid="B51-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">51</a>] proposed a non-intrusive drowsiness detection ML system based on eye-tracking data. The experiments were conducted in a simulated driving environment, with 53 participants. The authors collected data for eye-tracking signals and multichannel electroencephalography signals. The electroencephalography signal was only used as a reliable baseline for comparison and to label the eye-tracking signals epochs as drowsy or alert. The proposed ML system extracted 34 eye-tracking signals’ features, obtained from overlapping eye signals’ epochs with different lengths. The system performance, subject to various combinations of different features and epoch lengths, was also studied. Two binary classifiers were used: the RF classifier with 200 trees and non-linear SVM with a Gaussian kernel classifier. The experiment results revealed that the RF classifiers resulted in an accuracy range of 88.37% to 91.18% across all epochs, as well as a sensitivity–specificity of 88.1% to 88.8% for a 10-s epoch. In contrast, the non-linear SVM classifier showed an accuracy range of 77.12% to 82.62%. Additionally, it resulted in a sensitivity–specificity of 79.1% to 80.8% for a 10-s epoch. Using eye-tracking data and a proper classification framework, such results confirmed that drowsiness could be reliably detected with high accuracy, specificity, and sensitivity.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">4.</div><div>Drowsiness detection using multiple features</div></li></ul><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Eye and mouth analysis</div></li></ul>
</div></li></ul><p>Celecia et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B52-sensors-22-02069" rid="B52-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">52</a>] proposed a low-cost, portable, robust, and accurate DDD device that used an infrared illuminator and camera to record images. The device’s processing model, which was performed over a Raspberry Pi 3 Model B, combines features obtained from the eyes and mouths of the subjects under consideration. The features include PERCLOS [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B31-sensors-22-02069" rid="B31-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">31</a>], eye closing duration, and average mouth opening time. The 300-W dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B53-sensors-22-02069" rid="B53-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">53</a>] was used in the training process. The authors determined the state of each feature through a cascade of regression tree algorithms. A Mamdani fuzzy inference system then estimated the driver state by combing the three features’ states as an input. The device generates a final output that represents the drowsiness level by giving a label of either “Low-Normal”, “Medium-Drowsy”, or “High-Severe state.” According to Celecia et al., using various drowsiness measures overcomes the issues of partly losing some of them in the image. Thus, the study resulted in a DDD device, robust to different ambient lighting conditions, with 95.5% accuracy.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Eye state analysis and yawning</div></li></ul>
</div></li></ul><p>Alioua et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B54-sensors-22-02069" rid="B54-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">54</a>] proposed a non-intrusive and robust system that detects drowsiness in real-time to reduce traffic accidents. The system detects drowsiness based on a closed-eyes and open-mouth detection algorithm. In this work, a group of images was collected using a webcam. According to the authors, the system starts with an SVM face detector to extract the face region from the video frames. Then, the eye and mouth regions localization within the face is performed. Finally, the circular Hough transform is applied to the extracted eye to find the iris, a colored muscular curtain close to the front of the eye, as an indication of eye openness. Additionally, it is used over the mouth region to determine the degree of mouth openness. Based on the fusion of the state of the eye and the mouth, the system decides whether the driver is drowsy or not. The results showed that this system is robust, with 94% accuracy and 86% kappa statistic value.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Eye Closeness</div></li></ul>
</div></li></ul><p>In order to detect the levels of drowsiness, Khunpisuth et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B55-sensors-22-02069" rid="B55-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">55</a>] conducted a study with ten volunteers. During the study, the frequency of eyes blinking and head tilting was monitored and related to the drivers’ drowsiness state. The authors built an embedded device for drowsiness detection that used a Raspberry Pi Camera and Raspberry Pi 3 Model B to collect image data, detect the drowsiness level, and alert the driver. Initially, the proposed device applied the Haar cascade classifier to detect an upright face, head level, and eye blinking. Moreover, if the head position is not upright, geometric rotation is used to calculate the angle and rotate the image to an upright position, in order to detect accurately. Secondly, template matching is used to detect whether the eyes are open or closed. Thirdly, the drowsiness level is calculated via the frequency of head tilting and eye blinking. The system uses a scale of 0–100 to describe the severity of the drowsiness. If the drowsiness level reaches 100, the system triggers a loud, audible warning to alert the driver. Finally, the accuracy system gave an accuracy of 99.59%. However, this system had some limitations, as it is affected by the subject’s skin tone and background light.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Facial features</div></li></ul>
</div></li></ul><p>Deng and Wu [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B56-sensors-22-02069" rid="B56-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">56</a>] proposed DriCare, a real-time DDD system. This system detects the drowsiness status using images from video streams. The authors introduced an enhanced in-video face-tracking algorithm, called multiple CNNs-kernelized correlation filters. Further, they used 68 key points in the driver’s face to locate key regions, including the eyes and mouth. The authors then calculated the number of closed-eye frames to the total number of frames, continuous-time of eye closure, blinking frequency, and number of yawns in a minute to detect the driver’s drowsiness. Finally, the DriCare system alerts the driver, using some warning, if found drowsy. The system was tested on CelebA [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B57-sensors-22-02069" rid="B57-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">57</a>], YawDD [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B58-sensors-22-02069" rid="B58-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">58</a>] datasets, and other videos obtained by the authors. Overall, the system showed an accuracy of around 92%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Deep CNN models-based ensemble approach</div></li></ul>
</div></li></ul><p>Dua et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B59-sensors-22-02069" rid="B59-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">59</a>] utilized the NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>] to propose an architecture that detects driver drowsiness. This architecture comprises of four deep learning models: AlexNet, VGG-FaceNet, FlowImageNet, and ResNet. These models are used to extract four different types of features: facial expression, head gestures, hand gestures, and behavioral features, such as head, eyes, or mouth movements. While the AlexNet model accounts for different environmental and background conditions, the VGG-FaceNet model detects and extracts facial traits. In contrast, FlowImageNet is used to extract head gestures and behavioral features, while ResNet is used for hand gestures. Using RGB videos of the drivers as an input, the four models generate four outputs that are fed to an ensemble algorithm, called simple averaging [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B60-sensors-22-02069" rid="B60-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">60</a>], followed by a SoftMax classifier [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B61-sensors-22-02069" rid="B61-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">61</a>]. Dua et al. proposed system resulted in an overall accuracy of 85%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Fatigue detection using convolutional two-stream network</div></li></ul>
</div></li></ul><p>Liu et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B17-sensors-22-02069" rid="B17-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">17</a>] presented a fatigue detection algorithm that feeds multi-facial features, such as eye closure duration, head nodding, and yawning, to a convolutional two-stream network, referred to as a gamma fatigue detection network. Initially, the algorithm locates the eyes and mouth of the driver using multi-task cascaded CNNs. The static features are then extracted from a partial facial image. After that, the dynamic features are extracted from a partial facial optical flow. Once obtained, both static and dynamic features are combined using a two-stream neural network to classify the image data. In addition, the paper showed that applying gamma correction [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B62-sensors-22-02069" rid="B62-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">62</a>] to enhance image contrast increased the accuracy by 2% for night shoots. The algorithm was verified using the NTHUDDD public dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>], with an accuracy of 97.06%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Condition-adaptive representation learning</div></li></ul>
</div></li></ul><p>Yu et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B63-sensors-22-02069" rid="B63-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">63</a>] presented a condition-adaptive representation learning framework for DDD, based on a 3D-deep CNN using the NTHUDDD public dataset. The framework contained four models: spatio-temporal representation learning, scene condition understanding, feature fusion model, and the drowsiness detection model. </p><p>First, spatio-temporal representation learning was used to simultaneously extract features that describe movements and appearances in the video. Then, scene condition understanding was used to represent different driving conditions and classify the drivers. Such conditions include facial changes in the eye, mouth, and head, in addition to others. Then, the feature fusion model generates an adaptive representation for driving conditions by fusing two features. Finally, the drowsiness detection model recognizes the drivers’ alertness status, using the condition-adaptive representation from the previous model. The framework’s accuracy was 76.2%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Face descriptors</div></li></ul>
</div></li></ul><p>Moujahid et al. introduced a face monitoring DDD system that can capture the most discriminant drowsiness features [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B33-sensors-22-02069" rid="B33-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">33</a>]. It is based on a hand-crafted, compact face texture descriptor. After extracting the raw features, the compactness is achieved by employing pyramid multi-level face representation and feature selection. This work used the NTHUDDD [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>] public dataset. The authors have focused on extracting the tiredness features from the eyes, head, and mouth, such as blinking rate, head nodding, and yawning frequency. This process led to three descriptors, namely covariance descriptor [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B64-sensors-22-02069" rid="B64-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">64</a>], a histogram of oriented gradients features [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B65-sensors-22-02069" rid="B65-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">65</a>], and classical texture local binary pattern features [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B66-sensors-22-02069" rid="B66-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">66</a>]. The framework consists of five phases: first, face detection and alignment; second, pyramid multi-level face representation; third, pyramid multi-level feature extraction; fourth, dimensionality reduction principal component analysis and subset feature selection, using the Fisher score [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B67-sensors-22-02069" rid="B67-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">67</a>]; finally, non-linear SVM-based classification. After testing the data with several DDD methods, the experimental results showed that the proposed method achieved an accuracy of 79.84%. Furthermore, these results proved that this method is similar or superior to other approaches that rely on deep CNN.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Facial motion information entropy</div></li></ul>
</div></li></ul><p>In [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B18-sensors-22-02069" rid="B18-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">18</a>], You et al. proposed a real-time algorithm for driver fatigue detection using facial motion information entropy. The algorithm contains four modules. First, a face positioning module, where the authors presented an improved YOLOv3-tiny CNN to capture the facial regions, under various complex conditions, within the captured video frames. The second module is dedicated to feature vector extraction. In this module, a face feature triangle geometry area was constructed using the Dlib toolkit, face’s landmarks, and facial regions’ coordinates. The third module involves extracting face feature vectors that contain information about each face feature triangle area, as well as the centroid extracted for each frame. This vector is used as an indicator to determine the driver’s state. In the fourth module, the fatigue judgment module, a sliding window is designed to acquire the facial motion information entropy. This information is then compared to a judgment threshold, specified by the SVM classifier, to evaluate the driver’s fatigue state. The authors verified their proposed algorithm using an open-source dataset (YawDD [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B58-sensors-22-02069" rid="B58-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">58</a>]). You et al. reported accuracy of 94.32%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Monitoring drowsiness on a mobile platform</div></li></ul>
</div></li></ul><p>Wijnands et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069" rid="B68-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">68</a>] described a new DDD method, based on activity prediction, through depth-wise separable 3D CNN using real-time video. Similar to others, their method used the academic NTHUDDD dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]. An advantage of this method is that it implicitly decides on the essential features, rather than pre-specifying a set of features beforehand. Some features include eyelid closure, mouth position, frowning, outer brow raises, nose wrinkles, and chin raises. Thus, if a sufficient amount of data labels are provided, it will capture these features. The experiments were conducted under different lighting and face wear conditions, including driving at night and daytime. Additionally, subjects drove while wearing glasses, sunglasses, and without any. The results presented different accuracies, based on the different scenarios and selected features, but the method showed a final accuracy of 73.9%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>DDD with hybrid CNN and LSTM</div></li></ul>
</div></li></ul><p>Guo and Markoni [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B69-sensors-22-02069" rid="B69-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">69</a>] proposed a new method that applies real-time DDD, based on a combination of CNN and long short-term memory (LSTM). The proposed method consists of two parts: spatial and temporal. In the spatial part, the method extracts facial features, such as eyes and mouth, in one frame. CNN was used for face detection, face landmark detection, and eyes and mouth classification. As for the temporal part, an LSTM analyzer used the concatenated spatial features that indicate drowsiness or alertness for analysis and final classification. </p><p>Overall, the DDD method follows three steps. First, face detection using multi-task cascaded CNN and landmark extraction, along with spatial feature extraction, which is done by utilizing CNN. Then, temporal features are formed by concatenating spatial features through frame vector concatenation using sliding windows. Finally, the concatenated features are fed to an LSTM, where a decision of drowsiness (or not) is made. This method employed the NTHUDDD public dataset from the ACCV 2016 competition [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>]. Various accuracies for the different applied scenarios and experiments were presented. However, the proposed method gave a final accuracy of 84.85%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Fatigue detecrion using new CNN method</div></li></ul>
</div></li></ul><p>Ed-Doughmi et al.’s research [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B70-sensors-22-02069" rid="B70-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">70</a>] presented an approach to analyze and predict fatigue based on a recursive neural network (RNN), using a sequence of frames from videos. The authors implemented a repetitive neural network architecture, based on an RNN model, called multi-layer, model-based 3D convolutional networks [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B71-sensors-22-02069" rid="B71-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">71</a>], to detect fatigue. They detected fatigue by extracting the subjects’ drowsy behaviors, such as yawning, eye closure, and head nodding, from the NTHUDDD dataset videos. An accuracy of 97.3% was obtained [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069" rid="B35-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>].</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Fatigue detection using eye and mouth CNN</div></li></ul>
</div></li></ul><p>Zhao et al. proposed a fully automated driver fatigue detection algorithm [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B72-sensors-22-02069" rid="B72-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">72</a>]. This study uses the driving images dataset provided by Biteda, an information technology company. This algorithm applies face detection and feature points location, using a multitask cascaded CNN architecture, where the region of interest (ROI) can be extracted using the feature points. Moreover, a new CNN algorithm, called eye and mouth CNN (EM-CNN), was proposed. The EM-CNN algorithm detects the mouth and eye state from the ROI. Both the PERCLOS and mouth opening degree were used as parameters for detection. The final results showed an accuracy of 93.62% and sensitivity of 93.64%.</p><p class="p"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t004/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t004" rid-ob="ob-sensors-22-02069-t004" co-legend-rid=""><span>Table 4</span></a> reveals that image-based systems have reported accuracies between 72.25% and 99.59%, with [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B55-sensors-22-02069" rid="B55-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">55</a>] showing the highest accuracy. Most of them rely on eye state features. Generally, such systems are non-intrusive, non-invasive, and cost-effective, as they require only a camera to collect the needed data. However, the system’s performance is severely affected in cases where it is difficult to track facial data due to obstacles. Further details are discussed later in the challenges section.</p></div><div id="sec3dot2-sensors-22-02069" class="sec"><h3 id="sec3dot2-sensors-22-02069title">3.2. Biological-Based Measures</h3><p class="p p-first">Many biological signals have been used to detect the driver’s drowsiness, such as brain activity, heart rate, breathing rate, pulse rate, and body temperature signals [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B10-sensors-22-02069" rid="B10-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">10</a>]. These biological signals, also known as physiological measures [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B9-sensors-22-02069" rid="B9-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>], are proven to be more accurate and reliable for detecting drowsiness. This accuracy is due to their ability to capture early biological changes that may appear, in the case of drowsiness, thus alerting the driver before any physical drowsiness signs appear. The most commonly used biological measures in literature are listed in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t005/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t005" rid-ob="ob-sensors-22-02069-t005" co-legend-rid=""><span>Table 5</span></a>.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t005"><h3>Table 5</h3><!--caption a7--><div class="caption"><p>Some biological-based measures.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Biological Signals</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electroencephalography (EEG) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B73-sensors-22-02069" rid="B73-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">73</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">An EEG signal is a monitoring method that records the brain’s electrical activity from the scalp. It represents the microscopic activity of the brain’s surface layer underneath the scalp. Based on the frequency ranges (0.1 Hz–100 Hz), these signals are categorized as delta, theta, alpha, beta, and gamma.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrocardiography (ECG) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B74-sensors-22-02069" rid="B74-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">74</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG signals represent the electrical activity of the heart, which are acquired using electrodes placed on the skin. ECG monitors heart functionality, including heart rhythm and rate.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Photoplethysmography (PPG) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B75-sensors-22-02069" rid="B75-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">75</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PPG signals are used to detect blood volume changes. These signals are measured at the skin’s surface using a pulse oximeter. It is often used for heart rate monitoring.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate variability (HRV) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B76-sensors-22-02069" rid="B76-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">76</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">HRV signals are used to monitor the changes in the cardiac cycle, including the heartbeats.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrooculography (EOG) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B77-sensors-22-02069" rid="B77-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">77</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EOG signals are used to measure the corneo-retinal standing potential between the front and back of the human eye and record the eye movements.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electromyography (EMG) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B78-sensors-22-02069" rid="B78-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">78</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EMG signals are the collective electric signals produced from muscles movement.</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253530746128"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t005/?report=objectonly">Open in a separate window</a></div></div><p>This section will cover some of the systems that detect drowsiness using the driver’s biological changes. A summary of these systems is shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t006/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t006" rid-ob="ob-sensors-22-02069-t006" co-legend-rid=""><span>Table 6</span></a>.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t006"><h3>Table 6</h3><!--caption a7--><div class="caption"><p>Biological-based drowsiness detection systems.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Ref.</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Biological Parameters</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sensors</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Extracted Features</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Classification Method</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Quality Metric</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Dataset</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B79-sensors-22-02069" rid="B79-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">79</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Brain activity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Bluetooth-enabled EEG headband and a commercial smartwatch</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relative EEG<br>power ratio (power percentages)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM-based posterior probabilistic model</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A real-time system used an SVM-based posterior probabilistic model to detect and classify drowsiness into three levels.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>Drowsy case: 91.92%<br>Alert case: 91.25%<br>Warning case: 83.78%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B80-sensors-22-02069" rid="B80-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">80</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Brain activity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG<br>(silver surface electrode)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">IMF of the EEG signal</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ANN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection was based on the extraction of the IMFs from the EEG signal by applying the EMD method.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 88.2%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B81-sensors-22-02069" rid="B81-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">81</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG signals and EEG spectrogram images</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG Sensors</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Energy distribution and zero-crossing distribution of the raw EEG signals, in-depth features of the EEG spectrogram, etc.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LSTM network</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG-based drowsiness detection method. It used pre-trained AlexNet and VGG16 models to extract in-depth features from the EEG spectrogram images.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 94.31%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MIT/BIH polysomnographic EEG database [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B83-sensors-22-02069" rid="B83-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">83</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG Sensors</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The first quartile, median, range, and energy of the Hermite coefficients</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ELM decision tree, KNN, least<br>squares SVM, ANN, and<br>naive Bayes</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection was based on an adaptive Hermite decomposition for EEG signals. The Hermite functions were employed as basic functions.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>ELM: 92.28%<br>Sensitivity:<br>ELM: 95.45%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MIT/BIH polysomnographic database [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B85-sensors-22-02069" rid="B85-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">85</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Standard wet-electrode EEG and a cap-type dry-electrodeEEG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Multi-taper power spectral density</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Extreme gradient boosting classifier</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A framework for detecting instantaneous drowsiness with a 2-s length of EEG signal. It was implemented on a wireless and wired EEG to show its applicability in a mobile environment.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>Wired EEG: 78.51%<br>Wireless EEG: 77.22%.<br>Sensitivity:<br>Wired EEG: 78.5%,<br>Wireless EEG: 68.3%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B87-sensors-22-02069" rid="B87-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">87</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG sensors</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F1–F9, extracted from<br>Higuchi fractal dimension, complexity, and mobility characteristics of the<br>original EEG signal, as well as all the EEG sub-bands</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Extra trees classifier</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Employed wavelet packet transform to extract the time domain features from a single-channel EEG signal. Eleven classifiers were tested in this work. The extra trees classifier had the best results.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy, sensitivity, and precision:<br>Dataset1: 94.45%, 95.82%, and 96.14%<br>Dataset2: 85.3%, 79.55%, and 90.02%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dataset1: Fpz-Cz channel dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B89-sensors-22-02069" rid="B89-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">89</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B90-sensors-22-02069" rid="B90-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">90</a>] Dataset2:SVDD dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B91-sensors-22-02069" rid="B91-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">91</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B96-sensors-22-02069" rid="B96-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">96</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG Sensors</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Tsallis entropy, Renyi entropy, permutation entropy, log energy entropy, and Shannon entropy</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Ensemble boosted tree classifier</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used AVMD to analyze and synthesize the EEG signals. By applying statistical analysis, five entropy-based features were selected. Ten classifiers were used, and the ensemble boosted tree classifier achieved the highest accuracy.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>97.19%<br>Sensitivity:<br>97.01%<br>Precision:<br>98.18%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MIT/BIH polysomnographic dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B100-sensors-22-02069" rid="B100-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">100</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate and blood volume changes</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG and PPG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Features obtained from Bin-RP, Cont-RP, and ReLU-RP patterns</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used wearable ECG/PPG sensors to track the different patterns in HRV signals in a simulation environment and used CNN.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Best accuracy, sensitivity, and precision:<br>ECG: 70%, 85%, and 71%<br>PPG: 64%, 78%, and 71%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B101-sensors-22-02069" rid="B101-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">101</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PPG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Frequency measurements (HF, LF, and HF/LF) extracted from PPG signals</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Differentiating between two (HF, LF, and HF/LF) patterns</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection is done by analyzing the changes in PPG signals frequency measurements (HF, LF, and HF/LF) that are obtained from measurements on fingers and earlobes</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 8/9 = 88.8%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B102-sensors-22-02069" rid="B102-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">102</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Wrist-worn wearable sensor<br>and ECG sensor</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">HRV and activity of the autonomic nervous systems</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Random Tree, RF, KNN, SVM, Decision Stump, etc.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection was based on the physiological data extracted from a wrist-worn wearable sensor and ECG sensor. Multiple ML algorithms for binary classification were used</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The highest accuracy was more than 92% for the KNN algorithm</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B103-sensors-22-02069" rid="B103-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">103</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">HRV</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG electrodes</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MeanNN, SDNN, RMSSD, TP, NN50, LF, HF, and LF/HF</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Multivariate statistical process control</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection was based on HRV analysis. Eight HRV features were monitored to detect the changes in HRV using the multivariate statistical process control anomaly detection method. The algorithm was validated by comparing its results with EEG-based sleep scoring.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 92%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B104-sensors-22-02069" rid="B104-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">104</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiration</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Three respiratory inductive plethysmography sensors</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RRV and quality of the respiratory signals</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Thoracic effort-derived drowsiness</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">An algorithm for DDD, based on the respiratory signal variations. It combined the analysis of the RRV and the quality level of the respiratory signals to detect the changes in the driver’s alertness status.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sensitivity: 90.3%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B107-sensors-22-02069" rid="B107-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">107</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG and EMG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Disposable Ag–AgCl electrodes</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Features extracted from the bispectrum of the signals H1, H2, and H3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear discriminant analysis, quadratic discriminant analysis, and KNN classifiers</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detects hypovigilance caused by drowsiness and inattention using ECG and EMG signals. The gathered physiological signals from the experiments were first pre-processed. Then, multiple higher-order spectral features were extracted to be classified.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy and Sensitivity:<br>ECG with KNN: 96.75% and 98%<br>EMG with linear discriminant analysis: 92.31% and 96%<br>Fused features with KNN: 97.06%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B108-sensors-22-02069" rid="B108-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">108</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG and EMG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Two pieces of conductive knit fabric</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EMG peak factor and maximum of the cross-relation curve of ECG and EMG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Discriminant criterion using Mahalanobis distance</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A noncontact onboard DDD system studied the EMG and ECG signals changes during driving. Feature selection was applied using the Kolmogorov–Smirnov Z test.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 86%.<br>Sensitivity: 91.38%<br>Precision: 83.45%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B109-sensors-22-02069" rid="B109-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">109</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG and<br>EEG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Enobio-20 channel device</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG signals time-domain statistical descriptors, complexity measures, power spectral measures, ECG signals HR and HRV’s LF, HF, and LF/HF ratio</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Combined ECG and EEG features to detect drowsiness. After the feature extraction, a paired t-test was only used to select the significant features.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 80.9%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B110-sensors-22-02069" rid="B110-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">110</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG, EOG, ECG</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG, ECG, and EOG electrodes</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG features from the temporal, frontal, and occipital channels<br>EOG features: eyeblink rate<br>ECG feature: blood pressure and heart rate</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear discriminant analysis, linear SVM, kernel SVM, and KNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The fuzzy mutual information-based wavelet packet transform method extracted the features. The features were dimensionally reduced, using spectral regression and kernel-based spectral regression methods. After that, four classifiers were applied.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>Spectral regression: 95%<br>Kernel spectral regression: 97%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253531338464"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t006/?report=objectonly">Open in a separate window</a></div></div><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">1.</div><div>Drowsiness detection using EEG signals</div></li></ul><p>The EEG signals reveal brain activities. They provide valuable information about brain physiology. Such an approach has gained extra attention in the past years because EEG signals can show the changes in the brain activity of a drowsy driver, allowing for early detection of drowsiness.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Smartwatch-based wearable EEG system</div></li></ul>
</div></li></ul><p>Li et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B79-sensors-22-02069" rid="B79-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">79</a>] proposed a driver drowsiness detection system based on EEG signals. The proposed system employs an SVM-based posterior probabilistic model for drowsiness detection, in order to classify the drowsiness states into three categories (alert, drowsy, and early warning). This method is slightly different from other EEG-based detection systems, which generate discrete drowsiness labels, identifying the driver’s state as drowsy or alert. Thus, instead of using discrete labels to identify the driver’s drowsiness level, the SVM-based posterior probabilistic model transforms the drowsiness level to a value between 0 and 1, providing a continuous measure for drowsiness. This work’s fully wearable EEG system included a commercial smartwatch and a Bluetooth-enabled EEG, enabling real-time data evaluation. This system showed different accuracies for each detected state. It obtained a 91.92% accuracy for the drowsy case, 91.25% for the alert case, and 83.78% for the early warning case.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>EEG signal analysis using EMD and trained neural network</div></li></ul>
</div></li></ul><p>Kaur and Singh [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B80-sensors-22-02069" rid="B80-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">80</a>] presented a method to detect driver drowsiness, based on EEG signal analysis, using empirical mode decomposition (EMD) and trained ANN. Kaur and Singh placed silver surface electrodes on the subject’s scalp to extract the EEG signals. In addition, they have used a video camera to provide a drowsiness label, alongside the EEG features. Thus, they produced their own dataset. Then, drowsiness positions in the EEG signals were labeled as drowsy or awake using a utility designed in MATLAB. Afterward, using the EMD method, the intrinsic mode functions (IMFs) were obtained from the labeled EEG data. Finally, the IMFs were used as an input to train the ANN. A total of 70% of samples were used for training, 15% for testing, and 15% for validation. The final classification results showed an accuracy of 88.22%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>EEG features with LTSM</div></li></ul>
</div></li></ul><p>Budak et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B81-sensors-22-02069" rid="B81-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">81</a>] proposed an EEG-based drowsiness detection method that consists of three essential building blocks. The instantaneous frequency and spectral entropy features are extracted from the EEG spectrogram images in the first block. The raw EEG signals are analyzed, as well, to calculate the energy distribution and zero-crossing distribution features. In the second block, using pre-trained AlexNet and VGG16 models, in-depth features are directly extracted from the EEG spectrogram images. As for the third block, the EEG signals are decomposed into related sub-bands, through a tunable Q-factor wavelet transform. The authors then calculate the obtained sub-bands spectrogram images and statistical features, such as the sub-bands instantaneous frequencies’ mean and standard deviation. After processing the three blocks, the extracted feature groups are fed to an LSTM network classifier. The method was trained and evaluated on MIT/BIH polysomnographic EEG dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>]. Specifically, a subset was collected from 16 subjects, with ages and weights of around 43 years and 119 kg, respectively. Finally, the proposed method was evaluated using a 10-fold cross-validation test, obtaining a final average accuracy of 94.31%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Adaptive Hermite decomposition and ELM</div></li></ul>
</div></li></ul><p>Taran and Bajaj [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B83-sensors-22-02069" rid="B83-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">83</a>] presented a DDD method, based on an adaptive Hermite decomposition for EEG signals. In general, Hermite functions help find applications for analyzing nonstationary and complex signals. In this decomposition, the Hermite functions were employed as basic functions, which were selected adaptively using evolutionary optimization algorithms for each EEG signal. The authors used the MIT/BIH polysomnographic database [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>] in their research. The extracted features were taken from the statistical measures of Hermite coefficients, which were first quartile, median, range, and energy. These features were then tested and classified using the extreme learning machine (ELM) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B84-sensors-22-02069" rid="B84-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">84</a>], KNN, decision tree, least-squares SVM, naive Bayes, and ANN classifiers. The ELM classifier obtained the highest accuracy, which was 92.28%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Wired- and wireless-based EEG system</div></li></ul>
</div></li></ul><p>Choi et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B85-sensors-22-02069" rid="B85-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">85</a>] presented a framework for detecting instantaneous drowsiness, with only 2-s EEG signal segments. Multi-taper power spectral density [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B86-sensors-22-02069" rid="B86-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">86</a>] was employed for feature extraction, and an extreme gradient boosting classifier was used for classification. This research defined a novel phenotype labeling method for detecting instantaneous drowsiness. Thus, the labeling was done by combining the psychomotor vigilance task’s advantages as a standard reference and EOG as a task-independent alertness measure. The framework was implemented on a wireless and wired EEG, in order to show the applicability of this mobile environment. The final results showed that the wired EEG gave an accuracy of 78.51%. At the same time, the wireless EEG gave an accuracy of 77.22%. This degradation in the performance is due to the instability of the wireless EEG dry sensors and small amount of EEG data used for training.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Wavelet packet transform employed on EEG</div></li></ul>
</div></li></ul><p>In [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B87-sensors-22-02069" rid="B87-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">87</a>], Phanikrishna and Chinara proposed a new drowsiness detection model that employs wavelet packet transform [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B88-sensors-22-02069" rid="B88-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">88</a>] to extract the time domain features from a single-channel EEG signal. The data used for this work was obtained from the Fpz-Cz channel dataset, a pre-recorded data available on the National Institute of Health [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B89-sensors-22-02069" rid="B89-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">89</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B90-sensors-22-02069" rid="B90-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">90</a>]. Additionally, the simulated virtual driving driver (SVDD) dataset from [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B91-sensors-22-02069" rid="B91-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">91</a>] was utilized. Five sub-bands were extracted from the EEG signal: delta, theta, alpha, beta, and gamma. In the feature extraction stage, the Higuchi fractal dimension [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B92-sensors-22-02069" rid="B92-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">92</a>], mobility [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B93-sensors-22-02069" rid="B93-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">93</a>], and complexity characteristics of the EEG signal, in addition to the EEG sub-bands, extracted in the previous stage, were utilized to compute the values of nine features labeled from F1 to F9. Then, by applying the Mann–Whitney U test [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B94-sensors-22-02069" rid="B94-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">94</a>], followed by Wilkinson’s meta-analysis [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B95-sensors-22-02069" rid="B95-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">95</a>] method, the PComb values were computed for each feature. The features with the lower PComb values were selected for the last stage. Eleven classifiers were tested in this work. Out of the eleven classifiers, extra trees exhibited the best results, with an accuracy of 94.45% for the Fpz-Cz channel and 85.3% for the SVDD dataset.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Entropy-based detection using AVMD</div></li></ul>
</div></li></ul><p>In [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B96-sensors-22-02069" rid="B96-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">96</a>], Khare and Bajaj presented a drowsiness detection method that used adaptive variational mode decomposition (AVMD) to analyze and synthesize the EEG signals. This method utilized the MIT/BIH polysomnographic dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>]. Through the AVMD, the signal is decomposed into several modes. From the adaptively decomposed modes, the features were extracted. By applying statistical analysis, five entropy-based features were selected [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B97-sensors-22-02069" rid="B97-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">97</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B98-sensors-22-02069" rid="B98-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">98</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B99-sensors-22-02069" rid="B99-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">99</a>]: Tsallis entropy, Renyi entropy, permutation entropy, log energy entropy, and Shannon entropy. Then, ten classifiers were used to evaluate the classification accuracy. Among them, the ensemble boosted tree classifier achieved the highest results, with an accuracy of 97.19%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">2.</div><div>Drowsiness detection using ECG, PPG, and HRV signals</div></li></ul><p>ECG is a sensor that senses the heart’s electrical signals, indicating different heart conditions. In contrast, PPG is plethysmography used to detect the blood volume changes in the tissue’s microvascular bed. As for HRV, it refers to the variation in time between consecutive heartbeats.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Wearable ECG/PPG sensors</div></li></ul>
</div></li></ul><p>In 2019, Lee et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B100-sensors-22-02069" rid="B100-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">100</a>] investigated driver’s drowsiness by tracking the distinguishable patterns of HRV signals. Such signals are obtained using wearable ECG or PPG sensors. According to the authors, wearable sensors tend to produce more noise in signals because they are vulnerable to slight movements. Thus, in order to classify the noisy HRV signals as drowsy or not, the authors explored three types of recurrence plots (RPs), obtained from the heartbeats’ R–R intervals (RRI). These RPs are the binary recurrence plot (Bin-RP), continuous recurrence plot (Cont-RP), and thresholded recurrence plot (ReLU-RP), which is acquired by using a modified rectified linear unit (ReLU) function to filter Cont-RP. Each recurrence plot is utilized as an input feature to a CNN. Then, the usefulness of each classification is examined. The study, conducted in a simulation environment, showed that DDD’s most reliable and distinct pattern was the ReLU-RP (using either the ECG sensor or the PPG sensor). ReLU-RP CNN could distinguish between awake and drowsy states better than the other alternatives. PPG signals gave 64% accuracy, 71% precision, 78% recall, and 71% F-score. On the other hand, ECG signals gave 70% accuracy, 71% precision, 85% recall, and 77% F-score. Overall, the ReLU-RP CNN showed an approximately 4 to 14% better accuracy for PPG and 6 to 17% for ECG in classification results, compared to the Bin-RP and Cont-RP results, respectively.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>PPG biosignals and multimodal head support</div></li></ul>
</div></li></ul><p>Koh et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B101-sensors-22-02069" rid="B101-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">101</a>] proposed a method for DDD by employing the high frequency (HF), low frequency (LF), and low to high frequency (LF/HF) values of the PPG signals measured from sensors mounted on fingers and earlobes. The experiments included 20 subjects aged, between the early twenties and late forties. The authors used a driving simulator equipped with two PPG sensors. A sensor was placed to touch the user’s earlobe, and the other was placed on the finger. The collected PPG signals were analyzed using Telescan and KITECH programs to design an algorithm to classify the driver’s drowsiness state. The classification relied on the changes in the extracted LF and HF values. The standard drowsy state criteria were specified by a decrease in LF and LF/HF values and increase in HF value. In contrast, other cases will indicate an awake driver. The results showed a significant difference in PPG signals in the two states.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>DDD using wrist-worn wearable sensor</div></li></ul>
</div></li></ul><p>Kundinger et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B102-sensors-22-02069" rid="B102-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">102</a>] proposed a non-intrusive retrofittable system that detects drowsiness, based solely on physiological data extracted from a wrist-worn wearable sensor. The study was conducted using a simulator, with over 30 subjects. First, the heart rate signals, including the ECG and PPG/ blood volume pulse, were collected and analyzed to get the HRV. Then, the HRV was used to obtain the autonomic nervous systems activity, which gave a more in-depth insight into the drowsiness status. Videos of the driver’s face were recorded to be used for labeling purposes. Multiple ML algorithms for binary classification were used, including random tree, RF, SVM, and decision stump, amongst others. KNN algorithm achieved the highest accuracy, around 92.13%.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>HRV anomaly analysis</div></li></ul>
</div></li></ul><p>Fujiwara et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B103-sensors-22-02069" rid="B103-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">103</a>] proposed an algorithm that uses HRV anomaly analysis to detect drowsiness, based on the fact that changes in alertness levels affect the autonomic nervous system and HRV. The HRV reflects this effect through the RRI fluctuation on the ECG trace. The R wave is the height peak on the ECG, and the RRI is the interval between two consecutive R waves. Using an anomaly detection method, referred to as the multivariate statistical process control method, Fujiwara et al. monitored changes in eight HRV features. These features include the mean of RRI (MeanNN), standard deviation of RRI (SDNN), root means square of the difference of adjacent RRI (RMSSD), total power (which is the variance of RRI) (TP), number of pairs of adjacent RRI spaced by 50 ms or more (NN50), LF, HF, and LF/HF. The proposed algorithm performance was evaluated experimentally in a simulator, with 34 participants. This algorithm was validated by comparing its results with EEG-based sleep scoring. The algorithm showed an accuracy of 92%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">3.</div><div>Drowsiness detection using respiratory signals analysis</div></li></ul><p>Respiratory signals can be used to provide information related to drowsiness. In fact, by tracking the diaphragm, abdomen, and rib cage changes during the respiratory process, the obtained signals can be linked to the driver’s drowsiness state.</p><p>Guede-Fernández et al. proposed a novel algorithm for DDD utilizing respiratory signal variations [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B104-sensors-22-02069" rid="B104-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">104</a>]. In their study, three respiratory inductive plethysmography band sensors were used to guarantee the best tracking quality of the respiratory signals. The study was conducted in a simulator cabin, with twenty volunteers, where 36 tests were done to collect the data. The proposed algorithm depends on analyzing the respiratory rate variability (RRV) to detect the driver’s alertness status changes. Furthermore, another method was used to ensure a quality level of the respiratory signals. Those two methods were combined to reduce the detection errors and formed the thoracic effort-derived drowsiness index algorithm. The system achieved a 90.3% sensitivity and 96.6% specificity.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">4.</div><div>Drowsiness detection using EMG signals</div></li></ul><p>EMG is an electrodiagnostic medicine technique that is utilized to record and evaluate the electrical activities produced by the skeletal muscles [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B105-sensors-22-02069" rid="B105-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">105</a>]. EMG can be used for clinical or biomedical applications, modern human-computer interaction, and evolvable hardware chips [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B106-sensors-22-02069" rid="B106-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">106</a>]. The EMG signals can be analyzed and used to detect medical abnormalities and alertness levels, as well as to analyze the animal or human biomechanics movement.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Hypovigilance detection using higher-order spectra</div></li></ul>
</div></li></ul><p>Sahayadhas et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B107-sensors-22-02069" rid="B107-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">107</a>] developed a system that detects hypovigilance, caused by drowsiness and inattention, using ECG and EMG signals. Inattention was controlled through a series of questions asked to the driver, through messaging or phone calls. On the other hand, drowsiness was controlled by allowing the subjects to drive continuously for 2 h using a simulator game in a controlled laboratory environment. The ECG and EMG data were recorded through disposable Ag–AgCl electrodes. The gathered physiological signals from the experiments were first pre-processed, in order to remove the artifacts and noise. Then, multiple higher-order spectral features were extracted, including the bispectrum, which is the Fourier transform of the second-order moment. From the bispectrum, other features were extracted, such as the (1) sum of the logarithmic amplitudes of the bispectrum (H1), (2) sum of the logarithmic amplitudes of the diagonal elements in the bispectrum (H2), and (3) first-order spectral moment of the amplitudes of diagonal elements in the bispectrum (H3). Furthermore, to enhance the accuracy of the results, the data collected from the two signals were fused using principal component analysis. Next, the extracted features were trained and classified, using linear discriminant analysis, quadratic discriminant analysis, and KNN classifiers. Finally, the bispectral features showed an overall accuracy of 96.75% for the H3 feature from the ECG signal with the KNN classifier. Moreover, an accuracy of 92.31% for the H2 feature from the EMG signal with the linear discriminant analysis classifier was achieved. As for the fused features, the results showed a maximum accuracy of 97.06% using the KNN classifier.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>Fatigue detection using noncontact EMG and ECG system</div></li></ul>
</div></li></ul><p>Fu and Wang [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B108-sensors-22-02069" rid="B108-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">108</a>] proposed a noncontact onboard fatigue detection system that analyzes the changes in the EMG and ECG signals during driving. Fast independent component analysis and digital filters are used to process these signals. Eight volunteers participated in this study, in order to collect data and train the system. The data were gathered using the noncontact data acquisition system, without direct contact with the driver’s skin. The system consisted of two conductive knit fabrics, sewn on the car cushion, that collected the data while the subject was sitting on them. The acquired data were pre-processed to extract the homogeneous signal parts. Then, feature selection was applied using the Kolmogorov–Smirnov Z test, which yields that the EMG peak factor (p &lt; 0.001) and maximum cross-relation curve of ECG and EMG features showed an evident change when the drowsiness state started. To train this model, Mahalanobis distance, a measure of distance based on correlations between variables, was used to obtain discriminant criterion. The system’s final results showed an accuracy of 86%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">5.</div><div>Drowsiness detection with a combination of various biological signals</div></li></ul><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>An approach using EEG and ECG signals</div></li></ul>
</div></li></ul><p>Awais et a. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B109-sensors-22-02069" rid="B109-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">109</a>] proposed a DDD method that combines ECG and EEG features to increase the detection performance. The authors measured the difference between drowsy and alert states, using a dataset from 22 participants in a simulator-based driving environment. During this study, a collection of features was extracted from both EEG and ECG signals. The features extracted from EEG signals included frequency domain absolute and relative powers, as well as time-domain statistical and complexity measures. On the other hand, the features extracted from the ECG signals included the HR and HRV features. After the feature extraction, a paired t-test was used to select significant features only. All features are then combined and fed to an SVM classifier. The results proved that combining the features obtained from both signals outperformed the features obtained from a single type of signal. It also showed that the use of combined EEG/ECG features allowed for reducing the number of electrodes needed. An accuracy of 80.90% was achieved when using a single EEG and ECG electrodes.</p><ul class="simple" style="list-style-type:none"><li><div>
<ul class="unordered" style="list-style-type:disc"><li><div>DDD using EEG, EOG, and ECG signals with fuzzy wavelet packet-based feature-extraction algorithm</div></li></ul>
</div></li></ul><p>Khushaba et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B110-sensors-22-02069" rid="B110-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">110</a>] presented a feature extraction method for extracting the most relevant features to identify the driver drowsiness state. The proposed fuzzy mutual information-based wavelet packet transforms the feature extraction method, and it is aimed to optimize the amount of data, in relation to drowsiness, extracted from EEG, EOG, and ECG signals. These data were used to classify the driver state to one of the predefined drowsiness levels, which are alert (class-1), slightly drowsy (class-2), moderately drowsy (class-3), significantly drowsy (class-4), and extremely drowsy (class-5). The dataset came from 31 volunteers, who used a simulated driving test environment. The video data were rated and labeled using majority voting. Then, the new fuzzy mutual information-based wavelet packet transform method was used to extract the features, including EEG features from the temporal, frontal, and occipital channels, as well as the eyeblink rate, blood pressure, and heart rate. Next, these features were dimensionally reduced using spectral regression-based linear discriminant analysis [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B111-sensors-22-02069" rid="B111-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">111</a>] and kernel-based spectral regression [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B112-sensors-22-02069" rid="B112-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">112</a>] methods. After that, training was applied using four classifiers: linear discriminant analysis, linear SVM, kernel SVM, and KNN. The final results showed that the proposed method achieved an accuracy of 95% with spectral regression and 97% for kernel spectral regression across different classifiers. </p><p class="p p-last"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t006/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t006" rid-ob="ob-sensors-22-02069-t006" co-legend-rid=""><span>Table 6</span></a> reveals that biological-based systems have reported accuracies between 70% and 97.19%, with [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B96-sensors-22-02069" rid="B96-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">96</a>] showing the highest accuracy. Most of them rely on brain activity signals for detection. These systems may be intrusive or invasive, depending on the utilized sensors. Further details are discussed later in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec4-sensors-22-02069" rid="sec4-sensors-22-02069" class=" sec">Section 4</a>. As mentioned earlier, these systems can detect drowsiness at an early stage.</p></div><div id="sec3dot3-sensors-22-02069" class="sec"><h3 id="sec3dot3-sensors-22-02069title">3.3. Vehicle-Based Measures</h3><p class="p p-first">This method depends on tracing and analyzing driving patterns. Every driver forms a unique driving pattern. Thus, the driving patterns of a drowsy driver can be easily distinguished from those of an alert driver. According to Pratama et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B8-sensors-22-02069" rid="B8-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">8</a>], vehicular-based measures are the least investigated methods, due to the difficulty of precisely determining drowsy driving state features. Thus, many researchers combine this measure with image-based or biological measures [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069" rid="B24-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B113-sensors-22-02069" rid="B113-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">113</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B114-sensors-22-02069" rid="B114-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">114</a>]. The two most common detected vehicle-based measures, used to identify driver drowsiness, are steering wheel angle (SWA) and lane departure. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t007/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t007" rid-ob="ob-sensors-22-02069-t007" co-legend-rid=""><span>Table 7</span></a> provides a list of DDD systems based on vehicle measures.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t007"><h3>Table 7</h3><!--caption a7--><div class="caption"><p>Vehicle-based drowsiness detection systems.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Ref.</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Vehicle<br>Parameters</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Extracted Features</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Classification Method</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Quality Metric</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Dataset</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B113-sensors-22-02069" rid="B113-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">113</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Steering wheel</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SWA</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used SWA as input data and compared it with PERCLOS. The RF algorithm was trained by a series of decision trees, with a randomly selected feature.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: RF- steering model:<br>79%<br>PERCLOS: 55%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B114-sensors-22-02069" rid="B114-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">114</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Lateral distance</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Statistical features, derived from the time and wavelet domains, relevant to the lateral distance and lane trajectory</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM and neural network</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection was based on lateral distance. Additionally, it collects data of the driver’s facial and head movements to be used as ground truth for the vehicle data.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>Over 90%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B117-sensors-22-02069" rid="B117-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">117</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Steering wheel</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SWA</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specially designed binary decision classifier</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used SWA data to apply online fatigue detection. The alertness state is determined using a specially designed classifier.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: Drowsy: 84.85%<br>Awake: 78.01%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B118-sensors-22-02069" rid="B118-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">118</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Steering wheel</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SWA, steering wheel velocity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ANFIS for feature selection, PSO for optimizing the ANFIS parameters, and<br>SVM for classification</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Detection was based on steering wheel data. The system used a selection method that utilized ANFIS.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 98.12%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B119-sensors-22-02069" rid="B119-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">119</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Steering wheel</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SW_Range_2, Amp_D2_Theta, PNS, and NMRHOLD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MOL, SVM, and BPNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used steering wheel status data. Using variance analysis, four parameters were selected, based on the correlation level with the driver’s status. MOL model performed best.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>MOL: 72.92%<br>SVM: 63.86%<br>BPNN: 62.10%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253539439840"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t007/?report=objectonly">Open in a separate window</a></div></div><p>As for the SWA, it can be measured using angle sensors that are connected to the steering wheel. However, the way the data are collected may differ from one method to another. Lane departure feature can be acquired by tracking lane curvature, position, or curvature derivative. Below, we present some examples of vehicle-based DDD systems that use these measures.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">1.</div><div>Tracking drowsiness using SWA</div></li></ul><p>McDonald et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B113-sensors-22-02069" rid="B113-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">113</a>] proposed analyzing lane departure using SWA data and the RF algorithm. The authors compared their approach to another image-based drowsiness measure that used PERCLOS. The comparison showed that the SWA measure had higher accuracy, which reached 79% and could detect drowsiness 6 s in advance. At the same time, the PERCLOS method achieved 55% accuracy only. The algorithm was tested using a dataset (72 participants) from a study at the University of Iowa’s National Advanced Driving Simulator [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B115-sensors-22-02069" rid="B115-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">115</a>]. The modified observer rating of drowsiness scale extracted the drowsiness related to lane departure from raw simulator data. The readings were taken every one minute after departing out of the lane. As for the PERCLOS measure, the features were extracted from a video and captured using an eye detecting FaceLab software. Furthermore, the RF algorithm was trained by a series of decision trees, with a randomly selected feature.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">2.</div><div>Lateral distance using wavelet transform and neural network</div></li></ul><p>Ma et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B114-sensors-22-02069" rid="B114-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">114</a>] proposed a model that detects driver drowsiness based on lateral distance. The lateral distance can be acquired from fusing lane curvature, position, and curvature derivative. Those three raw features were obtained using the transportable instrumentation package system [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B116-sensors-22-02069" rid="B116-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">116</a>], with a video camera placed on the car’s front bumper. Moreover, this system uses real-time video recording to collect the driver’s facial and head movements data. The driver’s visual data were used as ground truth for the car’s data. The recorded car data was fed to TRW’s simulator, in order to extract lane-related signals in the frequency and time domain. After that, the signals were analyzed, along with the acquired footage of the driver’s face. Then, the data were fed to SVM and neural network algorithms for classification. As for the experimental results, all classification methods showed a detection accuracy higher than 90%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">3.</div><div>Entropy features from SWA time series</div></li></ul><p>This system uses SWA data to apply online fatigue detection. The data were collected from a sensor settled on the steering lever for 14.68 h and under real driving conditions. Li et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B117-sensors-22-02069" rid="B117-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">117</a>] proposed a system that uses a fixed sliding window to extract the approximate entropy features from a SWAs time series data. Then, the approximate entropy features series are linearized, using an adaptive piecewise linear fitting, with a specific deviation. Then, the system calculates the warping distance between the linear features series to determine the driver’s alertness state. Finally, the alertness state, either “drowsy” or “awake,” is determined using a specially designed binary decision classifier. The system’s experimental results showed an accuracy of 84.85% for true detections of the “drowsy state” and 78.01% for the “awake” state’s true detections.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">4.</div><div>ANFIS based steering wheel feature selection</div></li></ul><p>Arefnezhad et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B118-sensors-22-02069" rid="B118-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">118</a>] presented a non-invasive DDD system based on steering wheel data. The system aimed to increase classification accuracy using feature selection strategies. The proposed selection method used adaptive neuro-fuzzy inference systems (ANFIS), a combination of filters and wrapper feature selection algorithms. The study was conducted in a simulated driving environment involving 39 bus drivers, resulting in a new dataset. Thirty-six features were extracted from the steering wheel data. These features were applied to four different filter indices. The output of each filter was fed to the fuzzy system to select the most important features. Then, an SVM classifier is used to classify the selected features and specify the drivers’ state. Finally, using a particle swarm optimization method, the classifier’s accuracy is used to optimize the parameters of the ANFIS. The final results showed an accuracy of 98.12%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">5.</div><div>DDD based on steering wheel status</div></li></ul><p>Chai et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B119-sensors-22-02069" rid="B119-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">119</a>] presented a study on drowsiness monitoring, using data relating to steering wheel status. They used a driving simulator to collect 11 parameters for the steering wheel. Based on the correlation level with driver’s status, four parameters were selected:</p><ul class="unordered" style="list-style-type:disc"><li><div>SW_Range_2: steering wheel angular velocity percentage in the range of 2.5–5°/s.</div></li><li><div>Amp_D2_Theta: the area between the SWA, θ; the mean of θ is multiplied by the time the SWA is on the same side of the mean of θ.</div></li><li><div>PNS: proportion of the time that the steering wheel remains stationary (±0.1°).</div></li><li><div>NMRHOLD: number of times the steering wheel is held steady (within a certain threshold angle) for longer than 0.04 s. Steady means that the change in angle is lower than ±0.5°.</div></li></ul><p></p><p>Three models were then built for drowsiness detection based on these parameters: a multilevel ordered logit (MOL) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B120-sensors-22-02069" rid="B120-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">120</a>], SVM, and back propagation neural network (BPNN) model. Under the same classification conditions, the results showed that the MOL model had achieved an accuracy of 72.92%, much higher than the others. Thus, the authors concluded that using these four parameters, while considering the differences of individuals, the MOL model has outperformed the other two models.</p><p class="p p-last"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t007/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t007" rid-ob="ob-sensors-22-02069-t007" co-legend-rid=""><span>Table 7</span></a> reveals that vehicle-based systems have reported accuracies between 62.1% and 98.12%, with [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B118-sensors-22-02069" rid="B118-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">118</a>] showing the highest accuracy. Most of them rely on the SWA feature. Generally, these systems are non-intrusive and -invasive.</p></div><div id="sec3dot4-sensors-22-02069" class="sec sec-last"><h3 id="sec3dot4-sensors-22-02069title">3.4. Hybrid-Based Measures</h3><p class="p p-first">A hybrid DDD system employs a combination of image-, biological-, and vehicle-based measures to extract drowsiness features, with the aim of producing a more robust, accurate, and reliable DDD system. This subsection presents some of the recently proposed hybrid DDD systems. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t008/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t008" rid-ob="ob-sensors-22-02069-t008" co-legend-rid=""><span>Table 8</span></a> shows a list of those systems.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t008"><h3>Table 8</h3><!--caption a7--><div class="caption"><p>Hybrid-based drowsiness detection systems.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Ref.</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sensors</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hybrid<br>Parameters</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Extracted Features</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Classification Method</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Quality Metric</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Dataset</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069" rid="B24-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Automatic gearbox, image-generating computers, and control-loaded steering system</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Image- and vehicle-based features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Latera position, yaw angle, speed, steering angle, driver’s input torque, eyelid opening degree, etc.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A series of mathematical operations, specified schemes from the study hypothesis</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A system that assists the driver in case drowsiness is detected to prevent lane departure. It gives the driver a specific duration of time to control the car. If not, the system controls the vehicle and parks it.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracies up to 100% in taking control of the car when the specified driving conditions were met</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B28-sensors-22-02069" rid="B28-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">28</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PPG, sensor, accelerometer, and gyroscope</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological- and vehicle-based features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate, stress level, respiratory rate, adjustment counter, and pulse rate variability, steering wheel’s linear acceleration, and radian speed</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">It collected data from the sensors. Then, the features were extracted and fed to the SVM algorithm. If determined drowsy, the driver is alerted via the watch’s alarm.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 98.3%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B121-sensors-22-02069" rid="B121-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">121</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Smartphone camera</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological- and image-based features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Blood volume pulse, blinking duration and frequency, HRV, and yawning frequency</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">If any of the detected parameters showed a specific change/value</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used a multichannel second-order blind identification based on the extended-PPG in a smartphone to extract blood volume pulse, yawning, and blinking signals.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sensitivity: Up to 94%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B29-sensors-22-02069" rid="B29-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">29</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Headband, equipped with EEG electrodes, accelerometer, and<br>gyroscope</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological- and behavioral-based features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Eyeblink patterns analysis, head movement angle, and magnitude, and spectral power analysis</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Backward feature selection method applied followed by various classifiers</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used a non-invasive and wearable headband that contains three sensors. This system combines the features extracted from the head movement analysis, eye blinking, and spectral signals. The features are then fed to a feature selection block followed by various classification methods. Linear SVM performed the best.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy, sensitivity, and precision:<br>Linear SVM: 86.5%, 88%, and 84.6%<br>Linear SVM after feature selection: 92%, 88%, and 95.6%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B122-sensors-22-02069" rid="B122-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">122</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SCANeR Studio, faceLAB, electrocardiogram, PPG sensor,<br>electro-dermal activity, Biopac MP150 system, and AcqKnowledge software</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological-, image-, and vehicle-based features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate and variability, respiration rate, blink duration, frequency, <br>PERCLOS, head and eyelid movements, time-to-lane-crossing, position on the lane, speed, and SWA</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ANN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Included two models that used ANN. One is for detecting the drowsiness degree, and the other is for predicting the time needed to reach a specific drowsiness level. Different combinations of the features were tested.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Overall mean square error of 0.22 for predicting various drowsiness levels<br>Overall mean square error of 4.18 min for predicting when a specific drowsiness level will be reached</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B123-sensors-22-02069" rid="B123-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">123</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG, EOG, ECG<br>electrodes, and channels</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological-based features and NIRS</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Heart rate, alpha and beta bands power, blinking rate, and eye closure duration</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Fisher’s linear discriminant analysis method</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A new approach that combined EEG and NIRS to detect driver drowsiness. The most informative parameters were the frontal beta band and the oxygenation. As for classification, Fisher’s linear discriminant analysis method was used. Additionally, time series analysis was employed to predict drowsiness.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 79.2%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MIT/BIH polysomnographic database [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069" rid="B82-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">82</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B124-sensors-22-02069" rid="B124-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">124</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Multi-channel amplifier with active electrodes, projection screen, and touch screen</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological-based features and contextual information</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EEG signal: power spectra, five frequency characteristics, along with four power ratiosEOG signal: blinking duration and PERCLOS contextual information: the driving conditions (lighting condition and driving environment) and sleep/wake predictor value.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">KNN, SVM, case-based reasoning, and RF</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Used EOG, EEG, and contextual information. The scheme contained five sub-modules. Overall, the SVM classifier showed the best performance.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy:<br>SVM multiclass classification: 79%<br>SVM binary classification: 93%<br>Sensitivity:<br>SVM multiclass classification: 74%<br>SVM binary classification: 94%.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own data</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B125-sensors-22-02069" rid="B125-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">125</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Smartphone</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Image-based features, as well as voice and touch information</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PERCLOS, vocal data, touch response data</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Utilized a smartphone for DDD. The system used three verification stages in the process of detection. If drowsiness is verified, an alarm will be initiated.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy: 93.33%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset called ‘Invedrifac’ [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B126-sensors-22-02069" rid="B126-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">126</a>]</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B127-sensors-22-02069" rid="B127-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">127</a>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Driving simulator and monitoring system</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Biological-, image-, and vehicle-based features</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80 features were extracted: PERCLOS, SWA, LF/HF, etc.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF and majority voting (logistic regression, SVM, KNN) classifiers</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Vehicle-based, physiological, and behavioral signs were used in this system. Two ways for labeling the driver’s drowsiness state were used, slightly drowsy and moderately drowsy.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy, sensitivity, and precision:<br>RF classifier:<br>Slightly drowsy labeling: 82.4%, 84.1%, and 81.6%<br>Majority voting:<br>Moderately drowsy labeling: 95.4%, 92.9%, and 97.1%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prepared their own dataset</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253538673488"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t008/?report=objectonly">Open in a separate window</a></div></div><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">1.</div><div>Driver assistance system, based on image- and vehicle-based features</div></li></ul><p>Saito et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069" rid="B24-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>] presented a driver assistance system with a dual control scheme. This system effectively identifies driver drowsiness based on eyelid’s state, steering wheel, and lane departure and takes control of the car, if needed. The assistance system initiates a partial control of the vehicle, in the case of a lane departure. The system gives the driver a chance to control the car and center it in the lane. If the driver does not take control of the vehicle within a specific time duration, the system assumes that the driver is unable to drive or is asleep. Thus, the system will take control and park the car. Twenty participants took part in this study. The data were mainly collected when the proposed assistance system was active. The driver status was determined through a series of mathematical operations and specified schemes from the study hypothesis. The study results showed accuracies of up to 100% in taking control of the car when the specified driving conditions were met.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">2.</div><div>Biomedical and motion sensors</div></li></ul><p>Leng et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B28-sensors-22-02069" rid="B28-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">28</a>] proposed a wearable device that uses motion and biomedical sensors to detect drowsiness using a mobile application. The system combines both drivers’ biosignals and vehicle measures to get an accurate result. It uses a self-designed wristband to detect biosignals and motion sensors to detect steering wheel movement. The wristband contains two main components: galvanic skin response and photoplethysmogram sensors that detect PPG signals. Additionally, a smartwatch’s built-in accelerometer and gyroscope sensors are used to detect the steering wheel’s linear acceleration and radian speed. Thus, the system starts by collecting data from the sensors. Then, the collected data are passed to the smartwatch, where they are processed and analyzed. After that, five features are extracted from the received biological raw data: heart rate, stress level, respiratory rate, adjustment counter, and pulse rate variability. Next, these five features, along with the steering wheel data, are fed to an SVM algorithm to detect the driver’s drowsiness state. After getting the classification result, the smartwatch alerts the driver, through a visual and vibration alarm. The system resulted in an accuracy of 98.3%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">3.</div><div>Yawning, blinking, and blood volume pulse-based method</div></li></ul><p>Yawning, blinking, and heart rate change can provide clues about the driver’s mental state. Based on that fact, Zhang et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B121-sensors-22-02069" rid="B121-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">121</a>] proposed a DDD system that uses a smartphone’s camera as a non-contact optical sensor. The system captures image sequences and uses them as raw data to extract blink and yawn signals. Additionally, the extended-PPG signals, obtained from the image sequence, enable extracting blood volume pulse, without direct contact with the person under consideration. Using a multichannel second-order blind identification, the blood volume pulse, yawning, and blinking signals are simultaneously extracted from smartphone videos. The combined signals are then analyzed to estimate the blinking duration and frequency, HRV, and yawning frequency. Should any of the estimated parameters show a specific value, then drowsiness will be declared, and an alarm will sound from the phone. The system showed different sensitivity values, ranging up to 94%. </p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">4.</div><div>EEG signals’ spectral, head movement, and blink analysis</div></li></ul><p>Mehreen et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B29-sensors-22-02069" rid="B29-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">29</a>] extracted the drivers’ behavioral and biological features, using a lightweight, non-invasive, wearable headband to replace cameras and intrusive sensors in DDD systems. The proposed DDD system uses a combination of signals, acquired from a headband equipped with an accelerometer, gyroscope, and EEG electrodes. The dataset was collected in both drowsy and fresh state conditions, with the help of 50 volunteers, using a driving simulator. To increase the robustness and acquire better accuracy results, the authors combined the features extracted from the head movement analysis, eye blinking, and spectral signals to make a feature vector. The backward feature selection method was then applied on the feature vector over various classifiers. When fed with the whole feature vector, the linear SVM performed the best, with an accuracy of 86.5% before feature selection and 92% after feature selection was applied.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">5.</div><div>DDD using image-, biological-, and vehicle-based features fusion</div></li></ul><p>De Naurois et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B122-sensors-22-02069" rid="B122-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">122</a>] investigated the possibility of predicting when a drowsiness level is reached by utilizing the same information used to determine drowsiness. Furthermore, they explored whether including additional data, such as the participant information and driving time, would improve the detection and prediction accuracy. Using a car simulator, 21 participants drove for 110 min, under special conditions that induced drowsiness. The researchers measured biological, behavioral, and vehicle drowsiness features. Such features include heart rate and variability, respiration rate, blink duration, frequency, PERCLOS, head and eyelid movements, time-to-lane-crossing, position on the lane, speed, and SWA. Two models that use ANN were developed, one for detecting the drowsiness degree, and the other is for predicting the time needed to reach a specific drowsiness level. Both models ran every minute. Different combinations of the features were tested during this study. Finally, the models showed that it could detect drowsiness levels (with a mean square error of 0.22) and predict the time to reach a specified drowsiness level (with a mean square error of 4.18 min).</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">6.</div><div>Combined EEG/NIRS DDD system</div></li></ul><p>In their study, Nguyen et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B123-sensors-22-02069" rid="B123-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">123</a>] introduced an approach that combines EEG and near-infrared spectroscopy (NIRS) to detect driver drowsiness. NIRS is a spectroscopic method that utilizes the electromagnetic spectrum near-infrared region. Multiple biological signals were recorded during a simulated driving task over nine subjects. These measurements included the neuronal electrical activity (using EEG signals), tissue oxygenation (using NIRS), eye movement (using EOG signals), and heart rate using (ECG signals). The features studied to determine the drowsiness state included heart rate, alpha and beta bands power, blinking rate, and eye closure duration. Statistical tests showed that the frontal beta band and oxygenation change showed the most significant difference between the alert and drowsy states and thus were chosen as the most relevant parameters from the EEG and NIRS signals for the study. Fisher’s linear discriminant analysis method was used for driver’s state classification. In addition, the time series analysis was employed to predict drowsiness. Although multimodal data were collected, only EEG and NIRS were used for further analysis because the other data did not clearly correspond to the drivers’ alertness state changes. The proposed system resulted in an accuracy of 79.2%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">7.</div><div>DDD using EEG, EOG, and contextual information</div></li></ul><p>In this study, Barua et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B124-sensors-22-02069" rid="B124-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">124</a>] proposed an automatic sleepiness detection scheme using EOG, EEG, and contextual information. The features extracted from the EEG signal power spectra included five frequency characteristics and four power ratios. Blinking duration and PERCLOS were calculated from the EOG signal. The contextual information features used in the proposed system included driving conditions, such as the lighting condition and driving environment, along with the sleep/wake predictor value. Three feature selection algorithms were employed to select the most suitable feature combination from the abovementioned features pools. These algorithms were the univariate feature selection method, sequential forward floating selection wrapper method, and minimum redundancy maximum relevance method. KNN, SVM, case-based reasoning, and RF were used for classification. The authors considered two classification cases: multiclass classification (alert, somewhat sleepy, or sleepy) and binary classification (alert or sleepy). </p><p>The study used data from 30 drivers, who used a driving simulator. Overall, the SVM classifier showed the best performance, with 79% accuracy for the multiclass classification and 93% for binary classification. The study clearly showed that adding contextual information to the signals data boosted the classification accuracy by 4% and 5% for multiclass and binary classification, respectively.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">8.</div><div>DDD with a smartphone</div></li></ul><p>Dasgupta et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B125-sensors-22-02069" rid="B125-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">125</a>] proposed a DDD and warning system using a smartphone. This proposed system was one of the first attempts to combine voice cues with PERCLOS to detect drowsiness. Thus, they have prepared their own dataset, called the Invedrifac dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B126-sensors-22-02069" rid="B126-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">126</a>]. The presented work uses three verification stages in the process of detection. The first stage computes the PERCLOS feature, obtained from a smartphone’s front camera images. If the PERCLOS value crosses a certain threshold, the system initiates the second stage by requesting the driver say his full name. Having been labeled a drowsy driver in the first two stages, the system asks the driver to tap the smartphone screen within 10 s. If the condition is not met, drowsiness is verified, and an alarm is initiated. The proposed framework used a linear SVM classifier and resulted in a final accuracy of 93.33%.</p><ul class="simple" style="list-style-type:none"><li class="a_label"><div class="inline_block a_label">9.</div><div>DDD using ensemble ML and hybrid sensing</div></li></ul><p>In [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B127-sensors-22-02069" rid="B127-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">127</a>], Gwak et al. investigated the feasibility of detecting early drowsiness based on hybrid measures, namely vehicle-based, physiological, and behavioral signs, to implement a detection system. Sixteen participants were involved in this study. A total of 80 features were extracted from the measured data and videos. The study consisted of three main parts. In the first part, the drivers’ physiological signals, driving performance, and behavioral drowsiness signs were recorded, using a driving simulator and monitoring system. Then, classification was performed using two different classification methods: RF classifier and majority voting, using logistic regression, SVM, and KNN. In the case of majority voting, sequential backward feature selection was performed, and then classification was applied. On the other hand, in the case of RF, the number of estimators and features used was optimized to get better classification performance. Finally, the performance of the algorithms was evaluated. This study, which followed Zilberg’s criteria [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B128-sensors-22-02069" rid="B128-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">128</a>] in labeling the drowsiness levels, has focused on differentiating between alert and slightly drowsy and alert and moderately drowsy states. The results showed that the RF classifier gave the best results, with 82.4% accuracy of alert vs slightly drowsy case. In contrast, majority voting performed the best for alert vs moderately drowsy case, at an accuracy of 95.4%.</p><p class="p p-last"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t008/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t008" rid-ob="ob-sensors-22-02069-t008" co-legend-rid=""><span>Table 8</span></a> reveals that hybrid-based systems have reported accuracies between 79% and 99%, with [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069" rid="B24-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>] showing the highest accuracy. Most of them rely on at least one biological feature for detection. This type of system may be intrusive or invasive, depending on the features they use. Hybrid-based systems’ advantages and challenges rely on the combination of features they utilize to detect drowsiness. Further details are discussed in the following section. </p></div></div><div id="sec4-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec4-sensors-22-02069title">4. Challenges</h2><p class="p p-first">Since the launching of Volvo’s first DDD system in 2007 [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B129-sensors-22-02069" rid="B129-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">129</a>], the technology has evolved tremendously. However, there are still many challenges and issues that face researchers. In this section, we discuss the challenges in detecting drivers’ drowsiness.</p><p>Most researchers generally apply their studies in a virtual or simulated environment and build their final system results based on the simulation output. However, those results do not necessarily represent real-life driving situations. Moreover, in such simulated environments, the study is narrowed by specific drowsiness scenarios, eliminating the vast range of possibilities and conditions a driver faces in real-life scenarios, which, in return, affects the system reported accuracy [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B17-sensors-22-02069" rid="B17-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">17</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B33-sensors-22-02069" rid="B33-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">33</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B59-sensors-22-02069" rid="B59-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">59</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B63-sensors-22-02069" rid="B63-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">63</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069" rid="B68-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">68</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B121-sensors-22-02069" rid="B121-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">121</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B123-sensors-22-02069" rid="B123-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">123</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B127-sensors-22-02069" rid="B127-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">127</a>]. Such issues may be overcome by validating the system’s results through equivalent testing in real-life driving sessions.</p><p>The major challenge of image-based DDD systems is the struggle to track and recognize high-quality head and facial data. This challenge is due to the dependence on the efficiency and quality of the used equipment, as well as the driver and environmental conditions. Other issues associated with such systems are the presence of additional features on the face, such as sunglasses, a beard, or a mustache, that may cover the eye or mouth and lead to a system failure. Additional challenges include the random head movement [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B38-sensors-22-02069" rid="B38-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">38</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B41-sensors-22-02069" rid="B41-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">41</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B52-sensors-22-02069" rid="B52-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">52</a>], different skin colors, various lighting conditions [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B55-sensors-22-02069" rid="B55-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">55</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B130-sensors-22-02069" rid="B130-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">130</a>], face’s distance from the camera, different face structure based on race, and real-time video analysis that require powerful computing resources [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B103-sensors-22-02069" rid="B103-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">103</a>]. All of that may reduce the accuracy or even lead to false detection.</p><p>As for the biological-based systems, the studies show that such systems are the most accurate in detecting early drowsiness signs. However, the main issue with such systems is the equipment and sensors associated with them. Such equipment types are not comfortable, in some cases, as they must be attached to the driver’s body during the journey. Additionally, the used biological sensors are vulnerable to slight movement, which may produce some noise in the extracted signals, reducing the accuracy [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B100-sensors-22-02069" rid="B100-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">100</a>]. </p><p>Another challenge that may specifically affect biological- and hybrid-based systems is the hardware complexity and limitations. For example, in [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B85-sensors-22-02069" rid="B85-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">85</a>], the system faced technical challenges, including hardware and compatibility issues. The wireless EEG hardware could not collect as much data as the wired EEG did, partly because of the instability of the used dry electrodes. Additionally, the EOG sensor R100 that was used in the experiment had compatibility issues with the used wireless EEG system. They could not be used simultaneously because of interference. Moreover, in [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B124-sensors-22-02069" rid="B124-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">124</a>], Barua et al. pointed out that measuring EEG signals alone in a real driving scenario could lead to features that are not reliable enough to produce high accuracy. They added that more complex sensors need to be employed for better system performance, in order to provide multimodal information, i.e., additional features that can enhance accurate sleepiness detection.</p><p>In comparison, three significant challenges face vehicle-based DDD systems. First, weather conditions. If a driver is driving in harsh weather, with strong wind or rain, the car will naturally deviate out of the lane, leading the system to generate false results. Another challenge is the geometric conditions of roads. In some cases, the driver may drive on a steep and bumpy road, causing the car to vibrate, divert, and the steering wheel to shake, causing the collected data to become unreliable. Furthermore, some vehicle-based systems do not extract drowsiness signs precisely, leading to inaccurate detection results. Thus, many systems use an additional measure with vehicle measures, in oder to increase the system’s accuracy. </p><p>Nevertheless, many future research directions address these issues to enhance the accuracy of these systems. For example, recent research [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B121-sensors-22-02069" rid="B121-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">121</a>] uses some lightweight sensors or analyzes biological signals based on video data, which does not require direct contact with the driver and maintains a high accuracy rate at the same time. Such an approach eases the detection process and shows a promising future for such systems. Besides, more and more systems are designed with hybrid measures that give not only higher accuracy but also each separate measure in such systems complement each other, which increases the system’s efficiency.</p><p>Inspired by [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B131-sensors-22-02069" rid="B131-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">131</a>], we attempt in this work to quantitatively describe the challenges facing DDD systems. The challenges are summarized and listed in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t009/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t009" rid-ob="ob-sensors-22-02069-t009" co-legend-rid=""><span>Table 9</span></a>, against the three principal DDD systems. Each challenge in the table is labeled as low, medium, high, or not applicable (N/A), in order to describe the significance level of that challenge on the performance of each DDD system type. Hybrid DDD systems are a combination of the other three systems. Thus, they were not included in the table, since the listed challenges may impact them in various degrees.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t009"><h3>Table 9</h3><!--caption a7--><div class="caption"><p>DDD systems challenges.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th align="right" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">System Type</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Imaged-Based</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Biological-Based</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Vehicle-Based</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Challenges </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th></tr></thead><tbody><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Difficulty in extracting drowsiness signs, due to facial characteristics/skin color</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Difficulty in extracting drowsiness signs, due to objects that cover the face</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Driver’s posture and distance from the dashboard</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Real-time video analysis</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medium</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Driver movement</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N/A</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Noisy sensor measurements</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Monitoring equipment and sensors inconvenience</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medium</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Influence of environmental conditions (weather/illumination)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medium</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Influence of the road conditions and geometry </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Hardware complexity and limitations</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Drowsiness signs extraction precision</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Testing under real (not simulated) driving conditions</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medium</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medium</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medium</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253539113040"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t009/?report=objectonly">Open in a separate window</a></div></div><p class="p p-last"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t009/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t009" rid-ob="ob-sensors-22-02069-t009" co-legend-rid=""><span>Table 9</span></a> shows that the challenges facing the image-based systems are mainly related to the face region, which is the region of interest, where most features are extracted. On the other hand, the biological-based system’s challenges relate to the used equipment and hardware setup. In contrast, vehicle-based systems have fewer challenges, with the main one being the inability to extract drowsiness signs precisely. Therefore, using vehicle-based techniques with other measures would result in a more reliable hybrid system.</p></div><div id="sec5-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec5-sensors-22-02069title">5. Discussion</h2><p class="p p-first">A thorough literature review showed that various methods implement drowsiness detection and terminate possible hazards while driving. Moreover, the technological development and continuous advancement in the artificial intelligence domain solved many challenges faced by such systems and enhanced their performance. This section compares the DDD systems, in terms of their practicality and reliability, as reported in the literature, and discusses the four drowsiness detection measures mentioned previously. System practicality describes the system’s effectiveness, in terms of invasiveness, intrusiveness, cost, ease of use, and accuracy, in detecting true drowsiness states. Intrusive systems stand for systems that use sensors with probes that are attached to the surface of the human body. In contrast, invasive systems refer to systems that use invasive sensors, where the probe must enter the human body and come into contact with bodily fluid. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t010/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t010" rid-ob="ob-sensors-22-02069-t010" co-legend-rid=""><span>Table 10</span></a> summarizes the practical characteristics of each of the four types of DDD systems.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="sensors-22-02069-t010"><h3>Table 10</h3><!--caption a7--><div class="caption"><p>DDD systems comparison, based on practicality.</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th align="right" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Practicality<br>Features</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Intrusiveness</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Invasiveness</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Reported Accuracies in DDD Literature</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Cost</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Ease of Use</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DDD Systems<br>Types</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th></tr></thead><tbody><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Image-based systems</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Non-intrusive</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Non-invasive</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High accuracy, between 72.25–99.59%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Generally low-cost</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Automatic—no required set up or user intervention</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Biological-based systems</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Depends on the hardware and method used</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Depends on the hardware and method used</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High accuracy, between 70–97.19%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Expensive when high-quality sensors are used</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May require set up, user intervention, or wearing sensors</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Vehicle-based systems</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Non-intrusive</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Non-invasive</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Low accuracy, as low as 62.1%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mostly comes as an expensive car accessory</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Automatic—no required set up or user intervention</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Hybrid-based systems</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Depends on the hardware and method used</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Depends on the hardware and method used</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High accuracy, between 79–99%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Cost depends on the used hardware</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May require set up, user intervention, or wearing sensors</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140253580583072"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t010/?report=objectonly">Open in a separate window</a></div></div><p>The first type, image-based systems, are generally considered practical because they are non-intrusive, non-invasive systems, as well as cost-efficient and automatic, in the sense that there is no need to set up any sensor each time the system is used. Such systems use various types of cameras, such as webcams [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B39-sensors-22-02069" rid="B39-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">39</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B49-sensors-22-02069" rid="B49-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">49</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B54-sensors-22-02069" rid="B54-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">54</a>], smartphone cameras [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B121-sensors-22-02069" rid="B121-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">121</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B125-sensors-22-02069" rid="B125-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">125</a>], or thermal cameras [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B16-sensors-22-02069" rid="B16-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">16</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B38-sensors-22-02069" rid="B38-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">38</a>]. The cameras are set at a specific distance from the driver to collect data without obstructing the driver’s view. In terms of detection accuracy, the DDD image-based systems differ in their results. Since they monitor features that are highly correlated to drowsiness, such as yawning, blinking, head movement, and eye closure, most of them have achieved high accuracy, between 85% to 99%, as shown in systems [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B17-sensors-22-02069" rid="B17-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">17</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B52-sensors-22-02069" rid="B52-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">52</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B54-sensors-22-02069" rid="B54-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">54</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B55-sensors-22-02069" rid="B55-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">55</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B59-sensors-22-02069" rid="B59-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">59</a>]. However, it should be noted that such systems are affected by multiple factors, as mentioned previously in the challenges section, and are often implemented and tested in a controlled environment or using existing DDD video datasets [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B30-sensors-22-02069" rid="B30-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">30</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B33-sensors-22-02069" rid="B33-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">33</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B49-sensors-22-02069" rid="B49-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">49</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B59-sensors-22-02069" rid="B59-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">59</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B63-sensors-22-02069" rid="B63-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">63</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069" rid="B68-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">68</a>]. Thus, the drowsiness signs are mostly simulated, where the driver is asked to mimic specific signs during the data collection part. Hence, all of these factors reduce the reliability of the image-based systems.</p><p>The second type is biological-based DDD systems. The practicality characteristics of such systems are based on the sensors used to detect the targeted biological feature. Such sensors are usually required to be set up every time they are used, and if they were high-quality, they would be costly. In terms of intrusiveness and invasiveness, various types of sensors are used in such systems, and these characteristics differ, based on the used one. Take, for example, systems [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B85-sensors-22-02069" rid="B85-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">85</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B103-sensors-22-02069" rid="B103-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">103</a>], where they require the driver to put electrodes on the scalp before driving. In this case, these systems are considered invasive and intrusive, making them impractical because it is burdensome for drivers to keep them attached while driving. In comparison, systems [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B79-sensors-22-02069" rid="B79-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">79</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B100-sensors-22-02069" rid="B100-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">100</a>] have used devices like a headband with sensors or a smartwatch, which are biological devices that can easily be worn and attached to the driver’s head and arm for data collection. Those devices are non-invasive and intrusive and do not disturb or obstruct the driver. Nonetheless, other biological-based systems were designed more comfortably and did not require the driver to put them on before driving. Such systems use sensors attached to the seat or steering wheel, making them comfortable for long rides. Examples include systems [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B101-sensors-22-02069" rid="B101-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">101</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B108-sensors-22-02069" rid="B108-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">108</a>]. </p><p>In [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B101-sensors-22-02069" rid="B101-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">101</a>], a head support that contains PPG sensors to measure the pulse was connected to the simulator chair. While in [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B108-sensors-22-02069" rid="B108-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">108</a>], Fu and Wang used two pieces of conductive knit fabric that was sewed to the seat cushion. The fabric collected data, while the driver was seated. Regardless of the hardware or method implemented for drowsiness detection, the accuracy of the biological-based systems tends to be high. These systems trace the human body’s biological signals that reflect the very initial changes in the human alertness state, which allows them to make an accurate detection when the drowsiness signs appear. The accuracies of the reviewed biological-based systems were between 77–97%. Thus, unlike image-based systems, biological-based systems are considered highly reliable, when it comes to detecting real-time drowsiness.</p><p>In the third type, vehicle-based systems, these systems take their readings from vehicle-related parameters, as the name implies. Thus, they are also non-intrusive and -invasive systems. Furthermore, like image-based systems, they automatically start the detection process, without the need for initial preparations, but their cost differs, depending on the sensor used. In terms of the final accuracy, vehicle-based systems have scored the lowest accuracy, compared to other types of systems. For example, systems [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B117-sensors-22-02069" rid="B117-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">117</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B119-sensors-22-02069" rid="B119-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">119</a>], in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t007/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t007" rid-ob="ob-sensors-22-02069-t007" co-legend-rid=""><span>Table 7</span></a>, have shown an accuracy of 78% and 62.1%, respectively. Nevertheless, such systems did not obstruct the driver in any way. However, this type of system is the least reliable for detecting drowsiness, due to the type of features they track, such as SWA and lane departure. Such features cannot solely detect drowsiness accurately.</p><p>In some studies, researchers used additional measures to enhance the effectiveness of vehicle-based systems. Such systems have resulted in the fourth type of DDD systems, which we referred to as hybrid-based systems. As mentioned before, hybrid systems have many combinations using vehicle-, image-, biological-, image-based measures, etc. These systems may be intrusive or invasive, easy to use, or costly, depending on the measures combined and hardware used. For example, in [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B29-sensors-22-02069" rid="B29-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">29</a>], the authors have used a non-invasive and wearable headband that contains three sensors to detect the EEG signals, head movement, and blinking. Thus, this system has reduced the detection surface, where the sensors can be placed into one headband. However, the head band must be worn at all the time during the ride, which may be uncomfortable for the driver. As shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/table/sensors-22-02069-t010/" target="table" class="fig-table-link figpopup" rid-figpopup="sensors-22-02069-t010" rid-ob="ob-sensors-22-02069-t010" co-legend-rid=""><span>Table 10</span></a>, most of the hybrid-based DDD systems have achieved accuracy exceeding 85%, which indicates the effectiveness and practicality of such systems.</p><p>Overall, according to the literature, image-based systems gave more than 90% accuracy within a simulated testing environment or using an existing dataset. This measure has proven reliable in detecting drowsiness, once visual signs start appearing. However, being implemented in a controlled environment is a major drawback, which argues the need to be tested in real-life driving scenarios, under highly safe measures, for it to be considered reliable. On the other hand, biological systems detect drowsiness early because they depend on internal drowsiness signs, which usually appear before visual signs [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B9-sensors-22-02069" rid="B9-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>]. Thus, they can give an early alarm that alerts the driver, significantly reducing the chances of falling asleep. </p><p>In contrast, vehicle-based systems resulted in the least accuracy. Additionally, as this measure’s results are unreliable alone, such systems are usually accompanied by another to validate the results of the vehicle-based measures. The hybrid-based systems showed a high performance; however, their multiple drowsiness measures distinguished this type of system. Notably, the various combinations of the hybrid systems have increased their performance and accuracy; additionally, they overcame some of the limitations that each measure has individually. In conclusion, using an accurate drowsiness detection system is one of the essential factors in reducing drowsiness-related car accidents. Furthermore, as the hybrid systems showed that they are highly reliable, they are the best option for drowsiness detection. </p><p class="p p-last">Our paper classifies and reviews the latest DDD systems. Each system presented in this paper is accompanied by a detailed exposition of the involved features, classification algorithms, and datasets used. Our review also compares the systems, in terms of cost, invasiveness, intrusiveness, ease of use, and classification quality metrics (accuracy, sensitivity, and precision). Furthermore, the paper discusses the current challenges in DDD literature and sheds light on future research directions.</p></div><div id="sec6-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec6-sensors-22-02069title">6. Future Trends in Drowsiness Detection Systems</h2><p class="p p-first">Mobile phones have been introduced in literature [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069" rid="B68-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">68</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B132-sensors-22-02069" rid="B132-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">132</a>] as an inexpensive alternative to collect driving data. Nowadays, mobile phones are equipped with at least two cameras and multiple sensors. Additionally, they can connect with a wide range of sensors through Bluetooth or other wireless technologies. When attached to the driver’s dashboard, a mobile phone’s front camera can collect various visual parameters, including eye features, mouth features, and head movements. Furthermore, the rear camera is capable of detecting vehicle-based features, such as lane departure and change in orientation, among others. Most mobile phones are also equipped with GPS sensors, an accelerometer, a gyroscope, and a magnetometer, which also could describe the car’s direction and orientation, leading to a better understanding of the driving experience. The phone’s microphone can also be used to collect data about the driver. </p><p>The possibility of connecting sensors to a mobile phone using various wireless technologies allows the use of various biological sensors to collect the driver’s data seamlessly. For example, ECG, EEG, EMG, or PPG sensors can be attached to the driver’s body or embedded within the seat or steering wheel for more convenience. </p><p>The data collected by the phone are analyzed using pre-trained machine learning models to infer the driver’s drowsiness status. While the use of machine learning algorithms on a mobile phone is possible, the use of deep learning is challenging and could lead to delayed inference times. Therefore, it is proposed to equip new mobile phones with chips, optimized for artificial intelligence [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069" rid="B68-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">68</a>], that facilitate the use of deep learning [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B133-sensors-22-02069" rid="B133-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">133</a>] for drowsiness detection on mobile platforms in real-time. </p><p>Cloud system architecture has also been used to collect multi-sensor data from smartphones about drivers to analyze their driving behaviors and study their drowsiness patterns [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B132-sensors-22-02069" rid="B132-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">132</a>]. Developers use the gathered data to produce applications that consider contextual driving situations and personalized driver traits. Despite their advantages, the inherent latency in cloud systems makes cloud-based applications not favorable for driver drowsiness detection systems, where real-time decisions must be made [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B134-sensors-22-02069" rid="B134-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">134</a>]. An alternative method, with low latency, is multi-access edge computing (MEC). The MEC technology brings computing power and storage resources to the edge of the mobile network, instead of the central cloud server approach. MEC has been used in various mobile applications, where it showed fewer delays than cloud systems. The use of MEC-based DDD systems over 5G networks would lead to real-time decisions, which, in turn, provides safety to the driver [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B134-sensors-22-02069" rid="B134-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">134</a>].</p><p>DDD systems not only assure the safety of the driver and companions but also other passengers on the road. When the DDD system detects that the driver is drowsy, it signals an alarm (such as a flickering light) to other vehicles on the road, warning them that the driver is drowsy and to take caution [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B135-sensors-22-02069" rid="B135-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">135</a>]. The car could also be a member of an Internet of vehicle network, an IoT network involving vehicles. In such a setting, vehicles send live data that includes the driver’s vital signals over a wireless medium, such as 5G [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B136-sensors-22-02069" rid="B136-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">136</a>]. The data are collected and analyzed in a traffic management platform, which, in the case of detected drowsiness, sends an alert signal to the driver to reduce the speed or park the car. It could also run an autopilot to take over the vehicle and park it safely. On the other hand, the platform can also contact neighboring vehicles in the networks to warn them about the drowsy driver.</p><p class="p p-last">A significant limitation in most proposed DDD systems is their dependence on limited datasets that were produced in simulated environments [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B4-sensors-22-02069" rid="B4-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">4</a>]. The accuracy of these systems could be increased by obtaining more data from various drivers in actual vehicles, where factors such as the ambient light, road surface vibrations, and individual differences among drivers are considered. This requires the use of deep learning, which can be done locally by equipping the vehicles with AI-enabled processors and GPUs [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B4-sensors-22-02069" rid="B4-sensors-22-02069" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">4</a>].</p></div><div id="sec7-sensors-22-02069" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec7-sensors-22-02069title">7. Conclusions</h2><p class="p p-first">Over the past decade, the drowsiness detection field has experienced significant enhancements, due to technological advancements in IoT, sensor miniaturization, and artificial intelligence. This paper has presented a detailed and up-to-date review of the driver drowsiness detection systems that have been implemented in the last ten years. It has described the four main approaches followed in designing DDD systems and categorized them based on the type of drowsiness indicative parameters employed. These four categories are image-, biological-, vehicle-, and hybrid-based systems. The paper has provided a detailed description of all the presented systems, in terms of the used features, implemented AI algorithms, and datasets used, as well as the resulting system accuracy, sensitivity, and precision. </p><p>Furthermore, the review has highlighted the current challenges in the DDD field, discussed the practicality of each DDD system, and discussed the current trends and future directions that aim to utilize affordable, easy-to-use, and practical methods to improve accuracy and reliability. </p><p>We expect 5G networks to play a prominent role in enhancing DDD systems. With 5G connectivity, future DDD systems will be based on real driving scenarios. The data will be obtained from various drivers in actual vehicles, where factors such as ambient light, road surface vibrations, and individual differences among drivers are considered. The use of 5G connectivity will also enable the use of multi-access edge computing power for deep learning, resulting in highly accurate real-time decisions. Vehicles are expected to operate as members of Internet of vehicle networks, enabling the network to warn the drowsy driver, take control of the car (if needed), and contact neighboring vehicles in the network to alert them about the weary driver. These technologies will lead to safer roads and pave the way towards realizing smart cities.</p><p class="p p-last">We conclude by emphasizing that DDD technology has enormous market potential. Many car manufacturers, such as Toyota and Nissan, have recently installed or upgraded driver assistance devices in their products. The artificial intelligence and deep learning fields are developing tremendously. Soon, the DDD systems will most likely evolve, enabling the formation of smart cities.</p></div><div id="glossary-a.aa.g" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="glossary-a.aa.gtitle">Abbreviations</h2><div class="bk-sec"><p>The nomenclature abbreviations, shown in Nomenclature, were used in this manuscript.
</p><table class="array small"><tbody><tr><td colspan="2" align="left" valign="middle" rowspan="1">Nomenclature</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>NHTSA</em></td><td align="left" valign="middle" rowspan="1" colspan="1">National highway traffic safety administration</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>DDD</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Driver drowsiness detection</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>IoT</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Internet of things</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>KSS</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Karolinska sleepiness scale</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ML</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Machine learning</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>TP</em></td><td align="left" valign="middle" rowspan="1" colspan="1">True positive</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>TN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">True negative</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>FP</em></td><td align="left" valign="middle" rowspan="1" colspan="1">False positive</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>FN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">False negative</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>NTHUDDD</em></td><td align="left" valign="middle" rowspan="1" colspan="1">National Tsuing Hua university drowsy driver detection</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>PERCLOS</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Percentage of eyelid closure</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>EAR</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Eye aspect ratio</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>SVM</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Support vector machine</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>KNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">K-nearest neighbor</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>SHRP2</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Strategic highway research program results</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>RF</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Random forest</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ANN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Artificial neural networks</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>CNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Convolutional neural network</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>FD-NN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Fully designed neural network</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>TL-VGG16</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Transfer learning in VGG16—VG16 is a 16-layers deep CNN architecture, named after the Visual Geometry Group from Oxford</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>TL-VGG19</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Transfer learning in VGG19—VG19 is a 19-layers deep CNN architecture</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>LSTM</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Long short-term memory</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>RNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Recursive neural network</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ROI</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Region of interest</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>EM-CNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Eye and mouth CNN</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>EMD</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Empirical mode decomposition</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>IMF</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Intrinsic mode functions</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>EEG</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Electroencephalography</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ECG</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Electrocardiography</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>PPG</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Photoplethysmography</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>HRV</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Heart rate variability</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>EOG</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Electrooculography</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>EMG</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Electromyography</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ELM</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Extreme learning machine</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>SVDD</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Simulated virtual driving driver</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>AVMD</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Adaptive variational mode decomposition</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>RPs</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Recurrence plots</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>RRIs</em></td><td align="left" valign="middle" rowspan="1" colspan="1">R–R intervals</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>Bin-RP</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Binary recurrence plot</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>Cont-RP</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Continuous recurrence plot</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ReLU-RP</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Thresholded recurrence plot</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ReLU</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Rectified linear unit</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>HF</em></td><td align="left" valign="middle" rowspan="1" colspan="1">High frequency</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>LF</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Low frequency</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>LF/HF</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Low to high frequency</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>MeanNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Mean of RRI</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>SDNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Standard deviation of RRI</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>RMSSD</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Root means square of the difference of adjacent RRI</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>TP</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Total power which is the variance of RRI</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>NN50</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Number of pairs of adjacent RRI spaced by 50 ms or more</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>RRV</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Respiratory rate variability.</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>H1</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Sum of the logarithmic amplitudes of the bispectrum</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>H2</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Sum of the logarithmic amplitudes of the diagonal elements in the bispectrum</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>H3</em></td><td align="left" valign="middle" rowspan="1" colspan="1">First-order spectral moment of the amplitudes of diagonal elements in the bispectrum</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>SWA</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Steering wheel angle</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>ANFIS</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Adaptive neuro-fuzzy inference systems</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>MOL</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Multilevel ordered logit</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>BPNN</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Back propagation neural network</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>NIRS</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Near-infrared spectroscopy</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><em>MEC</em></td><td align="left" valign="middle" rowspan="1" colspan="1">Multi-access edge computing</td></tr></tbody></table><p></p></div></div><div id="notes-a.aa.b" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="notes-a.aa.btitle">Author Contributions</h2><p>Conceptualization, Y.A. and M.T.; methodology, Y.A. and M.T.; formal analysis, Y.A., M.T. and M.A.; writing—original draft preparation, Y.A., M.T. and M.A.; writing—review and editing, Y.A., M.T. and M.A.; visualization, Y.A.; supervision, M.T. and M.A.; project administration, M.T.; funding acquisition, M.T. and M.A. All authors have read and agreed to the published version of the manuscript.</p></div><div id="notes-a.aa.c" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="notes-a.aa.ctitle">Funding</h2><p>This research received no external funding.</p></div><div id="notes-a.aa.d" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="notes-a.aa.dtitle">Institutional Review Board Statement</h2><p>Not applicable. </p></div><div id="notes-a.aa.e" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="notes-a.aa.etitle">Informed Consent Statement</h2><p>Not applicable.</p></div><div id="notes-a.aa.f" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="notes-a.aa.ftitle">Conflicts of Interest</h2><p>The authors declare no conflict of interest.</p></div><div id="fn-group-a.aa.a" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="fn-group-a.aa.atitle">Footnotes</h2><!--back/fn-group--><div class="fm-sec half_rhythm small"><p class="fn sec" id="fn-a.aa.a.a"></p><p class="p p-first-last"><strong>Publisher’s Note:</strong> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p><p></p></div></div><div id="ref-list-a.aa.h" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="ref-list-a.aa.htitle">References</h2><div class="ref-list-sec sec" id="reference-list"><div class="ref-cit-blk half_rhythm" id="B1-sensors-22-02069">1. <span class="element-citation">National Highway Traffic Safety Administration  Drowsy Driving.  [(accessed on 10 May 2021)];<span></span> Available online:  <a href="https://www.nhtsa.gov/risky-driving/drowsy-driving" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.nhtsa.gov/risky-driving/drowsy-driving</a></span></div><div class="ref-cit-blk half_rhythm" id="B2-sensors-22-02069">2. <span class="element-citation">Tefft B.C.  <span class="ref-journal">Prevalence of Motor Vehicle Crashes Involving Drowsy Drivers, United States, 2009–2013.</span> Citeseer; Washington, DC, USA: 2014.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Prevalence+of+Motor+Vehicle+Crashes+Involving+Drowsy+Drivers,+United+States,+2009%E2%80%932013&amp;author=B.C.+Tefft&amp;publication_year=2014&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B3-sensors-22-02069">3. <span class="element-citation">National Institutes of Health  Drowsiness.  [(accessed on 10 May 2021)];<span></span> Available online:  <a href="https://medlineplus.gov/ency/article/003208.htm#:~:text=Drowsiness%20refers%20to%20feeling%20abnormally,situations%20or%20at%20inappropriate%20times" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://medlineplus.gov/ency/article/003208.htm#:~:text=Drowsiness%20refers%20to%20feeling%20abnormally,situations%20or%20at%20inappropriate%20times</a></span></div><div class="ref-cit-blk half_rhythm" id="B4-sensors-22-02069">4. <span class="element-citation">Arakawa T. Trends and future prospects of the drowsiness detection and estimation technology. <span><span class="ref-journal">Sensors. </span>2021;<span class="ref-vol">21</span>:7921.  doi:&nbsp;10.3390/s21237921.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8659813/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/34883924" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs21237921" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Trends+and+future+prospects+of+the+drowsiness+detection+and+estimation+technology&amp;author=T.+Arakawa&amp;volume=21&amp;publication_year=2021&amp;pages=7921&amp;pmid=34883924&amp;doi=10.3390/s21237921&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B5-sensors-22-02069">5. <span class="element-citation">National Safety Council  Drivers are Falling Asleep Behind the Wheel.  [(accessed on 10 May 2021)].  Available online:  <a href="https://www.nsc.org/road-safety/safety-topics/fatigued-driving" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.nsc.org/road-safety/safety-topics/fatigued-driving</a></span></div><div class="ref-cit-blk half_rhythm" id="B6-sensors-22-02069">6. <span class="element-citation">National Sleep Foundation  Drowsy Driving.  [(accessed on 10 May 2021)].  Available online:  <a href="https://www.sleepfoundation.org/articles/drowsy-driving" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.sleepfoundation.org/articles/drowsy-driving</a></span></div><div class="ref-cit-blk half_rhythm" id="B7-sensors-22-02069">7. <span class="element-citation">Fuletra J.D., Bosamiya D. A survey on drivers drowsiness detection techniques. <span><span class="ref-journal">Int. J. Recent Innov. Trends Comput. Commun. </span>2013;<span class="ref-vol">1</span>:816–819.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Recent+Innov.+Trends+Comput.+Commun.&amp;title=A+survey+on+drivers+drowsiness+detection+techniques&amp;author=J.D.+Fuletra&amp;author=D.+Bosamiya&amp;volume=1&amp;publication_year=2013&amp;pages=816-819&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B8-sensors-22-02069">8. <span class="element-citation">Pratama B.G., Ardiyanto I., Adji T.B. A review on driver drowsiness based on image, bio-signal, and driver behavior; Proceedings of the 2017 3rd International Conference on Science and Technology-Computer (ICST); Bandung, Indonesia. 25–26 October 2017; pp. 70–75. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2017+3rd+International+Conference+on+Science+and+Technology-Computer+(ICST)&amp;title=A+review+on+driver+drowsiness+based+on+image,+bio-signal,+and+driver+behavior&amp;author=B.G.+Pratama&amp;author=I.+Ardiyanto&amp;author=T.B.+Adji&amp;pages=70-75&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B9-sensors-22-02069">9. <span class="element-citation">Ramzan M., Khan H.U., Awan S.M., Ismail A., Ilyas M., Mahmood A. A survey on state-of-the-art drowsiness detection techniques. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:61904–61919. doi:&nbsp;10.1109/ACCESS.2019.2914373.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2914373" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=A+survey+on+state-of-the-art+drowsiness+detection+techniques&amp;author=M.+Ramzan&amp;author=H.U.+Khan&amp;author=S.M.+Awan&amp;author=A.+Ismail&amp;author=M.+Ilyas&amp;volume=7&amp;publication_year=2019&amp;pages=61904-61919&amp;doi=10.1109/ACCESS.2019.2914373&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B10-sensors-22-02069">10. <span class="element-citation">Sikander G., Anwar S. Driver fatigue detection systems: A review. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2018;<span class="ref-vol">20</span>:2339–2352. doi:&nbsp;10.1109/TITS.2018.2868499.</span> [<a href="https://doi.org/10.1109%2FTITS.2018.2868499" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=Driver+fatigue+detection+systems:+A+review&amp;author=G.+Sikander&amp;author=S.+Anwar&amp;volume=20&amp;publication_year=2018&amp;pages=2339-2352&amp;doi=10.1109/TITS.2018.2868499&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B11-sensors-22-02069">11. <span class="element-citation">Ukwuoma C.C., Bo C. Deep Learning Review on Drivers Drowsiness Detection; Proceedings of the 2019 4th Technology Innovation Management and Engineering Science International Conference (TIMES-iCON); Bangkok, Thailand. 11–13 December 2019; pp. 1–5. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2019+4th+Technology+Innovation+Management+and+Engineering+Science+International+Conference+(TIMES-iCON)&amp;title=Deep+Learning+Review+on+Drivers+Drowsiness+Detection&amp;author=C.C.+Ukwuoma&amp;author=C.+Bo&amp;pages=1-5&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B12-sensors-22-02069">12. <span class="element-citation">Dong Y., Hu Z., Uchimura K., Murayama N. Driver inattention monitoring system for intelligent vehicles: A review. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2010;<span class="ref-vol">12</span>:596–614. doi:&nbsp;10.1109/TITS.2010.2092770.</span> [<a href="https://doi.org/10.1109%2FTITS.2010.2092770" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=Driver+inattention+monitoring+system+for+intelligent+vehicles:+A+review&amp;author=Y.+Dong&amp;author=Z.+Hu&amp;author=K.+Uchimura&amp;author=N.+Murayama&amp;volume=12&amp;publication_year=2010&amp;pages=596-614&amp;doi=10.1109/TITS.2010.2092770&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B13-sensors-22-02069">13. <span class="element-citation">Nordbakke S., Sagberg F. Sleepy at the wheel: Knowledge, symptoms and behaviour among car drivers. <span><span class="ref-journal">Transportation Research Part F: Traffic Psychology and Behaviour. </span>2007;<span class="ref-vol">10</span>:1–10. doi:&nbsp;10.1016/j.trf.2006.03.003.</span> [<a href="https://doi.org/10.1016%2Fj.trf.2006.03.003" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Transportation+Research+Part+F:+Traffic+Psychology+and+Behaviour&amp;title=Sleepy+at+the+wheel:+Knowledge,+symptoms+and+behaviour+among+car+drivers&amp;author=S.+Nordbakke&amp;author=F.+Sagberg&amp;volume=10&amp;publication_year=2007&amp;pages=1-10&amp;doi=10.1016/j.trf.2006.03.003&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B14-sensors-22-02069">14. <span class="element-citation">Chacon-Murguia M.I., Prieto-Resendiz C. Detecting Driver Drowsiness: A survey of system designs and technology. <span><span class="ref-journal">IEEE Consum. Electron. Mag. </span>2015;<span class="ref-vol">4</span>:107–119. doi:&nbsp;10.1109/MCE.2015.2463373.</span> [<a href="https://doi.org/10.1109%2FMCE.2015.2463373" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Consum.+Electron.+Mag.&amp;title=Detecting+Driver+Drowsiness:+A+survey+of+system+designs+and+technology&amp;author=M.I.+Chacon-Murguia&amp;author=C.+Prieto-Resendiz&amp;volume=4&amp;publication_year=2015&amp;pages=107-119&amp;doi=10.1109/MCE.2015.2463373&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B15-sensors-22-02069">15. <span class="element-citation">Beirness D.J., Simpson H.M., Desmond K., The Road Safety Monitor 2004: Drowsy Driving  Drowsy Driving. 2005.  [(accessed on 2 March 2022)].  Available online:  <a href="http://worldcat.org/isbn/0920071473" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">http://worldcat.org/isbn/0920071473</a></span></div><div class="ref-cit-blk half_rhythm" id="B16-sensors-22-02069">16. <span class="element-citation">Knapik M., Cyganek B. Driver’s fatigue recognition based on yawn detection in thermal images. <span><span class="ref-journal">Neurocomputing. </span>2019;<span class="ref-vol">338</span>:274–292. doi:&nbsp;10.1016/j.neucom.2019.02.014.</span> [<a href="https://doi.org/10.1016%2Fj.neucom.2019.02.014" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neurocomputing&amp;title=Driver%E2%80%99s+fatigue+recognition+based+on+yawn+detection+in+thermal+images&amp;author=M.+Knapik&amp;author=B.+Cyganek&amp;volume=338&amp;publication_year=2019&amp;pages=274-292&amp;doi=10.1016/j.neucom.2019.02.014&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B17-sensors-22-02069">17. <span class="element-citation">Liu W., Qian J., Yao Z., Jiao X., Pan J. Convolutional two-stream network using multi-facial feature fusion for driver fatigue detection. <span><span class="ref-journal">Future Internet. </span>2019;<span class="ref-vol">11</span>:115.  doi:&nbsp;10.3390/fi11050115.</span> [<a href="https://doi.org/10.3390%2Ffi11050115" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Future+Internet&amp;title=Convolutional+two-stream+network+using+multi-facial+feature+fusion+for+driver+fatigue+detection&amp;author=W.+Liu&amp;author=J.+Qian&amp;author=Z.+Yao&amp;author=X.+Jiao&amp;author=J.+Pan&amp;volume=11&amp;publication_year=2019&amp;pages=115&amp;doi=10.3390/fi11050115&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B18-sensors-22-02069">18. <span class="element-citation">You F., Gong Y., Tu H., Liang J., Wang H. A fatigue driving detection algorithm based on facial motion information entropy. <span><span class="ref-journal">J. Adv. Transp. </span>2020;<span class="ref-vol">2020</span>:1–17. doi:&nbsp;10.1155/2020/8851485.</span> [<a href="https://doi.org/10.1155%2F2020%2F8851485" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Adv.+Transp.&amp;title=A+fatigue+driving+detection+algorithm+based+on+facial+motion+information+entropy&amp;author=F.+You&amp;author=Y.+Gong&amp;author=H.+Tu&amp;author=J.+Liang&amp;author=H.+Wang&amp;volume=2020&amp;publication_year=2020&amp;pages=1-17&amp;doi=10.1155/2020/8851485&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B19-sensors-22-02069">19. <span class="element-citation">Mittal A., Kumar K., Dhamija S., Kaur M. Head movement-based driver drowsiness detection: A review of state-of-art techniques; Proceedings of the 2016 IEEE International Conference on Engineering and Technology (ICETECH); Coimbatore, India. 17–18 March 2016; pp. 903–908. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2016+IEEE+International+Conference+on+Engineering+and+Technology+(ICETECH)&amp;title=Head+movement-based+driver+drowsiness+detection:+A+review+of+state-of-art+techniques&amp;author=A.+Mittal&amp;author=K.+Kumar&amp;author=S.+Dhamija&amp;author=M.+Kaur&amp;pages=903-908&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B20-sensors-22-02069">20. <span class="element-citation">Otmani S., Pebayle T., Roge J., Muzet A. Effect of driving duration and partial sleep deprivation on subsequent alertness and performance of car drivers. <span><span class="ref-journal">Physiol. Behav. </span>2005;<span class="ref-vol">84</span>:715–724. doi:&nbsp;10.1016/j.physbeh.2005.02.021.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/15885247" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.physbeh.2005.02.021" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Physiol.+Behav.&amp;title=Effect+of+driving+duration+and+partial+sleep+deprivation+on+subsequent+alertness+and+performance+of+car+drivers&amp;author=S.+Otmani&amp;author=T.+Pebayle&amp;author=J.+Roge&amp;author=A.+Muzet&amp;volume=84&amp;publication_year=2005&amp;pages=715-724&amp;pmid=15885247&amp;doi=10.1016/j.physbeh.2005.02.021&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B21-sensors-22-02069">21. <span class="element-citation">Kaida K., Takahashi M., Åkerstedt T., Nakata A., Otsuka Y., Haratani T., Fukasawa K. Validation of the Karolinska sleepiness scale against performance and EEG variables. <span><span class="ref-journal">Clin. Neurophysiol. </span>2006;<span class="ref-vol">117</span>:1574–1581. doi:&nbsp;10.1016/j.clinph.2006.03.011.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/16679057" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.clinph.2006.03.011" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Clin.+Neurophysiol.&amp;title=Validation+of+the+Karolinska+sleepiness+scale+against+performance+and+EEG+variables&amp;author=K.+Kaida&amp;author=M.+Takahashi&amp;author=T.+%C3%85kerstedt&amp;author=A.+Nakata&amp;author=Y.+Otsuka&amp;volume=117&amp;publication_year=2006&amp;pages=1574-1581&amp;pmid=16679057&amp;doi=10.1016/j.clinph.2006.03.011&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B22-sensors-22-02069">22. <span class="element-citation">Shahid A., Wilkinson K., Marcu S., Shapiro C.M.  <span class="ref-journal">STOP, THAT and One Hundred Other Sleep Scales.</span> Springer; Berlin/Heidelberg, Germany: 2011. Karolinska sleepiness scale (KSS) pp. 209–210. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=STOP,+THAT+and+One+Hundred+Other+Sleep+Scales&amp;author=A.+Shahid&amp;author=K.+Wilkinson&amp;author=S.+Marcu&amp;author=C.M.+Shapiro&amp;publication_year=2011&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B23-sensors-22-02069">23. <span class="element-citation">Wierwille W.W., Ellsworth L.A. Evaluation of driver drowsiness by trained raters. <span><span class="ref-journal">Accid. Anal. Prev. </span>1994;<span class="ref-vol">26</span>:571–581. doi:&nbsp;10.1016/0001-4575(94)90019-1.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/7999202" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2F0001-4575(94)90019-1" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Accid.+Anal.+Prev.&amp;title=Evaluation+of+driver+drowsiness+by+trained+raters&amp;author=W.W.+Wierwille&amp;author=L.A.+Ellsworth&amp;volume=26&amp;publication_year=1994&amp;pages=571-581&amp;pmid=7999202&amp;doi=10.1016/0001-4575(94)90019-1&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B24-sensors-22-02069">24. <span class="element-citation">Saito Y., Itoh M., Inagaki T. Driver assistance system with a dual control scheme: Effectiveness of identifying driver drowsiness and preventing lane departure accidents. <span><span class="ref-journal">IEEE Trans. Hum. Mach. Syst. </span>2016;<span class="ref-vol">46</span>:660–671. doi:&nbsp;10.1109/THMS.2016.2549032.</span> [<a href="https://doi.org/10.1109%2FTHMS.2016.2549032" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Hum.+Mach.+Syst.&amp;title=Driver+assistance+system+with+a+dual+control+scheme:+Effectiveness+of+identifying+driver+drowsiness+and+preventing+lane+departure+accidents&amp;author=Y.+Saito&amp;author=M.+Itoh&amp;author=T.+Inagaki&amp;volume=46&amp;publication_year=2016&amp;pages=660-671&amp;doi=10.1109/THMS.2016.2549032&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B25-sensors-22-02069">25. <span class="element-citation">Sunagawa M., Shikii S., Nakai W., Mochizuki M., Kusukame K., Kitajima H. Comprehensive Drowsiness Level Detection Model Combining Multimodal Information. <span><span class="ref-journal">IEEE Sens. J. </span>2020;<span class="ref-vol">20</span>:3709–3717. doi:&nbsp;10.1109/JSEN.2019.2960158.</span> [<a href="https://doi.org/10.1109%2FJSEN.2019.2960158" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Comprehensive+Drowsiness+Level+Detection+Model+Combining+Multimodal+Information&amp;author=M.+Sunagawa&amp;author=S.+Shikii&amp;author=W.+Nakai&amp;author=M.+Mochizuki&amp;author=K.+Kusukame&amp;volume=20&amp;publication_year=2020&amp;pages=3709-3717&amp;doi=10.1109/JSEN.2019.2960158&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B26-sensors-22-02069">26. <span class="element-citation">Machine Learning Crash Course  Classification: Accuracy.  [(accessed on 2 March 2022)].  Available online:  <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">https://developers.google.com/machine-learning/crash-course/classification/accuracy</a></span></div><div class="ref-cit-blk half_rhythm" id="B27-sensors-22-02069">27. <span class="element-citation">Machine Learning Crash Course  Classification: Precision and Recall.  [(accessed on 2 March 2022)].  Available online:  <a href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall</a></span></div><div class="ref-cit-blk half_rhythm" id="B28-sensors-22-02069">28. <span class="element-citation">Leng L.B., Giin L.B., Chung W.-Y. Wearable driver drowsiness detection system based on biomedical and motion sensors; Proceedings of the 2015 IEEE SENSORS; Busan, Korea. 1–4 November 2015; pp. 1–4. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2015+IEEE+SENSORS&amp;title=Wearable+driver+drowsiness+detection+system+based+on+biomedical+and+motion+sensors&amp;author=L.B.+Leng&amp;author=L.B.+Giin&amp;author=W.-Y.+Chung&amp;pages=1-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B29-sensors-22-02069">29. <span class="element-citation">Mehreen A., Anwar S.M., Haseeb M., Majid M., Ullah M.O. A hybrid scheme for drowsiness detection using wearable sensors. <span><span class="ref-journal">IEEE Sens. J. </span>2019;<span class="ref-vol">19</span>:5119–5126. doi:&nbsp;10.1109/JSEN.2019.2904222.</span> [<a href="https://doi.org/10.1109%2FJSEN.2019.2904222" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=A+hybrid+scheme+for+drowsiness+detection+using+wearable+sensors&amp;author=A.+Mehreen&amp;author=S.M.+Anwar&amp;author=M.+Haseeb&amp;author=M.+Majid&amp;author=M.O.+Ullah&amp;volume=19&amp;publication_year=2019&amp;pages=5119-5126&amp;doi=10.1109/JSEN.2019.2904222&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B30-sensors-22-02069">30. <span class="element-citation">Bamidele A., Kamardin K., Syazarin N., Mohd S., Shafi I., Azizan A., Aini N., Mad H. Non-intrusive driver drowsiness detection based on face and eye tracking. <span><span class="ref-journal">Int J. Adv. Comput. Sci. Appl. </span>2019;<span class="ref-vol">10</span>:549–569. doi:&nbsp;10.14569/IJACSA.2019.0100775.</span> [<a href="https://doi.org/10.14569%2FIJACSA.2019.0100775" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int+J.+Adv.+Comput.+Sci.+Appl.&amp;title=Non-intrusive+driver+drowsiness+detection+based+on+face+and+eye+tracking&amp;author=A.+Bamidele&amp;author=K.+Kamardin&amp;author=N.+Syazarin&amp;author=S.+Mohd&amp;author=I.+Shafi&amp;volume=10&amp;publication_year=2019&amp;pages=549-569&amp;doi=10.14569/IJACSA.2019.0100775&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B31-sensors-22-02069">31. <span class="element-citation">Lin S.T., Tan Y.Y., Chua P.Y., Tey L.K., Ang C.H. Perclos threshold for drowsiness detection during real driving. <span><span class="ref-journal">J. Vis. </span>2012;<span class="ref-vol">12</span>:546. doi:&nbsp;10.1167/12.9.546.</span> [<a href="https://doi.org/10.1167%2F12.9.546" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Vis.&amp;title=Perclos+threshold+for+drowsiness+detection+during+real+driving&amp;author=S.T.+Lin&amp;author=Y.Y.+Tan&amp;author=P.Y.+Chua&amp;author=L.K.+Tey&amp;author=C.H.+Ang&amp;volume=12&amp;publication_year=2012&amp;pages=546&amp;doi=10.1167/12.9.546&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B32-sensors-22-02069">32. <span class="element-citation">Rosebrock A. Eyeblink Detection with OpenCV, Python, and dlib.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/_mjzu4CFQAAAAAdAAAAABAK" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/_mjzu4CFQAAAAAdAAAAABAK</a></span></div><div class="ref-cit-blk half_rhythm" id="B33-sensors-22-02069">33. <span class="element-citation">Moujahid A., Dornaika F., Arganda-Carreras I., Reta J. Efficient and compact face descriptor for driver drowsiness detection. <span><span class="ref-journal">Expert Syst. Appl. </span>2021;<span class="ref-vol">168</span>:114334.  doi:&nbsp;10.1016/j.eswa.2020.114334.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2020.114334" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Efficient+and+compact+face+descriptor+for+driver+drowsiness+detection&amp;author=A.+Moujahid&amp;author=F.+Dornaika&amp;author=I.+Arganda-Carreras&amp;author=J.+Reta&amp;volume=168&amp;publication_year=2021&amp;pages=114334&amp;doi=10.1016/j.eswa.2020.114334&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B34-sensors-22-02069">34. <span class="element-citation">Popieul J.C., Simon P., Loslever P. Using driver’s head movements evolution as a drowsiness indicator; Proceedings of the IEEE IV2003 Intelligent Vehicles Symposium; Columbus, OH, USA. 9–11 June 2003; pp. 616–621. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+IV2003+Intelligent+Vehicles+Symposium&amp;title=Using+driver%E2%80%99s+head+movements+evolution+as+a+drowsiness+indicator&amp;author=J.C.+Popieul&amp;author=P.+Simon&amp;author=P.+Loslever&amp;pages=616-621&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B35-sensors-22-02069">35. <span class="element-citation">Weng C.-H., Lai Y.-H., Lai S.-H. Driver drowsiness detection via a hierarchical temporal deep belief network; Proceedings of the Asian Conference on Computer Vision; Taipei, Taiwan. 20–24 November 2016; pp. 117–133. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+Asian+Conference+on+Computer+Vision&amp;title=Driver+drowsiness+detection+via+a+hierarchical+temporal+deep+belief+network&amp;author=C.-H.+Weng&amp;author=Y.-H.+Lai&amp;author=S.-H.+Lai&amp;pages=117-133&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B36-sensors-22-02069">36. <span class="element-citation">Knapik M.  <span class="ref-journal">Thermal Images Database.</span> GitHub; Krakow, Poland: 2018.  [(accessed on 20 September 2021)].  Available online:  <a href="https://github.com/mat02/ThermalImagingInCar" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/mat02/ThermalImagingInCar</a> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Thermal+Images+Database&amp;author=M.+Knapik&amp;publication_year=2018&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B37-sensors-22-02069">37. <span class="element-citation">Wikipedia  Voxel.  [(accessed on 20 September 2021)].  Available online:  <a href="https://en.wikipedia.org/wiki/Voxel" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://en.wikipedia.org/wiki/Voxel</a></span></div><div class="ref-cit-blk half_rhythm" id="B38-sensors-22-02069">38. <span class="element-citation">Kiashari S.E.H., Nahvi A., Bakhoda H., Homayounfard A., Tashakori M. Evaluation of driver drowsiness using respiration analysis by thermal imaging on a driving simulator. <span><span class="ref-journal">Multimed. Tools Appl. </span>2020;<span class="ref-vol">79</span>:17793–17815. doi:&nbsp;10.1007/s11042-020-08696-x.</span> [<a href="https://doi.org/10.1007%2Fs11042-020-08696-x" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Multimed.+Tools+Appl.&amp;title=Evaluation+of+driver+drowsiness+using+respiration+analysis+by+thermal+imaging+on+a+driving+simulator&amp;author=S.E.H.+Kiashari&amp;author=A.+Nahvi&amp;author=H.+Bakhoda&amp;author=A.+Homayounfard&amp;author=M.+Tashakori&amp;volume=79&amp;publication_year=2020&amp;pages=17793-17815&amp;doi=10.1007/s11042-020-08696-x&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B39-sensors-22-02069">39. <span class="element-citation">Tayab Khan M., Anwar H., Ullah F., Ur Rehman A., Ullah R., Iqbal A., Lee B.-H., Kwak K.S. Smart real-time video surveillance platform for drowsiness detection based on eyelid closure. <span><span class="ref-journal">Wirel. Commun. Mob. Comput. </span>2019;<span class="ref-vol">2019</span>:1–9. doi:&nbsp;10.1155/2019/2036818.</span> [<a href="https://doi.org/10.1155%2F2019%2F2036818" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Wirel.+Commun.+Mob.+Comput.&amp;title=Smart+real-time+video+surveillance+platform+for+drowsiness+detection+based+on+eyelid+closure&amp;author=M.+Tayab+Khan&amp;author=H.+Anwar&amp;author=F.+Ullah&amp;author=A.+Ur+Rehman&amp;author=R.+Ullah&amp;volume=2019&amp;publication_year=2019&amp;pages=1-9&amp;doi=10.1155/2019/2036818&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B40-sensors-22-02069">40. <span class="element-citation">Song F., Tan X., Liu X., Chen S. Eyes closeness detection from still images with multi-scale histograms of principal oriented gradients. <span><span class="ref-journal">Pattern Recognit. </span>2014;<span class="ref-vol">47</span>:2825–2838. doi:&nbsp;10.1016/j.patcog.2014.03.024.</span> [<a href="https://doi.org/10.1016%2Fj.patcog.2014.03.024" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Pattern+Recognit.&amp;title=Eyes+closeness+detection+from+still+images+with+multi-scale+histograms+of+principal+oriented+gradients&amp;author=F.+Song&amp;author=X.+Tan&amp;author=X.+Liu&amp;author=S.+Chen&amp;volume=47&amp;publication_year=2014&amp;pages=2825-2838&amp;doi=10.1016/j.patcog.2014.03.024&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B41-sensors-22-02069">41. <span class="element-citation">Ouabida E., Essadike A., Bouzid A. Optical correlator based algorithm for driver drowsiness detection. <span><span class="ref-journal">Optik. </span>2020;<span class="ref-vol">204</span>:164102.  doi:&nbsp;10.1016/j.ijleo.2019.164102.</span> [<a href="https://doi.org/10.1016%2Fj.ijleo.2019.164102" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Optik&amp;title=Optical+correlator+based+algorithm+for+driver+drowsiness+detection&amp;author=E.+Ouabida&amp;author=A.+Essadike&amp;author=A.+Bouzid&amp;volume=204&amp;publication_year=2020&amp;pages=164102&amp;doi=10.1016/j.ijleo.2019.164102&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B42-sensors-22-02069">42. <span class="element-citation">Lugt A.V. Signal detection by complex spatial filtering. <span><span class="ref-journal">IEEE Trans. Inf. Theory. </span>1964;<span class="ref-vol">10</span>:139–145. doi:&nbsp;10.1109/TIT.1964.1053650.</span> [<a href="https://doi.org/10.1109%2FTIT.1964.1053650" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Inf.+Theory&amp;title=Signal+detection+by+complex+spatial+filtering&amp;author=A.V.+Lugt&amp;volume=10&amp;publication_year=1964&amp;pages=139-145&amp;doi=10.1109/TIT.1964.1053650&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B43-sensors-22-02069">43. <span class="element-citation">Xu P., Yu J., Sun Z., Zhou L., Cheng G., Hong C., Han F. Misalignment influence of components on the performance of an integrated zigzag Vander Lugt correlator. <span><span class="ref-journal">Optik. </span>2017;<span class="ref-vol">140</span>:178–185. doi:&nbsp;10.1016/j.ijleo.2017.04.012.</span> [<a href="https://doi.org/10.1016%2Fj.ijleo.2017.04.012" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Optik&amp;title=Misalignment+influence+of+components+on+the+performance+of+an+integrated+zigzag+Vander+Lugt+correlator&amp;author=P.+Xu&amp;author=J.+Yu&amp;author=Z.+Sun&amp;author=L.+Zhou&amp;author=G.+Cheng&amp;volume=140&amp;publication_year=2017&amp;pages=178-185&amp;doi=10.1016/j.ijleo.2017.04.012&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B44-sensors-22-02069">44. <span class="element-citation">Thomaz C.E., Giraldi G.A. A new ranking method for principal components analysis and its application to face image analysis. <span><span class="ref-journal">Image Vis. Comput. </span>2010;<span class="ref-vol">28</span>:902–913. doi:&nbsp;10.1016/j.imavis.2009.11.005.</span> [<a href="https://doi.org/10.1016%2Fj.imavis.2009.11.005" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Image+Vis.+Comput.&amp;title=A+new+ranking+method+for+principal+components+analysis+and+its+application+to+face+image+analysis&amp;author=C.E.+Thomaz&amp;author=G.A.+Giraldi&amp;volume=28&amp;publication_year=2010&amp;pages=902-913&amp;doi=10.1016/j.imavis.2009.11.005&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B45-sensors-22-02069">45. <span class="element-citation">Gourier N., Hall D., Crowley J.L. Estimating face orientation from robust detection of salient facial features; Proceedings of the ICPR International Workshop on Visual Observation of Deictic Gestures; Cambridge, UK. 22 August 2004. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+ICPR+International+Workshop+on+Visual+Observation+of+Deictic+Gestures&amp;title=Estimating+face+orientation+from+robust+detection+of+salient+facial+features&amp;author=N.+Gourier&amp;author=D.+Hall&amp;author=J.L.+Crowley&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B46-sensors-22-02069">46. <span class="element-citation">Jesorsky O., Kirchberg K.J., Frischholz R.W. Robust face detection using the hausdorff distance; Proceedings of the International conference on audio-and video-based biometric person authentication; Halmstad, Sweden. 6–8 June 2001; pp. 90–95. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+International+conference+on+audio-and+video-based+biometric+person+authentication&amp;title=Robust+face+detection+using+the+hausdorff+distance&amp;author=O.+Jesorsky&amp;author=K.J.+Kirchberg&amp;author=R.W.+Frischholz&amp;pages=90-95&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B47-sensors-22-02069">47. <span class="element-citation">Villanueva A., Ponz V., Sesma-Sanchez L., Ariz M., Porta S., Cabeza R. Hybrid method based on topography for robust detection of iris center and eye corners. <span><span class="ref-journal">ACM Trans. Multimed. Comput. Commun. Appl. </span>2013;<span class="ref-vol">9</span>:1–20. doi:&nbsp;10.1145/2501643.2501647.</span> [<a href="https://doi.org/10.1145%2F2501643.2501647" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=ACM+Trans.+Multimed.+Comput.+Commun.+Appl.&amp;title=Hybrid+method+based+on+topography+for+robust+detection+of+iris+center+and+eye+corners&amp;author=A.+Villanueva&amp;author=V.+Ponz&amp;author=L.+Sesma-Sanchez&amp;author=M.+Ariz&amp;author=S.+Porta&amp;volume=9&amp;publication_year=2013&amp;pages=1-20&amp;doi=10.1145/2501643.2501647&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B48-sensors-22-02069">48. <span class="element-citation">SHRP2: Transportation Research Board of the National Academies of Science  . <span class="ref-journal">The 2nd Strategic Highway Research Program Naturalistic Driving Study Dataset.</span> Virginia Tech Transportation Institute; Blacksburg, VA, USA: 2018.  [(accessed on 20 September 2021)].  Available online:  <a href="https://insight.shrp2nds.us/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://insight.shrp2nds.us/</a> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=The+2nd+Strategic+Highway+Research+Program+Naturalistic+Driving+Study+Dataset&amp;publication_year=2018&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B49-sensors-22-02069">49. <span class="element-citation">Maior C.B.S., das Chagas Moura M.J., Santana J.M.M., Lins I.D. Real-time classification for autonomous drowsiness detection using eye aspect ratio. <span><span class="ref-journal">Expert Syst. Appl. </span>2020;<span class="ref-vol">158</span>:113505.  doi:&nbsp;10.1016/j.eswa.2020.113505.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2020.113505" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Real-time+classification+for+autonomous+drowsiness+detection+using+eye+aspect+ratio&amp;author=C.B.S.+Maior&amp;author=M.J.+das+Chagas+Moura&amp;author=J.M.M.+Santana&amp;author=I.D.+Lins&amp;volume=158&amp;publication_year=2020&amp;pages=113505&amp;doi=10.1016/j.eswa.2020.113505&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B50-sensors-22-02069">50. <span class="element-citation">Hashemi M., Mirrashid A., Shirazi A.B. Driver Safety Development: Real-Time Driver Drowsiness Detection System Based on Convolutional Neural Network. <span><span class="ref-journal">SN Comput. Sci. </span>2020;<span class="ref-vol">1</span>:1–10. doi:&nbsp;10.1007/s42979-020-00306-9.</span> [<a href="https://doi.org/10.1007%2Fs42979-020-00306-9" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=SN+Comput.+Sci.&amp;title=Driver+Safety+Development:+Real-Time+Driver+Drowsiness+Detection+System+Based+on+Convolutional+Neural+Network&amp;author=M.+Hashemi&amp;author=A.+Mirrashid&amp;author=A.B.+Shirazi&amp;volume=1&amp;publication_year=2020&amp;pages=1-10&amp;doi=10.1007/s42979-020-00306-9&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B51-sensors-22-02069">51. <span class="element-citation">Zandi A.S., Quddus A., Prest L., Comeau F.J. Non-intrusive detection of drowsy driving based on eye tracking data. <span><span class="ref-journal">Transp. Res. Rec. </span>2019;<span class="ref-vol">2673</span>:247–257. doi:&nbsp;10.1177/0361198119847985.</span> [<a href="https://doi.org/10.1177%2F0361198119847985" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Transp.+Res.+Rec.&amp;title=Non-intrusive+detection+of+drowsy+driving+based+on+eye+tracking+data&amp;author=A.S.+Zandi&amp;author=A.+Quddus&amp;author=L.+Prest&amp;author=F.J.+Comeau&amp;volume=2673&amp;publication_year=2019&amp;pages=247-257&amp;doi=10.1177/0361198119847985&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B52-sensors-22-02069">52. <span class="element-citation">Celecia A., Figueiredo K., Vellasco M., González R. A portable fuzzy driver drowsiness estimation system. <span><span class="ref-journal">Sensors. </span>2020;<span class="ref-vol">20</span>:4093.  doi:&nbsp;10.3390/s20154093.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7435375/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32717787" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs20154093" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=A+portable+fuzzy+driver+drowsiness+estimation+system&amp;author=A.+Celecia&amp;author=K.+Figueiredo&amp;author=M.+Vellasco&amp;author=R.+Gonz%C3%A1lez&amp;volume=20&amp;publication_year=2020&amp;pages=4093&amp;pmid=32717787&amp;doi=10.3390/s20154093&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B53-sensors-22-02069">53. <span class="element-citation">Sagonas C., Tzimiropoulos G., Zafeiriou S., Pantic M. 300 faces in-the-wild challenge: The first facial landmark localization challenge; Proceedings of the IEEE International Conference on Computer Vision Workshops; Sydney, Australia. 2–8 December 2013; pp. 397–403. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision+Workshops&amp;title=300+faces+in-the-wild+challenge:+The+first+facial+landmark+localization+challenge&amp;author=C.+Sagonas&amp;author=G.+Tzimiropoulos&amp;author=S.+Zafeiriou&amp;author=M.+Pantic&amp;pages=397-403&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B54-sensors-22-02069">54. <span class="element-citation">Alioua N., Amine A., Rziza M., Aboutajdine D. Driver’s fatigue and drowsiness detection to reduce traffic accidents on road; Proceedings of the International Conference on Computer Analysis of Images and Patterns; Seville, Spain. 29–31 August 2011; pp. 397–404. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+International+Conference+on+Computer+Analysis+of+Images+and+Patterns&amp;title=Driver%E2%80%99s+fatigue+and+drowsiness+detection+to+reduce+traffic+accidents+on+road&amp;author=N.+Alioua&amp;author=A.+Amine&amp;author=M.+Rziza&amp;author=D.+Aboutajdine&amp;pages=397-404&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B55-sensors-22-02069">55. <span class="element-citation">Khunpisuth O., Chotchinasri T., Koschakosai V., Hnoohom N. Driver drowsiness detection using eye-closeness detection; Proceedings of the 2016 12th International Conference on Signal-Image Technology &amp; Internet-Based Systems (SITIS); Naples, Italy. 28 November–1 December 2016; pp. 661–668. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2016+12th+International+Conference+on+Signal-Image+Technology+&amp;+Internet-Based+Systems+(SITIS)&amp;title=Driver+drowsiness+detection+using+eye-closeness+detection&amp;author=O.+Khunpisuth&amp;author=T.+Chotchinasri&amp;author=V.+Koschakosai&amp;author=N.+Hnoohom&amp;pages=661-668&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B56-sensors-22-02069">56. <span class="element-citation">Deng W., Wu R. Real-time driver-drowsiness detection system using facial features. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:118727–118738. doi:&nbsp;10.1109/ACCESS.2019.2936663.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2936663" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Real-time+driver-drowsiness+detection+system+using+facial+features&amp;author=W.+Deng&amp;author=R.+Wu&amp;volume=7&amp;publication_year=2019&amp;pages=118727-118738&amp;doi=10.1109/ACCESS.2019.2936663&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B57-sensors-22-02069">57. <span class="element-citation">Liu Z., Luo P., Wang X., Tang X. Deep learning face attributes in the wild; Proceedings of the IEEE International Conference on Computer Vision; Santiago, Chile. 7–13 December 2015; pp. 3730–3738. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision&amp;title=Deep+learning+face+attributes+in+the+wild&amp;author=Z.+Liu&amp;author=P.+Luo&amp;author=X.+Wang&amp;author=X.+Tang&amp;pages=3730-3738&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B58-sensors-22-02069">58. <span class="element-citation">Abtahi S., Omidyeganeh M., Shirmohammadi S., Hariri B. YawDD: A yawning detection dataset; Proceedings of the 5th ACM Multimedia Systems Conference; Singapore. 19 March 2014; pp. 24–28. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+5th+ACM+Multimedia+Systems+Conference&amp;title=YawDD:+A+yawning+detection+dataset&amp;author=S.+Abtahi&amp;author=M.+Omidyeganeh&amp;author=S.+Shirmohammadi&amp;author=B.+Hariri&amp;pages=24-28&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B59-sensors-22-02069">59. <span class="element-citation">Dua M., Singla R., Raj S., Jangra A. Deep CNN models-based ensemble approach to driver drowsiness detection. <span><span class="ref-journal">Neural Comput. Appl. </span>2021;<span class="ref-vol">33</span>:3155–3168. doi:&nbsp;10.1007/s00521-020-05209-7.</span> [<a href="https://doi.org/10.1007%2Fs00521-020-05209-7" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neural+Comput.+Appl.&amp;title=Deep+CNN+models-based+ensemble+approach+to+driver+drowsiness+detection&amp;author=M.+Dua&amp;author=R.+Singla&amp;author=S.+Raj&amp;author=A.+Jangra&amp;volume=33&amp;publication_year=2021&amp;pages=3155-3168&amp;doi=10.1007/s00521-020-05209-7&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B60-sensors-22-02069">60. <span class="element-citation">Sewell M. Ensemble learning. <span><span class="ref-journal">Res. Note. </span>2011;<span class="ref-vol">11</span>:1–34.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Res.+Note&amp;title=Ensemble+learning&amp;author=M.+Sewell&amp;volume=11&amp;publication_year=2011&amp;pages=1-34&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B61-sensors-22-02069">61. <span class="element-citation">Rosebrock A. Softmax Classifiers Explained.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/</a></span></div><div class="ref-cit-blk half_rhythm" id="B62-sensors-22-02069">62. <span class="element-citation">Hoang T., Pan B., Nguyen D., Wang Z. Generic gamma correction for accuracy enhancement in fringe-projection profilometry. <span><span class="ref-journal">Opt. Lett. </span>2010;<span class="ref-vol">35</span>:1992–1994. doi:&nbsp;10.1364/OL.35.001992.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/20548363" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1364%2FOL.35.001992" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Opt.+Lett.&amp;title=Generic+gamma+correction+for+accuracy+enhancement+in+fringe-projection+profilometry&amp;author=T.+Hoang&amp;author=B.+Pan&amp;author=D.+Nguyen&amp;author=Z.+Wang&amp;volume=35&amp;publication_year=2010&amp;pages=1992-1994&amp;pmid=20548363&amp;doi=10.1364/OL.35.001992&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B63-sensors-22-02069">63. <span class="element-citation">Yu J., Park S., Lee S., Jeon M. Driver drowsiness detection using condition-adaptive representation learning framework. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2018;<span class="ref-vol">20</span>:4206–4218. doi:&nbsp;10.1109/TITS.2018.2883823.</span> [<a href="https://doi.org/10.1109%2FTITS.2018.2883823" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=Driver+drowsiness+detection+using+condition-adaptive+representation+learning+framework&amp;author=J.+Yu&amp;author=S.+Park&amp;author=S.+Lee&amp;author=M.+Jeon&amp;volume=20&amp;publication_year=2018&amp;pages=4206-4218&amp;doi=10.1109/TITS.2018.2883823&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B64-sensors-22-02069">64. <span class="element-citation">Tuzel O., Porikli F., Meer P. Region covariance: A fast descriptor for detection and classification; Proceedings of the European conference on computer vision; Graz, Austria. 7–13 May 2006; pp. 589–600. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+European+conference+on+computer+vision&amp;title=Region+covariance:+A+fast+descriptor+for+detection+and+classification&amp;author=O.+Tuzel&amp;author=F.+Porikli&amp;author=P.+Meer&amp;pages=589-600&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B65-sensors-22-02069">65. <span class="element-citation">Dalal N., Triggs B. Histograms of oriented gradients for human detection; Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05); San Diego, CA, USA. 20–25 June 2005; pp. 886–893. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2005+IEEE+Computer+Society+Conference+on+Computer+Vision+and+Pattern+Recognition+(CVPR%E2%80%9905)&amp;title=Histograms+of+oriented+gradients+for+human+detection&amp;author=N.+Dalal&amp;author=B.+Triggs&amp;pages=886-893&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B66-sensors-22-02069">66. <span class="element-citation">Ahonen T., Hadid A., Pietikainen M. Face description with local binary patterns: Application to face recognition. <span><span class="ref-journal">IEEE Trans. Pattern Anal. Mach. Intell. </span>2006;<span class="ref-vol">28</span>:2037–2041. doi:&nbsp;10.1109/TPAMI.2006.244.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17108377" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTPAMI.2006.244" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Pattern+Anal.+Mach.+Intell.&amp;title=Face+description+with+local+binary+patterns:+Application+to+face+recognition&amp;author=T.+Ahonen&amp;author=A.+Hadid&amp;author=M.+Pietikainen&amp;volume=28&amp;publication_year=2006&amp;pages=2037-2041&amp;pmid=17108377&amp;doi=10.1109/TPAMI.2006.244&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B67-sensors-22-02069">67. <span class="element-citation">Gu Q., Li Z., Han J. Generalized Fisher Score for Feature Selection.  [(accessed on 20 September 2021)].  Available online:  <a href="https://arxiv.org/abs/1202.3725" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://arxiv.org/abs/1202.3725</a></span></div><div class="ref-cit-blk half_rhythm" id="B68-sensors-22-02069">68. <span class="element-citation">Wijnands J.S., Thompson J., Nice K.A., Aschwanden G.D., Stevenson M. Real-time monitoring of driver drowsiness on mobile platforms using 3D neural networks. <span><span class="ref-journal">Neural Comput. Appl. </span>2020;<span class="ref-vol">32</span>:9731–9743. doi:&nbsp;10.1007/s00521-019-04506-0.</span> [<a href="https://doi.org/10.1007%2Fs00521-019-04506-0" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neural+Comput.+Appl.&amp;title=Real-time+monitoring+of+driver+drowsiness+on+mobile+platforms+using+3D+neural+networks&amp;author=J.S.+Wijnands&amp;author=J.+Thompson&amp;author=K.A.+Nice&amp;author=G.D.+Aschwanden&amp;author=M.+Stevenson&amp;volume=32&amp;publication_year=2020&amp;pages=9731-9743&amp;doi=10.1007/s00521-019-04506-0&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B69-sensors-22-02069">69. <span class="element-citation">Guo J.-M., Markoni H. Driver drowsiness detection using hybrid convolutional neural network and long short-term memory. <span><span class="ref-journal">Multimed. Tools Appl. </span>2019;<span class="ref-vol">78</span>:29059–29087. doi:&nbsp;10.1007/s11042-018-6378-6.</span> [<a href="https://doi.org/10.1007%2Fs11042-018-6378-6" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Multimed.+Tools+Appl.&amp;title=Driver+drowsiness+detection+using+hybrid+convolutional+neural+network+and+long+short-term+memory&amp;author=J.-M.+Guo&amp;author=H.+Markoni&amp;volume=78&amp;publication_year=2019&amp;pages=29059-29087&amp;doi=10.1007/s11042-018-6378-6&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B70-sensors-22-02069">70. <span class="element-citation">Ed-Doughmi Y., Idrissi N., Hbali Y. Real-time system for driver fatigue detection based on a recurrent neuronal network. <span><span class="ref-journal">J. Imaging. </span>2020;<span class="ref-vol">6</span>:8.  doi:&nbsp;10.3390/jimaging6030008.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321037/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/34460605" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fjimaging6030008" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Imaging&amp;title=Real-time+system+for+driver+fatigue+detection+based+on+a+recurrent+neuronal+network&amp;author=Y.+Ed-Doughmi&amp;author=N.+Idrissi&amp;author=Y.+Hbali&amp;volume=6&amp;publication_year=2020&amp;pages=8&amp;pmid=34460605&amp;doi=10.3390/jimaging6030008&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B71-sensors-22-02069">71. <span class="element-citation">Tran D., Bourdev L., Fergus R., Torresani L., Paluri M. Learning spatiotemporal features with 3d convolutional networks; Proceedings of the IEEE International Conference on Computer Vision; Santiago, Chile. 7–13 December 2015; pp. 4489–4497. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision&amp;title=Learning+spatiotemporal+features+with+3d+convolutional+networks&amp;author=D.+Tran&amp;author=L.+Bourdev&amp;author=R.+Fergus&amp;author=L.+Torresani&amp;author=M.+Paluri&amp;pages=4489-4497&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B72-sensors-22-02069">72. <span class="element-citation">Zhao Z., Zhou N., Zhang L., Yan H., Xu Y., Zhang Z. Driver fatigue detection based on convolutional neural networks using em-cnn. <span><span class="ref-journal">Comput. Intell. Neurosci. </span>2020;<span class="ref-vol">2020</span>:1–11. doi:&nbsp;10.1155/2020/7251280.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7688374/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/33293943" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1155%2F2020%2F7251280" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Comput.+Intell.+Neurosci.&amp;title=Driver+fatigue+detection+based+on+convolutional+neural+networks+using+em-cnn&amp;author=Z.+Zhao&amp;author=N.+Zhou&amp;author=L.+Zhang&amp;author=H.+Yan&amp;author=Y.+Xu&amp;volume=2020&amp;publication_year=2020&amp;pages=1-11&amp;pmid=33293943&amp;doi=10.1155/2020/7251280&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B73-sensors-22-02069">73. <span class="element-citation">Kumar J.S., Bhuvaneswari P. Analysis of Electroencephalography (EEG) signals and its categorization—A study. <span><span class="ref-journal">Procedia Eng. </span>2012;<span class="ref-vol">38</span>:2525–2536. doi:&nbsp;10.1016/j.proeng.2012.06.298.</span> [<a href="https://doi.org/10.1016%2Fj.proeng.2012.06.298" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Procedia+Eng.&amp;title=Analysis+of+Electroencephalography+(EEG)+signals+and+its+categorization%E2%80%94A+study&amp;author=J.S.+Kumar&amp;author=P.+Bhuvaneswari&amp;volume=38&amp;publication_year=2012&amp;pages=2525-2536&amp;doi=10.1016/j.proeng.2012.06.298&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B74-sensors-22-02069">74. <span class="element-citation">Khorovets A. What Is an Electrocardiogram (ECG)?  [(accessed on 20 September 2021)];<span><span class="ref-journal">Internet J. Adv. Nurs. Pract. </span>1999 <span class="ref-vol">4</span>:1–4.</span> Available online:  <a href="https://ispub.com/IJANP/4/2/12928" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://ispub.com/IJANP/4/2/12928</a> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Internet+J.+Adv.+Nurs.+Pract.&amp;title=What+Is+an+Electrocardiogram+(ECG)?&amp;author=A.+Khorovets&amp;volume=4&amp;publication_year=1999&amp;pages=1-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B75-sensors-22-02069">75. <span class="element-citation">Castaneda D., Esparza A., Ghamari M., Soltanpur C., Nazeran H. A review on wearable photoplethysmography sensors and their potential future applications in health care. <span><span class="ref-journal">Int. J. Biosens. Bioelectron. </span>2018;<span class="ref-vol">4</span>:195. doi:&nbsp;10.15406/ijbsbe.2018.04.00125.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6426305/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/30906922" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.15406%2Fijbsbe.2018.04.00125" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Biosens.+Bioelectron.&amp;title=A+review+on+wearable+photoplethysmography+sensors+and+their+potential+future+applications+in+health+care&amp;author=D.+Castaneda&amp;author=A.+Esparza&amp;author=M.+Ghamari&amp;author=C.+Soltanpur&amp;author=H.+Nazeran&amp;volume=4&amp;publication_year=2018&amp;pages=195&amp;pmid=30906922&amp;doi=10.15406/ijbsbe.2018.04.00125&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B76-sensors-22-02069">76. <span class="element-citation">Mejía-Mejía E., Budidha K., Abay T.Y., May J.M., Kyriacou P.A. Heart rate variability (HRV) and pulse rate variability (PRV) for the assessment of autonomic responses. <span><span class="ref-journal">Front. Physiol. </span>2020;<span class="ref-vol">11</span>:779.  doi:&nbsp;10.3389/fphys.2020.00779.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7390908/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32792970" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3389%2Ffphys.2020.00779" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Front.+Physiol.&amp;title=Heart+rate+variability+(HRV)+and+pulse+rate+variability+(PRV)+for+the+assessment+of+autonomic+responses&amp;author=E.+Mej%C3%ADa-Mej%C3%ADa&amp;author=K.+Budidha&amp;author=T.Y.+Abay&amp;author=J.M.+May&amp;author=P.A.+Kyriacou&amp;volume=11&amp;publication_year=2020&amp;pages=779&amp;pmid=32792970&amp;doi=10.3389/fphys.2020.00779&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B77-sensors-22-02069">77. <span class="element-citation">The McGill Physiology Lab  Biological Signals Acquisition.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.medicine.mcgill.ca/physio/vlab/Other_exps/EOG/eogintro_n.htm" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.medicine.mcgill.ca/physio/vlab/Other_exps/EOG/eogintro_n.htm</a></span></div><div class="ref-cit-blk half_rhythm" id="B78-sensors-22-02069">78. <span class="element-citation">Chowdhury R., Reaz M.B.I., Mohd Ali M., Bakar A., Ashrif A., Chellappan K., Chang T.-G. Surface Electromyography Signal Processing and Classification Techniques. <span><span class="ref-journal">Sensors. </span>2013;<span class="ref-vol">13</span>:12431–12466. doi:&nbsp;10.3390/s130912431.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3821366/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24048337" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs130912431" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Surface+Electromyography+Signal+Processing+and+Classification+Techniques&amp;author=R.+Chowdhury&amp;author=M.B.I.+Reaz&amp;author=M.+Mohd+Ali&amp;author=A.+Bakar&amp;author=A.+Ashrif&amp;volume=13&amp;publication_year=2013&amp;pages=12431-12466&amp;pmid=24048337&amp;doi=10.3390/s130912431&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B79-sensors-22-02069">79. <span class="element-citation">Li G., Lee B.-L., Chung W.-Y. Smartwatch-based wearable EEG system for driver drowsiness detection. <span><span class="ref-journal">IEEE Sens. J. </span>2015;<span class="ref-vol">15</span>:7169–7180. doi:&nbsp;10.1109/JSEN.2015.2473679.</span> [<a href="https://doi.org/10.1109%2FJSEN.2015.2473679" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Smartwatch-based+wearable+EEG+system+for+driver+drowsiness+detection&amp;author=G.+Li&amp;author=B.-L.+Lee&amp;author=W.-Y.+Chung&amp;volume=15&amp;publication_year=2015&amp;pages=7169-7180&amp;doi=10.1109/JSEN.2015.2473679&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B80-sensors-22-02069">80. <span class="element-citation">Kaur R., Singh K. Drowsiness detection based on EEG signal analysis using EMD and trained neural network. <span><span class="ref-journal">Int. J. Sci. Res. </span>2013;<span class="ref-vol">10</span>:157–161.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Sci.+Res.&amp;title=Drowsiness+detection+based+on+EEG+signal+analysis+using+EMD+and+trained+neural+network&amp;author=R.+Kaur&amp;author=K.+Singh&amp;volume=10&amp;publication_year=2013&amp;pages=157-161&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B81-sensors-22-02069">81. <span class="element-citation">Budak U., Bajaj V., Akbulut Y., Atila O., Sengur A. An effective hybrid model for EEG-based drowsiness detection. <span><span class="ref-journal">IEEE Sens. J. </span>2019;<span class="ref-vol">19</span>:7624–7631. doi:&nbsp;10.1109/JSEN.2019.2917850.</span> [<a href="https://doi.org/10.1109%2FJSEN.2019.2917850" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=An+effective+hybrid+model+for+EEG-based+drowsiness+detection&amp;author=U.+Budak&amp;author=V.+Bajaj&amp;author=Y.+Akbulut&amp;author=O.+Atila&amp;author=A.+Sengur&amp;volume=19&amp;publication_year=2019&amp;pages=7624-7631&amp;doi=10.1109/JSEN.2019.2917850&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B82-sensors-22-02069">82. <span class="element-citation">Ichimaru Y., Moody G. Development of the polysomnographic database on CD-ROM. <span><span class="ref-journal">Psychiatry Clin. Neurosci. </span>1999;<span class="ref-vol">53</span>:175–177. doi:&nbsp;10.1046/j.1440-1819.1999.00527.x.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/10459681" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1046%2Fj.1440-1819.1999.00527.x" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychiatry+Clin.+Neurosci.&amp;title=Development+of+the+polysomnographic+database+on+CD-ROM&amp;author=Y.+Ichimaru&amp;author=G.+Moody&amp;volume=53&amp;publication_year=1999&amp;pages=175-177&amp;pmid=10459681&amp;doi=10.1046/j.1440-1819.1999.00527.x&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B83-sensors-22-02069">83. <span class="element-citation">Taran S., Bajaj V. Drowsiness detection using adaptive hermite decomposition and extreme learning machine for electroencephalogram signals. <span><span class="ref-journal">IEEE Sens. J. </span>2018;<span class="ref-vol">18</span>:8855–8862. doi:&nbsp;10.1109/JSEN.2018.2869775.</span> [<a href="https://doi.org/10.1109%2FJSEN.2018.2869775" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Drowsiness+detection+using+adaptive+hermite+decomposition+and+extreme+learning+machine+for+electroencephalogram+signals&amp;author=S.+Taran&amp;author=V.+Bajaj&amp;volume=18&amp;publication_year=2018&amp;pages=8855-8862&amp;doi=10.1109/JSEN.2018.2869775&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B84-sensors-22-02069">84. <span class="element-citation">Chen L.-l., Zhao Y., Zhang J., Zou J.-z. Automatic detection of alertness/drowsiness from physiological signals using wavelet-based nonlinear features and machine learning. <span><span class="ref-journal">Expert Syst. Appl. </span>2015;<span class="ref-vol">42</span>:7344–7355. doi:&nbsp;10.1016/j.eswa.2015.05.028.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2015.05.028" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Automatic+detection+of+alertness/drowsiness+from+physiological+signals+using+wavelet-based+nonlinear+features+and+machine+learning&amp;author=L.-l.+Chen&amp;author=Y.+Zhao&amp;author=J.+Zhang&amp;author=J.-z.+Zou&amp;volume=42&amp;publication_year=2015&amp;pages=7344-7355&amp;doi=10.1016/j.eswa.2015.05.028&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B85-sensors-22-02069">85. <span class="element-citation">Choi H.-S., Min S., Kim S., Bae H., Yoon J.-E., Hwang I., Oh D., Yun C.-H., Yoon S. Learning-based instantaneous drowsiness detection using wired and wireless electroencephalography. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:146390–146402. doi:&nbsp;10.1109/ACCESS.2019.2946053.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2946053" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Learning-based+instantaneous+drowsiness+detection+using+wired+and+wireless+electroencephalography&amp;author=H.-S.+Choi&amp;author=S.+Min&amp;author=S.+Kim&amp;author=H.+Bae&amp;author=J.-E.+Yoon&amp;volume=7&amp;publication_year=2019&amp;pages=146390-146402&amp;doi=10.1109/ACCESS.2019.2946053&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B86-sensors-22-02069">86. <span class="element-citation">Thomson D.J. Spectrum estimation and harmonic analysis. <span><span class="ref-journal">Proc. IEEE. </span>1982;<span class="ref-vol">70</span>:1055–1096. doi:&nbsp;10.1109/PROC.1982.12433.</span> [<a href="https://doi.org/10.1109%2FPROC.1982.12433" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proc.+IEEE&amp;title=Spectrum+estimation+and+harmonic+analysis&amp;author=D.J.+Thomson&amp;volume=70&amp;publication_year=1982&amp;pages=1055-1096&amp;doi=10.1109/PROC.1982.12433&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B87-sensors-22-02069">87. <span class="element-citation">Chinara S. Automatic classification methods for detecting drowsiness using wavelet packet transform extracted time-domain features from single-channel EEG signal. <span><span class="ref-journal">J. Neurosci. Methods. </span>2021;<span class="ref-vol">347</span>:108927.  doi:&nbsp;10.1016/j.jneumeth.2020.108927.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32941920" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jneumeth.2020.108927" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Neurosci.+Methods&amp;title=Automatic+classification+methods+for+detecting+drowsiness+using+wavelet+packet+transform+extracted+time-domain+features+from+single-channel+EEG+signal&amp;author=S.+Chinara&amp;volume=347&amp;publication_year=2021&amp;pages=108927&amp;pmid=32941920&amp;doi=10.1016/j.jneumeth.2020.108927&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B88-sensors-22-02069">88. <span class="element-citation">Percival D.B., Walden A.T.  <span class="ref-journal">Wavelet Methods for Time Series Analysis.</span> Volume 4 Cambridge University Press; Cambridge, UK: 2000.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Wavelet+Methods+for+Time+Series+Analysis&amp;author=D.B.+Percival&amp;author=A.T.+Walden&amp;publication_year=2000&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B89-sensors-22-02069">89. <span class="element-citation">Kemp B., Zwinderman A.H., Tuk B., Kamphuisen H.A., Oberye J.J. Analysis of a sleep-dependent neuronal feedback loop: The slow-wave microcontinuity of the EEG. <span><span class="ref-journal">IEEE Trans. Biomed. Eng. </span>2000;<span class="ref-vol">47</span>:1185–1194. doi:&nbsp;10.1109/10.867928.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/11008419" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2F10.867928" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Biomed.+Eng.&amp;title=Analysis+of+a+sleep-dependent+neuronal+feedback+loop:+The+slow-wave+microcontinuity+of+the+EEG&amp;author=B.+Kemp&amp;author=A.H.+Zwinderman&amp;author=B.+Tuk&amp;author=H.A.+Kamphuisen&amp;author=J.J.+Oberye&amp;volume=47&amp;publication_year=2000&amp;pages=1185-1194&amp;pmid=11008419&amp;doi=10.1109/10.867928&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B90-sensors-22-02069">90. <span class="element-citation">Kemp B. Sleep-EDF Database Expanded.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.physionet.org/content/sleep-edfx/1.0.0/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.physionet.org/content/sleep-edfx/1.0.0/</a></span></div><div class="ref-cit-blk half_rhythm" id="B91-sensors-22-02069">91. <span class="element-citation">Zheng W.-L., Lu B.-L. A multimodal approach to estimating vigilance using EEG and forehead EOG. <span><span class="ref-journal">J. Neural Eng. </span>2017;<span class="ref-vol">14</span>:026017. doi:&nbsp;10.1088/1741-2552/aa5a98.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28102833" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1088%2F1741-2552%2Faa5a98" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Neural+Eng.&amp;title=A+multimodal+approach+to+estimating+vigilance+using+EEG+and+forehead+EOG&amp;author=W.-L.+Zheng&amp;author=B.-L.+Lu&amp;volume=14&amp;publication_year=2017&amp;pages=026017&amp;pmid=28102833&amp;doi=10.1088/1741-2552/aa5a98&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B92-sensors-22-02069">92. <span class="element-citation">Higuchi T. Approach to an irregular time series on the basis of the fractal theory. <span><span class="ref-journal">Phys. D Nonlinear Phenom. </span>1988;<span class="ref-vol">31</span>:277–283. doi:&nbsp;10.1016/0167-2789(88)90081-4.</span> [<a href="https://doi.org/10.1016%2F0167-2789(88)90081-4" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Phys.+D+Nonlinear+Phenom.&amp;title=Approach+to+an+irregular+time+series+on+the+basis+of+the+fractal+theory&amp;author=T.+Higuchi&amp;volume=31&amp;publication_year=1988&amp;pages=277-283&amp;doi=10.1016/0167-2789(88)90081-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B93-sensors-22-02069">93. <span class="element-citation">Hjorth B. EEG analysis based on time domain properties. <span><span class="ref-journal">Electroencephalogr. Clin. Neurophysiol. </span>1970;<span class="ref-vol">29</span>:306–310. doi:&nbsp;10.1016/0013-4694(70)90143-4.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/4195653" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2F0013-4694(70)90143-4" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;title=EEG+analysis+based+on+time+domain+properties&amp;author=B.+Hjorth&amp;volume=29&amp;publication_year=1970&amp;pages=306-310&amp;pmid=4195653&amp;doi=10.1016/0013-4694(70)90143-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B94-sensors-22-02069">94. <span class="element-citation">Wilcoxon F.  <span class="ref-journal">Breakthroughs in Statistics.</span> Springer; Berlin/Heidelberg, Germany: 1992. Individual comparisons by ranking methods. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Breakthroughs+in+Statistics&amp;author=F.+Wilcoxon&amp;publication_year=1992&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B95-sensors-22-02069">95. <span class="element-citation">Wilkinson B. A statistical consideration in psychological research. <span><span class="ref-journal">Psychol. Bull. </span>1951;<span class="ref-vol">48</span>:156. doi:&nbsp;10.1037/h0059111.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/14834286" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1037%2Fh0059111" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychol.+Bull.&amp;title=A+statistical+consideration+in+psychological+research&amp;author=B.+Wilkinson&amp;volume=48&amp;publication_year=1951&amp;pages=156&amp;pmid=14834286&amp;doi=10.1037/h0059111&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B96-sensors-22-02069">96. <span class="element-citation">Khare S.K., Bajaj V. Entropy-Based Drowsiness Detection Using Adaptive Variational Mode Decomposition. <span><span class="ref-journal">IEEE Sens. J. </span>2020;<span class="ref-vol">21</span>:6421–6428. doi:&nbsp;10.1109/JSEN.2020.3038440.</span> [<a href="https://doi.org/10.1109%2FJSEN.2020.3038440" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Entropy-Based+Drowsiness+Detection+Using+Adaptive+Variational+Mode+Decomposition&amp;author=S.K.+Khare&amp;author=V.+Bajaj&amp;volume=21&amp;publication_year=2020&amp;pages=6421-6428&amp;doi=10.1109/JSEN.2020.3038440&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B97-sensors-22-02069">97. <span class="element-citation">Bandt C., Pompe B. Permutation entropy: A natural complexity measure for time series. <span><span class="ref-journal">Phys. Rev. Lett. </span>2002;<span class="ref-vol">88</span>:174102.  doi:&nbsp;10.1103/PhysRevLett.88.174102.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/12005759" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1103%2FPhysRevLett.88.174102" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Phys.+Rev.+Lett.&amp;title=Permutation+entropy:+A+natural+complexity+measure+for+time+series&amp;author=C.+Bandt&amp;author=B.+Pompe&amp;volume=88&amp;publication_year=2002&amp;pages=174102&amp;pmid=12005759&amp;doi=10.1103/PhysRevLett.88.174102&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B98-sensors-22-02069">98. <span class="element-citation">Borowska M. Entropy-based algorithms in the analysis of biomedical signals. <span><span class="ref-journal">Stud. Log. Gramm. Rhetor. </span>2015;<span class="ref-vol">43</span>:21–32. doi:&nbsp;10.1515/slgr-2015-0039.</span> [<a href="https://doi.org/10.1515%2Fslgr-2015-0039" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Stud.+Log.+Gramm.+Rhetor.&amp;title=Entropy-based+algorithms+in+the+analysis+of+biomedical+signals&amp;author=M.+Borowska&amp;volume=43&amp;publication_year=2015&amp;pages=21-32&amp;doi=10.1515/slgr-2015-0039&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B99-sensors-22-02069">99. <span class="element-citation">Aydın S., Saraoğlu H.M., Kara S. Log energy entropy-based EEG classification with multilayer neural networks in seizure. <span><span class="ref-journal">Ann. Biomed. Eng. </span>2009;<span class="ref-vol">37</span>:2626. doi:&nbsp;10.1007/s10439-009-9795-x.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/19757057" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1007%2Fs10439-009-9795-x" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Ann.+Biomed.+Eng.&amp;title=Log+energy+entropy-based+EEG+classification+with+multilayer+neural+networks+in+seizure&amp;author=S.+Ayd%C4%B1n&amp;author=H.M.+Sarao%C4%9Flu&amp;author=S.+Kara&amp;volume=37&amp;publication_year=2009&amp;pages=2626&amp;pmid=19757057&amp;doi=10.1007/s10439-009-9795-x&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B100-sensors-22-02069">100. <span class="element-citation">Lee H., Lee J., Shin M. Using wearable ECG/PPG sensors for driver drowsiness detection based on distinguishable pattern of recurrence plots. <span><span class="ref-journal">Electronics. </span>2019;<span class="ref-vol">8</span>:192.  doi:&nbsp;10.3390/electronics8020192.</span> [<a href="https://doi.org/10.3390%2Felectronics8020192" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Electronics&amp;title=Using+wearable+ECG/PPG+sensors+for+driver+drowsiness+detection+based+on+distinguishable+pattern+of+recurrence+plots&amp;author=H.+Lee&amp;author=J.+Lee&amp;author=M.+Shin&amp;volume=8&amp;publication_year=2019&amp;pages=192&amp;doi=10.3390/electronics8020192&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B101-sensors-22-02069">101. <span class="element-citation">Koh S., Cho B.R., Lee J.-i., Kwon S.-O., Lee S., Lim J.B., Lee S.B., Kweon H.-D. Driver drowsiness detection via PPG biosignals by using multimodal head support; Proceedings of the 2017 4th international conference on control, decision and information technologies (CoDIT); Barcelona, Spain. 5–7 April 2017; pp. 383–388. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2017+4th+international+conference+on+control,+decision+and+information+technologies+(CoDIT)&amp;title=Driver+drowsiness+detection+via+PPG+biosignals+by+using+multimodal+head+support&amp;author=S.+Koh&amp;author=B.R.+Cho&amp;author=J.-i.+Lee&amp;author=S.-O.+Kwon&amp;author=S.+Lee&amp;pages=383-388&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B102-sensors-22-02069">102. <span class="element-citation">Kundinger T., Sofra N., Riener A. Assessment of the potential of wrist-worn wearable sensors for driver drowsiness detection. <span><span class="ref-journal">Sensors. </span>2020;<span class="ref-vol">20</span>:1029.  doi:&nbsp;10.3390/s20041029.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070962/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32075030" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs20041029" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Assessment+of+the+potential+of+wrist-worn+wearable+sensors+for+driver+drowsiness+detection&amp;author=T.+Kundinger&amp;author=N.+Sofra&amp;author=A.+Riener&amp;volume=20&amp;publication_year=2020&amp;pages=1029&amp;doi=10.3390/s20041029&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B103-sensors-22-02069">103. <span class="element-citation">Fujiwara K., Abe E., Kamata K., Nakayama C., Suzuki Y., Yamakawa T., Hiraoka T., Kano M., Sumi Y., Masuda F. Heart rate variability-based driver drowsiness detection and its validation with EEG. <span><span class="ref-journal">IEEE Trans. Biomed. Eng. </span>2018;<span class="ref-vol">66</span>:1769–1778. doi:&nbsp;10.1109/TBME.2018.2879346.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/30403616" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTBME.2018.2879346" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Biomed.+Eng.&amp;title=Heart+rate+variability-based+driver+drowsiness+detection+and+its+validation+with+EEG&amp;author=K.+Fujiwara&amp;author=E.+Abe&amp;author=K.+Kamata&amp;author=C.+Nakayama&amp;author=Y.+Suzuki&amp;volume=66&amp;publication_year=2018&amp;pages=1769-1778&amp;pmid=30403616&amp;doi=10.1109/TBME.2018.2879346&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B104-sensors-22-02069">104. <span class="element-citation">Guede-Fernandez F., Fernandez-Chimeno M., Ramos-Castro J., Garcia-Gonzalez M.A. Driver drowsiness detection based on respiratory signal analysis. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:81826–81838. doi:&nbsp;10.1109/ACCESS.2019.2924481.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2924481" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Driver+drowsiness+detection+based+on+respiratory+signal+analysis&amp;author=F.+Guede-Fernandez&amp;author=M.+Fernandez-Chimeno&amp;author=J.+Ramos-Castro&amp;author=M.A.+Garcia-Gonzalez&amp;volume=7&amp;publication_year=2019&amp;pages=81826-81838&amp;doi=10.1109/ACCESS.2019.2924481&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B105-sensors-22-02069">105. <span class="element-citation">Kamen G., Kinesiology E.  <span class="ref-journal">Research Methods in Biomechanics.</span> Human Kinetics Publ; Champaign, IL, USA: 2004.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Research+Methods+in+Biomechanics&amp;author=G.+Kamen&amp;author=E.+Kinesiology&amp;publication_year=2004&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B106-sensors-22-02069">106. <span class="element-citation">Reaz M., Hussain M., Mohd-Yasin F. Techniques of EMG signal analysis: Detection, processing, classification and applications (Correction) <span><span class="ref-journal">Biol. Proced. Online. </span>2006;<span class="ref-vol">8</span> doi:&nbsp;10.1251/bpo124.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1622762/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/19565309" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1251%2Fbpo124" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Biol.+Proced.+Online&amp;title=Techniques+of+EMG+signal+analysis:+Detection,+processing,+classification+and+applications+(Correction)&amp;author=M.+Reaz&amp;author=M.+Hussain&amp;author=F.+Mohd-Yasin&amp;volume=8&amp;publication_year=2006&amp;doi=10.1251/bpo124&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B107-sensors-22-02069">107. <span class="element-citation">Sahayadhas A., Sundaraj K., Murugappan M., Palaniappan R. Physiological signal based detection of driver hypovigilance using higher order spectra. <span><span class="ref-journal">Expert Syst. Appl. </span>2015;<span class="ref-vol">42</span>:8669–8677. doi:&nbsp;10.1016/j.eswa.2015.07.021.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2015.07.021" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Physiological+signal+based+detection+of+driver+hypovigilance+using+higher+order+spectra&amp;author=A.+Sahayadhas&amp;author=K.+Sundaraj&amp;author=M.+Murugappan&amp;author=R.+Palaniappan&amp;volume=42&amp;publication_year=2015&amp;pages=8669-8677&amp;doi=10.1016/j.eswa.2015.07.021&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B108-sensors-22-02069">108. <span class="element-citation">Fu R., Wang H. Detection of driving fatigue by using noncontact EMG and ECG signals measurement system. <span><span class="ref-journal">Int. J. Neural Syst. </span>2014;<span class="ref-vol">24</span>:1450006. doi:&nbsp;10.1142/S0129065714500063.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24552510" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1142%2FS0129065714500063" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Neural+Syst.&amp;title=Detection+of+driving+fatigue+by+using+noncontact+EMG+and+ECG+signals+measurement+system&amp;author=R.+Fu&amp;author=H.+Wang&amp;volume=24&amp;publication_year=2014&amp;pages=1450006&amp;pmid=24552510&amp;doi=10.1142/S0129065714500063&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B109-sensors-22-02069">109. <span class="element-citation">Awais M., Badruddin N., Drieberg M. A hybrid approach to detect driver drowsiness utilizing physiological signals to improve system performance and wearability. <span><span class="ref-journal">Sensors. </span>2017;<span class="ref-vol">17</span>:1991.  doi:&nbsp;10.3390/s17091991.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5620623/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28858220" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs17091991" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=A+hybrid+approach+to+detect+driver+drowsiness+utilizing+physiological+signals+to+improve+system+performance+and+wearability&amp;author=M.+Awais&amp;author=N.+Badruddin&amp;author=M.+Drieberg&amp;volume=17&amp;publication_year=2017&amp;pages=1991&amp;pmid=28858220&amp;doi=10.3390/s17091991&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B110-sensors-22-02069">110. <span class="element-citation">Khushaba R.N., Kodagoda S., Lal S., Dissanayake G. Driver drowsiness classification using fuzzy wavelet-packet-based feature-extraction algorithm. <span><span class="ref-journal">IEEE Trans. Biomed. Eng. </span>2010;<span class="ref-vol">58</span>:121–131. doi:&nbsp;10.1109/TBME.2010.2077291.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/20858575" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTBME.2010.2077291" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Biomed.+Eng.&amp;title=Driver+drowsiness+classification+using+fuzzy+wavelet-packet-based+feature-extraction+algorithm&amp;author=R.N.+Khushaba&amp;author=S.+Kodagoda&amp;author=S.+Lal&amp;author=G.+Dissanayake&amp;volume=58&amp;publication_year=2010&amp;pages=121-131&amp;pmid=20858575&amp;doi=10.1109/TBME.2010.2077291&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B111-sensors-22-02069">111. <span class="element-citation">Cai D., He X., Han J. SRDA: An efficient algorithm for large-scale discriminant analysis. <span><span class="ref-journal">IEEE Trans. Knowl. Data Eng. </span>2007;<span class="ref-vol">20</span>:1–12. doi:&nbsp;10.1109/TKDE.2007.190669.</span> [<a href="https://doi.org/10.1109%2FTKDE.2007.190669" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Knowl.+Data+Eng.&amp;title=SRDA:+An+efficient+algorithm+for+large-scale+discriminant+analysis&amp;author=D.+Cai&amp;author=X.+He&amp;author=J.+Han&amp;volume=20&amp;publication_year=2007&amp;pages=1-12&amp;doi=10.1109/TKDE.2007.190669&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B112-sensors-22-02069">112. <span class="element-citation">Cai D., He X., Han J. Efficient kernel discriminant analysis via spectral regression; Proceedings of the Seventh IEEE International Conference on Data Mining (ICDM 2007); Omaha, NE, USA. 28–31 October 2007; pp. 427–432. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+Seventh+IEEE+International+Conference+on+Data+Mining+(ICDM+2007)&amp;title=Efficient+kernel+discriminant+analysis+via+spectral+regression&amp;author=D.+Cai&amp;author=X.+He&amp;author=J.+Han&amp;pages=427-432&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B113-sensors-22-02069">113. <span class="element-citation">McDonald A.D., Schwarz C., Lee J.D., Brown T.L. Real-time detection of drowsiness related lane departures using steering wheel angle; Proceedings of the Human Factors and Ergonomics Society Annual Meeting; Boston, MA, USA. 22–26 October 2012; pp. 2201–2205. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+Human+Factors+and+Ergonomics+Society+Annual+Meeting&amp;title=Real-time+detection+of+drowsiness+related+lane+departures+using+steering+wheel+angle&amp;author=A.D.+McDonald&amp;author=C.+Schwarz&amp;author=J.D.+Lee&amp;author=T.L.+Brown&amp;pages=2201-2205&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B114-sensors-22-02069">114. <span class="element-citation">Ma J., Murphey Y.L., Zhao H. Real time drowsiness detection based on lateral distance using wavelet transform and neural network; Proceedings of the 2015 IEEE symposium series on computational intelligence; Cape Town, South Africa. 7–10 December 2015; pp. 411–418. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2015+IEEE+symposium+series+on+computational+intelligence&amp;title=Real+time+drowsiness+detection+based+on+lateral+distance+using+wavelet+transform+and+neural+network&amp;author=J.+Ma&amp;author=Y.L.+Murphey&amp;author=H.+Zhao&amp;pages=411-418&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B115-sensors-22-02069">115. <span class="element-citation">Brown T., Lee J., Schwarz C., Fiorentino D., McDonald A.  <span class="ref-journal">Final Report: Advanced Countermeasures for Multiple Impairments.</span> National Highway Traffic Safety Administration; Washington, DC, USA: 2011.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Final+Report:+Advanced+Countermeasures+for+Multiple+Impairments&amp;author=T.+Brown&amp;author=J.+Lee&amp;author=C.+Schwarz&amp;author=D.+Fiorentino&amp;author=A.+McDonald&amp;publication_year=2011&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B116-sensors-22-02069">116. <span class="element-citation">Murphey Y.L., Kochhar D., Chen F., Huang Y., Wang Y.  <span class="ref-journal">A Transportable Instrumentation Package for In-Vehicle On-Road Data Collection for Driver Research.</span> SAE; Warrendale, PA, USA: 2013.  Technical Paper: 0148-7191. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=A+Transportable+Instrumentation+Package+for+In-Vehicle+On-Road+Data+Collection+for+Driver+Research&amp;author=Y.L.+Murphey&amp;author=D.+Kochhar&amp;author=F.+Chen&amp;author=Y.+Huang&amp;author=Y.+Wang&amp;publication_year=2013&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B117-sensors-22-02069">117. <span class="element-citation">Li Z., Li S.E., Li R., Cheng B., Shi J. Online detection of driver fatigue using steering wheel angles for real driving conditions. <span><span class="ref-journal">Sensors. </span>2017;<span class="ref-vol">17</span>:495.  doi:&nbsp;10.3390/s17030495.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5375781/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28257094" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs17030495" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Online+detection+of+driver+fatigue+using+steering+wheel+angles+for+real+driving+conditions&amp;author=Z.+Li&amp;author=S.E.+Li&amp;author=R.+Li&amp;author=B.+Cheng&amp;author=J.+Shi&amp;volume=17&amp;publication_year=2017&amp;pages=495&amp;pmid=28257094&amp;doi=10.3390/s17030495&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B118-sensors-22-02069">118. <span class="element-citation">Arefnezhad S., Samiee S., Eichberger A., Nahvi A. Driver drowsiness detection based on steering wheel data applying adaptive neuro-fuzzy feature selection. <span><span class="ref-journal">Sensors. </span>2019;<span class="ref-vol">19</span>:943.  doi:&nbsp;10.3390/s19040943.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6412352/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/30813386" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs19040943" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Driver+drowsiness+detection+based+on+steering+wheel+data+applying+adaptive+neuro-fuzzy+feature+selection&amp;author=S.+Arefnezhad&amp;author=S.+Samiee&amp;author=A.+Eichberger&amp;author=A.+Nahvi&amp;volume=19&amp;publication_year=2019&amp;pages=943&amp;doi=10.3390/s19040943&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B119-sensors-22-02069">119. <span class="element-citation">Chai M. Drowsiness monitoring based on steering wheel status. <span><span class="ref-journal">Transp. Res. Part D Transp. Environ. </span>2019;<span class="ref-vol">66</span>:95–103. doi:&nbsp;10.1016/j.trd.2018.07.007.</span> [<a href="https://doi.org/10.1016%2Fj.trd.2018.07.007" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Transp.+Res.+Part+D+Transp.+Environ.&amp;title=Drowsiness+monitoring+based+on+steering+wheel+status&amp;author=M.+Chai&amp;volume=66&amp;publication_year=2019&amp;pages=95-103&amp;doi=10.1016/j.trd.2018.07.007&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B120-sensors-22-02069">120. <span class="element-citation">Wang X., Xu C. Driver drowsiness detection based on non-intrusive metrics considering individual specifics. <span><span class="ref-journal">Accid. Anal. Prev. </span>2016;<span class="ref-vol">95</span>:350–357. doi:&nbsp;10.1016/j.aap.2015.09.002.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/26433567" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.aap.2015.09.002" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Accid.+Anal.+Prev.&amp;title=Driver+drowsiness+detection+based+on+non-intrusive+metrics+considering+individual+specifics&amp;author=X.+Wang&amp;author=C.+Xu&amp;volume=95&amp;publication_year=2016&amp;pages=350-357&amp;pmid=26433567&amp;doi=10.1016/j.aap.2015.09.002&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B121-sensors-22-02069">121. <span class="element-citation">Zhang C., Wu X., Zheng X., Yu S. Driver drowsiness detection using multi-channel second order blind identifications. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:11829–11843. doi:&nbsp;10.1109/ACCESS.2019.2891971.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2891971" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Driver+drowsiness+detection+using+multi-channel+second+order+blind+identifications&amp;author=C.+Zhang&amp;author=X.+Wu&amp;author=X.+Zheng&amp;author=S.+Yu&amp;volume=7&amp;publication_year=2019&amp;pages=11829-11843&amp;doi=10.1109/ACCESS.2019.2891971&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B122-sensors-22-02069">122. <span class="element-citation">de Naurois C.J., Bourdin C., Stratulat A., Diaz E., Vercher J.-L. Detection and prediction of driver drowsiness using artificial neural network models. <span><span class="ref-journal">Accid. Anal. Prev. </span>2019;<span class="ref-vol">126</span>:95–104. doi:&nbsp;10.1016/j.aap.2017.11.038.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/29203032" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.aap.2017.11.038" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Accid.+Anal.+Prev.&amp;title=Detection+and+prediction+of+driver+drowsiness+using+artificial+neural+network+models&amp;author=C.J.+de+Naurois&amp;author=C.+Bourdin&amp;author=A.+Stratulat&amp;author=E.+Diaz&amp;author=J.-L.+Vercher&amp;volume=126&amp;publication_year=2019&amp;pages=95-104&amp;pmid=29203032&amp;doi=10.1016/j.aap.2017.11.038&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B123-sensors-22-02069">123. <span class="element-citation">Nguyen T., Ahn S., Jang H., Jun S.C., Kim J.G. Utilization of a combined EEG/NIRS system to predict driver drowsiness. <span><span class="ref-journal">Sci. Rep. </span>2017;<span class="ref-vol">7</span>:1–10. doi:&nbsp;10.1038/srep43933.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5339693/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28266633" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1038%2Fsrep43933" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sci.+Rep.&amp;title=Utilization+of+a+combined+EEG/NIRS+system+to+predict+driver+drowsiness&amp;author=T.+Nguyen&amp;author=S.+Ahn&amp;author=H.+Jang&amp;author=S.C.+Jun&amp;author=J.G.+Kim&amp;volume=7&amp;publication_year=2017&amp;pages=1-10&amp;pmid=28127051&amp;doi=10.1038/srep43933&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B124-sensors-22-02069">124. <span class="element-citation">Barua S., Ahmed M.U., Ahlström C., Begum S. Automatic driver sleepiness detection using EEG, EOG and contextual information. <span><span class="ref-journal">Expert Syst. Appl. </span>2019;<span class="ref-vol">115</span>:121–135. doi:&nbsp;10.1016/j.eswa.2018.07.054.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2018.07.054" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Automatic+driver+sleepiness+detection+using+EEG,+EOG+and+contextual+information&amp;author=S.+Barua&amp;author=M.U.+Ahmed&amp;author=C.+Ahlstr%C3%B6m&amp;author=S.+Begum&amp;volume=115&amp;publication_year=2019&amp;pages=121-135&amp;doi=10.1016/j.eswa.2018.07.054&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B125-sensors-22-02069">125. <span class="element-citation">Dasgupta A., Rahman D., Routray A. A smartphone-based drowsiness detection and warning system for automotive drivers. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2018;<span class="ref-vol">20</span>:4045–4054. doi:&nbsp;10.1109/TITS.2018.2879609.</span> [<a href="https://doi.org/10.1109%2FTITS.2018.2879609" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=A+smartphone-based+drowsiness+detection+and+warning+system+for+automotive+drivers&amp;author=A.+Dasgupta&amp;author=D.+Rahman&amp;author=A.+Routray&amp;volume=20&amp;publication_year=2018&amp;pages=4045-4054&amp;doi=10.1109/TITS.2018.2879609&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B126-sensors-22-02069">126. <span class="element-citation">INVEDRIFAC—A Video and Image Database of Faces of In-vehicle Automotive Drivers, India. 2019.  [(accessed on 20 September 2021)].  Available online:  <a href="https://sites.google.com/site/invedrifac/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">https://sites.google.com/site/invedrifac/</a></span></div><div class="ref-cit-blk half_rhythm" id="B127-sensors-22-02069">127. <span class="element-citation">Gwak J., Hirao A., Shino M. An investigation of early detection of driver drowsiness using ensemble machine learning based on hybrid sensing. <span><span class="ref-journal">Appl. Sci. </span>2020;<span class="ref-vol">10</span>:2890.  doi:&nbsp;10.3390/app10082890.</span> [<a href="https://doi.org/10.3390%2Fapp10082890" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Appl.+Sci.&amp;title=An+investigation+of+early+detection+of+driver+drowsiness+using+ensemble+machine+learning+based+on+hybrid+sensing&amp;author=J.+Gwak&amp;author=A.+Hirao&amp;author=M.+Shino&amp;volume=10&amp;publication_year=2020&amp;pages=2890&amp;doi=10.3390/app10082890&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B128-sensors-22-02069">128. <span class="element-citation">Zilberg E., Xu Z.M., Burton D., Karrar M., Lal S. Methodology and initial analysis results for development of non-invasive and hybrid driver drowsiness detection systems; Proceedings of the the 2nd International Conference on Wireless Broadband and Ultra Wideband Communications (AusWireless 2007); Sydney, Australia. 27–30 August 2007; p. 16. [<a href="https://doi.org/10.1109%2FAUSWIRELESS.2007.44" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+the+2nd+International+Conference+on+Wireless+Broadband+and+Ultra+Wideband+Communications+(AusWireless+2007)&amp;title=Methodology+and+initial+analysis+results+for+development+of+non-invasive+and+hybrid+driver+drowsiness+detection+systems&amp;author=E.+Zilberg&amp;author=Z.M.+Xu&amp;author=D.+Burton&amp;author=M.+Karrar&amp;author=S.+Lal&amp;pages=16&amp;doi=10.1109/AUSWIRELESS.2007.44&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B129-sensors-22-02069">129. <span class="element-citation">Volvo  Volvo Cars Introduces New Systems for Alerting Tired and Distracted Drivers.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.media.volvocars.com/us/en-us/media/pressreleases/12130" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.media.volvocars.com/us/en-us/media/pressreleases/12130</a></span></div><div class="ref-cit-blk half_rhythm" id="B130-sensors-22-02069">130. <span class="element-citation">Altameem A., Kumar A., Poonia R.C., Kumar S., Saudagar A.K.J. Early Identification and Detection of Driver Drowsiness by Hybrid Machine Learning. <span><span class="ref-journal">IEEE Access. </span>2021;<span class="ref-vol">9</span>:162805–162819. doi:&nbsp;10.1109/ACCESS.2021.3131601.</span> [<a href="https://doi.org/10.1109%2FACCESS.2021.3131601" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Early+Identification+and+Detection+of+Driver+Drowsiness+by+Hybrid+Machine+Learning&amp;author=A.+Altameem&amp;author=A.+Kumar&amp;author=R.C.+Poonia&amp;author=S.+Kumar&amp;author=A.K.J.+Saudagar&amp;volume=9&amp;publication_year=2021&amp;pages=162805-162819&amp;doi=10.1109/ACCESS.2021.3131601&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B131-sensors-22-02069">131. <span class="element-citation">Doudou M., Bouabdallah A., Berge-Cherfaoui V. Driver drowsiness measurement technologies: Current research, market solutions, and challenges. <span><span class="ref-journal">Int. J. Intell. Transp. Syst. Res. </span>2020;<span class="ref-vol">18</span>:297–319. doi:&nbsp;10.1007/s13177-019-00199-w.</span> [<a href="https://doi.org/10.1007%2Fs13177-019-00199-w" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Intell.+Transp.+Syst.+Res.&amp;title=Driver+drowsiness+measurement+technologies:+Current+research,+market+solutions,+and+challenges&amp;author=M.+Doudou&amp;author=A.+Bouabdallah&amp;author=V.+Berge-Cherfaoui&amp;volume=18&amp;publication_year=2020&amp;pages=297-319&amp;doi=10.1007/s13177-019-00199-w&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B132-sensors-22-02069">132. <span class="element-citation">Kashevnik A., Lashkov I., Ponomarev A., Teslya N., Gurtov A. Cloud-based driver monitoring system using a smartphone. <span><span class="ref-journal">IEEE Sens. J. </span>2020;<span class="ref-vol">20</span>:6701–6715. doi:&nbsp;10.1109/JSEN.2020.2975382.</span> [<a href="https://doi.org/10.1109%2FJSEN.2020.2975382" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Cloud-based+driver+monitoring+system+using+a+smartphone&amp;author=A.+Kashevnik&amp;author=I.+Lashkov&amp;author=A.+Ponomarev&amp;author=N.+Teslya&amp;author=A.+Gurtov&amp;volume=20&amp;publication_year=2020&amp;pages=6701-6715&amp;doi=10.1109/JSEN.2020.2975382&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B133-sensors-22-02069">133. <span class="element-citation">Tamanani R., Muresan R., Al-Dweik A. Estimation of Driver Vigilance Status Using Real-Time Facial Expression and Deep Learning. <span><span class="ref-journal">IEEE Sens. Lett. </span>2021;<span class="ref-vol">5</span>:1–4. doi:&nbsp;10.1109/LSENS.2021.3070419.</span> [<a href="https://doi.org/10.1109%2FLSENS.2021.3070419" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+Lett.&amp;title=Estimation+of+Driver+Vigilance+Status+Using+Real-Time+Facial+Expression+and+Deep+Learning&amp;author=R.+Tamanani&amp;author=R.+Muresan&amp;author=A.+Al-Dweik&amp;volume=5&amp;publication_year=2021&amp;pages=1-4&amp;doi=10.1109/LSENS.2021.3070419&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B134-sensors-22-02069">134. <span class="element-citation">Abbas Q., Alsheddy A. Driver fatigue detection systems using multi-sensors, smartphone, and cloud-based computing platforms: A comparative analysis. <span><span class="ref-journal">Sensors. </span>2021;<span class="ref-vol">21</span>:56.  doi:&nbsp;10.3390/s21010056.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7796320/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/33374270" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs21010056" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Driver+fatigue+detection+systems+using+multi-sensors,+smartphone,+and+cloud-based+computing+platforms:+A+comparative+analysis&amp;author=Q.+Abbas&amp;author=A.+Alsheddy&amp;volume=21&amp;publication_year=2021&amp;pages=56&amp;doi=10.3390/s21010056&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B135-sensors-22-02069">135. <span class="element-citation">Chang W.-J., Chen L.-B., Chiou Y.-Z. Design and implementation of a drowsiness-fatigue-detection system based on wearable smart glasses to increase road safety. <span><span class="ref-journal">IEEE Trans. Consum. Electron. </span>2018;<span class="ref-vol">64</span>:461–469. doi:&nbsp;10.1109/TCE.2018.2872162.</span> [<a href="https://doi.org/10.1109%2FTCE.2018.2872162" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Consum.+Electron.&amp;title=Design+and+implementation+of+a+drowsiness-fatigue-detection+system+based+on+wearable+smart+glasses+to+increase+road+safety&amp;author=W.-J.+Chang&amp;author=L.-B.+Chen&amp;author=Y.-Z.+Chiou&amp;volume=64&amp;publication_year=2018&amp;pages=461-469&amp;doi=10.1109/TCE.2018.2872162&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B136-sensors-22-02069">136. <span class="element-citation">Dong N., Li Y., Gao Z., Ip W.H., Yung K.L. A WPCA-based method for detecting fatigue driving from EEG-based internet of vehicles system. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:124702–124711. doi:&nbsp;10.1109/ACCESS.2019.2937914.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2937914" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=A+WPCA-based+method+for+detecting+fatigue+driving+from+EEG-based+internet+of+vehicles+system&amp;author=N.+Dong&amp;author=Y.+Li&amp;author=Z.+Gao&amp;author=W.H.+Ip&amp;author=K.L.+Yung&amp;volume=7&amp;publication_year=2019&amp;pages=124702-124711&amp;doi=10.1109/ACCESS.2019.2937914&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div></div></div><div style="display: none; width: 202px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbilinksmenu"><ul id="ui-ncbiinpagenav-2"><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#abstract-a.y.b.rtitle">Abstract</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec1-sensors-22-02069title">1. Introduction</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec2-sensors-22-02069title">2. Drowsiness Signs and Stages</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec3-sensors-22-02069title">3. Drowsiness Detection Measures</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec4-sensors-22-02069title">4. Challenges</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec5-sensors-22-02069title">5. Discussion</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec6-sensors-22-02069title">6. Future Trends in Drowsiness Detection Systems</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#sec7-sensors-22-02069title">7. Conclusions</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#glossary-a.aa.gtitle">Abbreviations</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#notes-a.aa.btitle">Author Contributions</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#notes-a.aa.ctitle">Funding</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#notes-a.aa.dtitle">Institutional Review Board Statement</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#notes-a.aa.etitle">Informed Consent Statement</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#notes-a.aa.ftitle">Conflicts of Interest</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#fn-group-a.aa.atitle">Footnotes</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#ref-list-a.aa.htitle">References</a></li></ul></div></div><!--post-content--><div class="courtesy-note whole_rhythm small"><hr><div class="half_rhythm">Articles from <span class="acknowledgment-journal-title">Sensors (Basel, Switzerland)</span> are provided here courtesy of <strong>Multidisciplinary Digital Publishing Institute  (MDPI)</strong></div><hr></div><div id="body-link-poppers"><span></span><div id="body-link-popper-B1-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">1. <span class="element-citation">National Highway Traffic Safety Administration  Drowsy Driving.  [(accessed on 10 May 2021)];<span></span> Available online:  <a href="https://www.nhtsa.gov/risky-driving/drowsy-driving" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.nhtsa.gov/risky-driving/drowsy-driving</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B1-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B2-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">2. <span class="element-citation">Tefft B.C.  <span class="ref-journal">Prevalence of Motor Vehicle Crashes Involving Drowsy Drivers, United States, 2009–2013.</span> Citeseer; Washington, DC, USA: 2014.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Prevalence+of+Motor+Vehicle+Crashes+Involving+Drowsy+Drivers,+United+States,+2009%E2%80%932013&amp;author=B.C.+Tefft&amp;publication_year=2014&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B2-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B3-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">3. <span class="element-citation">National Institutes of Health  Drowsiness.  [(accessed on 10 May 2021)];<span></span> Available online:  <a href="https://medlineplus.gov/ency/article/003208.htm#:~:text=Drowsiness%20refers%20to%20feeling%20abnormally,situations%20or%20at%20inappropriate%20times" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://medlineplus.gov/ency/article/003208.htm#:~:text=Drowsiness%20refers%20to%20feeling%20abnormally,situations%20or%20at%20inappropriate%20times</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B3-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B4-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">4. <span class="element-citation">Arakawa T. Trends and future prospects of the drowsiness detection and estimation technology. <span><span class="ref-journal">Sensors. </span>2021;<span class="ref-vol">21</span>:7921.  doi:&nbsp;10.3390/s21237921.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8659813/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/34883924" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs21237921" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Trends+and+future+prospects+of+the+drowsiness+detection+and+estimation+technology&amp;author=T.+Arakawa&amp;volume=21&amp;publication_year=2021&amp;pages=7921&amp;pmid=34883924&amp;doi=10.3390/s21237921&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B4-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B5-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">5. <span class="element-citation">National Safety Council  Drivers are Falling Asleep Behind the Wheel.  [(accessed on 10 May 2021)].  Available online:  <a href="https://www.nsc.org/road-safety/safety-topics/fatigued-driving" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.nsc.org/road-safety/safety-topics/fatigued-driving</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B5-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B6-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">6. <span class="element-citation">National Sleep Foundation  Drowsy Driving.  [(accessed on 10 May 2021)].  Available online:  <a href="https://www.sleepfoundation.org/articles/drowsy-driving" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.sleepfoundation.org/articles/drowsy-driving</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B6-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B7-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">7. <span class="element-citation">Fuletra J.D., Bosamiya D. A survey on drivers drowsiness detection techniques. <span><span class="ref-journal">Int. J. Recent Innov. Trends Comput. Commun. </span>2013;<span class="ref-vol">1</span>:816–819.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Recent+Innov.+Trends+Comput.+Commun.&amp;title=A+survey+on+drivers+drowsiness+detection+techniques&amp;author=J.D.+Fuletra&amp;author=D.+Bosamiya&amp;volume=1&amp;publication_year=2013&amp;pages=816-819&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B7-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B8-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">8. <span class="element-citation">Pratama B.G., Ardiyanto I., Adji T.B. A review on driver drowsiness based on image, bio-signal, and driver behavior; Proceedings of the 2017 3rd International Conference on Science and Technology-Computer (ICST); Bandung, Indonesia. 25–26 October 2017; pp. 70–75. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2017+3rd+International+Conference+on+Science+and+Technology-Computer+(ICST)&amp;title=A+review+on+driver+drowsiness+based+on+image,+bio-signal,+and+driver+behavior&amp;author=B.G.+Pratama&amp;author=I.+Ardiyanto&amp;author=T.B.+Adji&amp;pages=70-75&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B8-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B9-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">9. <span class="element-citation">Ramzan M., Khan H.U., Awan S.M., Ismail A., Ilyas M., Mahmood A. A survey on state-of-the-art drowsiness detection techniques. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:61904–61919. doi:&nbsp;10.1109/ACCESS.2019.2914373.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2914373" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=A+survey+on+state-of-the-art+drowsiness+detection+techniques&amp;author=M.+Ramzan&amp;author=H.U.+Khan&amp;author=S.M.+Awan&amp;author=A.+Ismail&amp;author=M.+Ilyas&amp;volume=7&amp;publication_year=2019&amp;pages=61904-61919&amp;doi=10.1109/ACCESS.2019.2914373&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B9-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B10-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">10. <span class="element-citation">Sikander G., Anwar S. Driver fatigue detection systems: A review. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2018;<span class="ref-vol">20</span>:2339–2352. doi:&nbsp;10.1109/TITS.2018.2868499.</span> [<a href="https://doi.org/10.1109%2FTITS.2018.2868499" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=Driver+fatigue+detection+systems:+A+review&amp;author=G.+Sikander&amp;author=S.+Anwar&amp;volume=20&amp;publication_year=2018&amp;pages=2339-2352&amp;doi=10.1109/TITS.2018.2868499&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B10-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B11-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">11. <span class="element-citation">Ukwuoma C.C., Bo C. Deep Learning Review on Drivers Drowsiness Detection; Proceedings of the 2019 4th Technology Innovation Management and Engineering Science International Conference (TIMES-iCON); Bangkok, Thailand. 11–13 December 2019; pp. 1–5. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2019+4th+Technology+Innovation+Management+and+Engineering+Science+International+Conference+(TIMES-iCON)&amp;title=Deep+Learning+Review+on+Drivers+Drowsiness+Detection&amp;author=C.C.+Ukwuoma&amp;author=C.+Bo&amp;pages=1-5&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B11-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B12-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">12. <span class="element-citation">Dong Y., Hu Z., Uchimura K., Murayama N. Driver inattention monitoring system for intelligent vehicles: A review. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2010;<span class="ref-vol">12</span>:596–614. doi:&nbsp;10.1109/TITS.2010.2092770.</span> [<a href="https://doi.org/10.1109%2FTITS.2010.2092770" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=Driver+inattention+monitoring+system+for+intelligent+vehicles:+A+review&amp;author=Y.+Dong&amp;author=Z.+Hu&amp;author=K.+Uchimura&amp;author=N.+Murayama&amp;volume=12&amp;publication_year=2010&amp;pages=596-614&amp;doi=10.1109/TITS.2010.2092770&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B12-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B13-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">13. <span class="element-citation">Nordbakke S., Sagberg F. Sleepy at the wheel: Knowledge, symptoms and behaviour among car drivers. <span><span class="ref-journal">Transportation Research Part F: Traffic Psychology and Behaviour. </span>2007;<span class="ref-vol">10</span>:1–10. doi:&nbsp;10.1016/j.trf.2006.03.003.</span> [<a href="https://doi.org/10.1016%2Fj.trf.2006.03.003" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Transportation+Research+Part+F:+Traffic+Psychology+and+Behaviour&amp;title=Sleepy+at+the+wheel:+Knowledge,+symptoms+and+behaviour+among+car+drivers&amp;author=S.+Nordbakke&amp;author=F.+Sagberg&amp;volume=10&amp;publication_year=2007&amp;pages=1-10&amp;doi=10.1016/j.trf.2006.03.003&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B13-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B14-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">14. <span class="element-citation">Chacon-Murguia M.I., Prieto-Resendiz C. Detecting Driver Drowsiness: A survey of system designs and technology. <span><span class="ref-journal">IEEE Consum. Electron. Mag. </span>2015;<span class="ref-vol">4</span>:107–119. doi:&nbsp;10.1109/MCE.2015.2463373.</span> [<a href="https://doi.org/10.1109%2FMCE.2015.2463373" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Consum.+Electron.+Mag.&amp;title=Detecting+Driver+Drowsiness:+A+survey+of+system+designs+and+technology&amp;author=M.I.+Chacon-Murguia&amp;author=C.+Prieto-Resendiz&amp;volume=4&amp;publication_year=2015&amp;pages=107-119&amp;doi=10.1109/MCE.2015.2463373&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B14-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B15-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">15. <span class="element-citation">Beirness D.J., Simpson H.M., Desmond K., The Road Safety Monitor 2004: Drowsy Driving  Drowsy Driving. 2005.  [(accessed on 2 March 2022)].  Available online:  <a href="http://worldcat.org/isbn/0920071473" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">http://worldcat.org/isbn/0920071473</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B15-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B16-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">16. <span class="element-citation">Knapik M., Cyganek B. Driver’s fatigue recognition based on yawn detection in thermal images. <span><span class="ref-journal">Neurocomputing. </span>2019;<span class="ref-vol">338</span>:274–292. doi:&nbsp;10.1016/j.neucom.2019.02.014.</span> [<a href="https://doi.org/10.1016%2Fj.neucom.2019.02.014" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neurocomputing&amp;title=Driver%E2%80%99s+fatigue+recognition+based+on+yawn+detection+in+thermal+images&amp;author=M.+Knapik&amp;author=B.+Cyganek&amp;volume=338&amp;publication_year=2019&amp;pages=274-292&amp;doi=10.1016/j.neucom.2019.02.014&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B16-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B17-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">17. <span class="element-citation">Liu W., Qian J., Yao Z., Jiao X., Pan J. Convolutional two-stream network using multi-facial feature fusion for driver fatigue detection. <span><span class="ref-journal">Future Internet. </span>2019;<span class="ref-vol">11</span>:115.  doi:&nbsp;10.3390/fi11050115.</span> [<a href="https://doi.org/10.3390%2Ffi11050115" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Future+Internet&amp;title=Convolutional+two-stream+network+using+multi-facial+feature+fusion+for+driver+fatigue+detection&amp;author=W.+Liu&amp;author=J.+Qian&amp;author=Z.+Yao&amp;author=X.+Jiao&amp;author=J.+Pan&amp;volume=11&amp;publication_year=2019&amp;pages=115&amp;doi=10.3390/fi11050115&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B17-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B18-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">18. <span class="element-citation">You F., Gong Y., Tu H., Liang J., Wang H. A fatigue driving detection algorithm based on facial motion information entropy. <span><span class="ref-journal">J. Adv. Transp. </span>2020;<span class="ref-vol">2020</span>:1–17. doi:&nbsp;10.1155/2020/8851485.</span> [<a href="https://doi.org/10.1155%2F2020%2F8851485" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Adv.+Transp.&amp;title=A+fatigue+driving+detection+algorithm+based+on+facial+motion+information+entropy&amp;author=F.+You&amp;author=Y.+Gong&amp;author=H.+Tu&amp;author=J.+Liang&amp;author=H.+Wang&amp;volume=2020&amp;publication_year=2020&amp;pages=1-17&amp;doi=10.1155/2020/8851485&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B18-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B19-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">19. <span class="element-citation">Mittal A., Kumar K., Dhamija S., Kaur M. Head movement-based driver drowsiness detection: A review of state-of-art techniques; Proceedings of the 2016 IEEE International Conference on Engineering and Technology (ICETECH); Coimbatore, India. 17–18 March 2016; pp. 903–908. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2016+IEEE+International+Conference+on+Engineering+and+Technology+(ICETECH)&amp;title=Head+movement-based+driver+drowsiness+detection:+A+review+of+state-of-art+techniques&amp;author=A.+Mittal&amp;author=K.+Kumar&amp;author=S.+Dhamija&amp;author=M.+Kaur&amp;pages=903-908&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B19-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B20-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">20. <span class="element-citation">Otmani S., Pebayle T., Roge J., Muzet A. Effect of driving duration and partial sleep deprivation on subsequent alertness and performance of car drivers. <span><span class="ref-journal">Physiol. Behav. </span>2005;<span class="ref-vol">84</span>:715–724. doi:&nbsp;10.1016/j.physbeh.2005.02.021.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/15885247" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.physbeh.2005.02.021" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Physiol.+Behav.&amp;title=Effect+of+driving+duration+and+partial+sleep+deprivation+on+subsequent+alertness+and+performance+of+car+drivers&amp;author=S.+Otmani&amp;author=T.+Pebayle&amp;author=J.+Roge&amp;author=A.+Muzet&amp;volume=84&amp;publication_year=2005&amp;pages=715-724&amp;pmid=15885247&amp;doi=10.1016/j.physbeh.2005.02.021&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B20-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B21-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">21. <span class="element-citation">Kaida K., Takahashi M., Åkerstedt T., Nakata A., Otsuka Y., Haratani T., Fukasawa K. Validation of the Karolinska sleepiness scale against performance and EEG variables. <span><span class="ref-journal">Clin. Neurophysiol. </span>2006;<span class="ref-vol">117</span>:1574–1581. doi:&nbsp;10.1016/j.clinph.2006.03.011.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/16679057" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.clinph.2006.03.011" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Clin.+Neurophysiol.&amp;title=Validation+of+the+Karolinska+sleepiness+scale+against+performance+and+EEG+variables&amp;author=K.+Kaida&amp;author=M.+Takahashi&amp;author=T.+%C3%85kerstedt&amp;author=A.+Nakata&amp;author=Y.+Otsuka&amp;volume=117&amp;publication_year=2006&amp;pages=1574-1581&amp;pmid=16679057&amp;doi=10.1016/j.clinph.2006.03.011&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B21-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B22-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">22. <span class="element-citation">Shahid A., Wilkinson K., Marcu S., Shapiro C.M.  <span class="ref-journal">STOP, THAT and One Hundred Other Sleep Scales.</span> Springer; Berlin/Heidelberg, Germany: 2011. Karolinska sleepiness scale (KSS) pp. 209–210. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=STOP,+THAT+and+One+Hundred+Other+Sleep+Scales&amp;author=A.+Shahid&amp;author=K.+Wilkinson&amp;author=S.+Marcu&amp;author=C.M.+Shapiro&amp;publication_year=2011&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B22-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B23-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">23. <span class="element-citation">Wierwille W.W., Ellsworth L.A. Evaluation of driver drowsiness by trained raters. <span><span class="ref-journal">Accid. Anal. Prev. </span>1994;<span class="ref-vol">26</span>:571–581. doi:&nbsp;10.1016/0001-4575(94)90019-1.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/7999202" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2F0001-4575(94)90019-1" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Accid.+Anal.+Prev.&amp;title=Evaluation+of+driver+drowsiness+by+trained+raters&amp;author=W.W.+Wierwille&amp;author=L.A.+Ellsworth&amp;volume=26&amp;publication_year=1994&amp;pages=571-581&amp;pmid=7999202&amp;doi=10.1016/0001-4575(94)90019-1&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B23-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B24-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">24. <span class="element-citation">Saito Y., Itoh M., Inagaki T. Driver assistance system with a dual control scheme: Effectiveness of identifying driver drowsiness and preventing lane departure accidents. <span><span class="ref-journal">IEEE Trans. Hum. Mach. Syst. </span>2016;<span class="ref-vol">46</span>:660–671. doi:&nbsp;10.1109/THMS.2016.2549032.</span> [<a href="https://doi.org/10.1109%2FTHMS.2016.2549032" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Hum.+Mach.+Syst.&amp;title=Driver+assistance+system+with+a+dual+control+scheme:+Effectiveness+of+identifying+driver+drowsiness+and+preventing+lane+departure+accidents&amp;author=Y.+Saito&amp;author=M.+Itoh&amp;author=T.+Inagaki&amp;volume=46&amp;publication_year=2016&amp;pages=660-671&amp;doi=10.1109/THMS.2016.2549032&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B24-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B25-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">25. <span class="element-citation">Sunagawa M., Shikii S., Nakai W., Mochizuki M., Kusukame K., Kitajima H. Comprehensive Drowsiness Level Detection Model Combining Multimodal Information. <span><span class="ref-journal">IEEE Sens. J. </span>2020;<span class="ref-vol">20</span>:3709–3717. doi:&nbsp;10.1109/JSEN.2019.2960158.</span> [<a href="https://doi.org/10.1109%2FJSEN.2019.2960158" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Comprehensive+Drowsiness+Level+Detection+Model+Combining+Multimodal+Information&amp;author=M.+Sunagawa&amp;author=S.+Shikii&amp;author=W.+Nakai&amp;author=M.+Mochizuki&amp;author=K.+Kusukame&amp;volume=20&amp;publication_year=2020&amp;pages=3709-3717&amp;doi=10.1109/JSEN.2019.2960158&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B25-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B26-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">26. <span class="element-citation">Machine Learning Crash Course  Classification: Accuracy.  [(accessed on 2 March 2022)].  Available online:  <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">https://developers.google.com/machine-learning/crash-course/classification/accuracy</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B26-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B27-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">27. <span class="element-citation">Machine Learning Crash Course  Classification: Precision and Recall.  [(accessed on 2 March 2022)].  Available online:  <a href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B27-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B28-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">28. <span class="element-citation">Leng L.B., Giin L.B., Chung W.-Y. Wearable driver drowsiness detection system based on biomedical and motion sensors; Proceedings of the 2015 IEEE SENSORS; Busan, Korea. 1–4 November 2015; pp. 1–4. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2015+IEEE+SENSORS&amp;title=Wearable+driver+drowsiness+detection+system+based+on+biomedical+and+motion+sensors&amp;author=L.B.+Leng&amp;author=L.B.+Giin&amp;author=W.-Y.+Chung&amp;pages=1-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B28-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B29-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">29. <span class="element-citation">Mehreen A., Anwar S.M., Haseeb M., Majid M., Ullah M.O. A hybrid scheme for drowsiness detection using wearable sensors. <span><span class="ref-journal">IEEE Sens. J. </span>2019;<span class="ref-vol">19</span>:5119–5126. doi:&nbsp;10.1109/JSEN.2019.2904222.</span> [<a href="https://doi.org/10.1109%2FJSEN.2019.2904222" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=A+hybrid+scheme+for+drowsiness+detection+using+wearable+sensors&amp;author=A.+Mehreen&amp;author=S.M.+Anwar&amp;author=M.+Haseeb&amp;author=M.+Majid&amp;author=M.O.+Ullah&amp;volume=19&amp;publication_year=2019&amp;pages=5119-5126&amp;doi=10.1109/JSEN.2019.2904222&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B29-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B30-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">30. <span class="element-citation">Bamidele A., Kamardin K., Syazarin N., Mohd S., Shafi I., Azizan A., Aini N., Mad H. Non-intrusive driver drowsiness detection based on face and eye tracking. <span><span class="ref-journal">Int J. Adv. Comput. Sci. Appl. </span>2019;<span class="ref-vol">10</span>:549–569. doi:&nbsp;10.14569/IJACSA.2019.0100775.</span> [<a href="https://doi.org/10.14569%2FIJACSA.2019.0100775" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int+J.+Adv.+Comput.+Sci.+Appl.&amp;title=Non-intrusive+driver+drowsiness+detection+based+on+face+and+eye+tracking&amp;author=A.+Bamidele&amp;author=K.+Kamardin&amp;author=N.+Syazarin&amp;author=S.+Mohd&amp;author=I.+Shafi&amp;volume=10&amp;publication_year=2019&amp;pages=549-569&amp;doi=10.14569/IJACSA.2019.0100775&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B30-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B31-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">31. <span class="element-citation">Lin S.T., Tan Y.Y., Chua P.Y., Tey L.K., Ang C.H. Perclos threshold for drowsiness detection during real driving. <span><span class="ref-journal">J. Vis. </span>2012;<span class="ref-vol">12</span>:546. doi:&nbsp;10.1167/12.9.546.</span> [<a href="https://doi.org/10.1167%2F12.9.546" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Vis.&amp;title=Perclos+threshold+for+drowsiness+detection+during+real+driving&amp;author=S.T.+Lin&amp;author=Y.Y.+Tan&amp;author=P.Y.+Chua&amp;author=L.K.+Tey&amp;author=C.H.+Ang&amp;volume=12&amp;publication_year=2012&amp;pages=546&amp;doi=10.1167/12.9.546&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B31-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B32-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">32. <span class="element-citation">Rosebrock A. Eyeblink Detection with OpenCV, Python, and dlib.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/_mjzu4CFQAAAAAdAAAAABAK" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/_mjzu4CFQAAAAAdAAAAABAK</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B32-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B33-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">33. <span class="element-citation">Moujahid A., Dornaika F., Arganda-Carreras I., Reta J. Efficient and compact face descriptor for driver drowsiness detection. <span><span class="ref-journal">Expert Syst. Appl. </span>2021;<span class="ref-vol">168</span>:114334.  doi:&nbsp;10.1016/j.eswa.2020.114334.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2020.114334" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Efficient+and+compact+face+descriptor+for+driver+drowsiness+detection&amp;author=A.+Moujahid&amp;author=F.+Dornaika&amp;author=I.+Arganda-Carreras&amp;author=J.+Reta&amp;volume=168&amp;publication_year=2021&amp;pages=114334&amp;doi=10.1016/j.eswa.2020.114334&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B33-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B34-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">34. <span class="element-citation">Popieul J.C., Simon P., Loslever P. Using driver’s head movements evolution as a drowsiness indicator; Proceedings of the IEEE IV2003 Intelligent Vehicles Symposium; Columbus, OH, USA. 9–11 June 2003; pp. 616–621. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+IV2003+Intelligent+Vehicles+Symposium&amp;title=Using+driver%E2%80%99s+head+movements+evolution+as+a+drowsiness+indicator&amp;author=J.C.+Popieul&amp;author=P.+Simon&amp;author=P.+Loslever&amp;pages=616-621&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B34-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B35-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">35. <span class="element-citation">Weng C.-H., Lai Y.-H., Lai S.-H. Driver drowsiness detection via a hierarchical temporal deep belief network; Proceedings of the Asian Conference on Computer Vision; Taipei, Taiwan. 20–24 November 2016; pp. 117–133. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+Asian+Conference+on+Computer+Vision&amp;title=Driver+drowsiness+detection+via+a+hierarchical+temporal+deep+belief+network&amp;author=C.-H.+Weng&amp;author=Y.-H.+Lai&amp;author=S.-H.+Lai&amp;pages=117-133&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B35-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B37-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">37. <span class="element-citation">Wikipedia  Voxel.  [(accessed on 20 September 2021)].  Available online:  <a href="https://en.wikipedia.org/wiki/Voxel" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://en.wikipedia.org/wiki/Voxel</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B37-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B36-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">36. <span class="element-citation">Knapik M.  <span class="ref-journal">Thermal Images Database.</span> GitHub; Krakow, Poland: 2018.  [(accessed on 20 September 2021)].  Available online:  <a href="https://github.com/mat02/ThermalImagingInCar" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/mat02/ThermalImagingInCar</a> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Thermal+Images+Database&amp;author=M.+Knapik&amp;publication_year=2018&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B36-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B38-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">38. <span class="element-citation">Kiashari S.E.H., Nahvi A., Bakhoda H., Homayounfard A., Tashakori M. Evaluation of driver drowsiness using respiration analysis by thermal imaging on a driving simulator. <span><span class="ref-journal">Multimed. Tools Appl. </span>2020;<span class="ref-vol">79</span>:17793–17815. doi:&nbsp;10.1007/s11042-020-08696-x.</span> [<a href="https://doi.org/10.1007%2Fs11042-020-08696-x" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Multimed.+Tools+Appl.&amp;title=Evaluation+of+driver+drowsiness+using+respiration+analysis+by+thermal+imaging+on+a+driving+simulator&amp;author=S.E.H.+Kiashari&amp;author=A.+Nahvi&amp;author=H.+Bakhoda&amp;author=A.+Homayounfard&amp;author=M.+Tashakori&amp;volume=79&amp;publication_year=2020&amp;pages=17793-17815&amp;doi=10.1007/s11042-020-08696-x&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B38-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B39-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">39. <span class="element-citation">Tayab Khan M., Anwar H., Ullah F., Ur Rehman A., Ullah R., Iqbal A., Lee B.-H., Kwak K.S. Smart real-time video surveillance platform for drowsiness detection based on eyelid closure. <span><span class="ref-journal">Wirel. Commun. Mob. Comput. </span>2019;<span class="ref-vol">2019</span>:1–9. doi:&nbsp;10.1155/2019/2036818.</span> [<a href="https://doi.org/10.1155%2F2019%2F2036818" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Wirel.+Commun.+Mob.+Comput.&amp;title=Smart+real-time+video+surveillance+platform+for+drowsiness+detection+based+on+eyelid+closure&amp;author=M.+Tayab+Khan&amp;author=H.+Anwar&amp;author=F.+Ullah&amp;author=A.+Ur+Rehman&amp;author=R.+Ullah&amp;volume=2019&amp;publication_year=2019&amp;pages=1-9&amp;doi=10.1155/2019/2036818&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B39-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B40-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">40. <span class="element-citation">Song F., Tan X., Liu X., Chen S. Eyes closeness detection from still images with multi-scale histograms of principal oriented gradients. <span><span class="ref-journal">Pattern Recognit. </span>2014;<span class="ref-vol">47</span>:2825–2838. doi:&nbsp;10.1016/j.patcog.2014.03.024.</span> [<a href="https://doi.org/10.1016%2Fj.patcog.2014.03.024" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Pattern+Recognit.&amp;title=Eyes+closeness+detection+from+still+images+with+multi-scale+histograms+of+principal+oriented+gradients&amp;author=F.+Song&amp;author=X.+Tan&amp;author=X.+Liu&amp;author=S.+Chen&amp;volume=47&amp;publication_year=2014&amp;pages=2825-2838&amp;doi=10.1016/j.patcog.2014.03.024&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B40-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B41-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">41. <span class="element-citation">Ouabida E., Essadike A., Bouzid A. Optical correlator based algorithm for driver drowsiness detection. <span><span class="ref-journal">Optik. </span>2020;<span class="ref-vol">204</span>:164102.  doi:&nbsp;10.1016/j.ijleo.2019.164102.</span> [<a href="https://doi.org/10.1016%2Fj.ijleo.2019.164102" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Optik&amp;title=Optical+correlator+based+algorithm+for+driver+drowsiness+detection&amp;author=E.+Ouabida&amp;author=A.+Essadike&amp;author=A.+Bouzid&amp;volume=204&amp;publication_year=2020&amp;pages=164102&amp;doi=10.1016/j.ijleo.2019.164102&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B41-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B44-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">44. <span class="element-citation">Thomaz C.E., Giraldi G.A. A new ranking method for principal components analysis and its application to face image analysis. <span><span class="ref-journal">Image Vis. Comput. </span>2010;<span class="ref-vol">28</span>:902–913. doi:&nbsp;10.1016/j.imavis.2009.11.005.</span> [<a href="https://doi.org/10.1016%2Fj.imavis.2009.11.005" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Image+Vis.+Comput.&amp;title=A+new+ranking+method+for+principal+components+analysis+and+its+application+to+face+image+analysis&amp;author=C.E.+Thomaz&amp;author=G.A.+Giraldi&amp;volume=28&amp;publication_year=2010&amp;pages=902-913&amp;doi=10.1016/j.imavis.2009.11.005&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B44-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B45-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">45. <span class="element-citation">Gourier N., Hall D., Crowley J.L. Estimating face orientation from robust detection of salient facial features; Proceedings of the ICPR International Workshop on Visual Observation of Deictic Gestures; Cambridge, UK. 22 August 2004. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+ICPR+International+Workshop+on+Visual+Observation+of+Deictic+Gestures&amp;title=Estimating+face+orientation+from+robust+detection+of+salient+facial+features&amp;author=N.+Gourier&amp;author=D.+Hall&amp;author=J.L.+Crowley&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B45-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B46-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">46. <span class="element-citation">Jesorsky O., Kirchberg K.J., Frischholz R.W. Robust face detection using the hausdorff distance; Proceedings of the International conference on audio-and video-based biometric person authentication; Halmstad, Sweden. 6–8 June 2001; pp. 90–95. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+International+conference+on+audio-and+video-based+biometric+person+authentication&amp;title=Robust+face+detection+using+the+hausdorff+distance&amp;author=O.+Jesorsky&amp;author=K.J.+Kirchberg&amp;author=R.W.+Frischholz&amp;pages=90-95&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B46-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B47-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">47. <span class="element-citation">Villanueva A., Ponz V., Sesma-Sanchez L., Ariz M., Porta S., Cabeza R. Hybrid method based on topography for robust detection of iris center and eye corners. <span><span class="ref-journal">ACM Trans. Multimed. Comput. Commun. Appl. </span>2013;<span class="ref-vol">9</span>:1–20. doi:&nbsp;10.1145/2501643.2501647.</span> [<a href="https://doi.org/10.1145%2F2501643.2501647" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=ACM+Trans.+Multimed.+Comput.+Commun.+Appl.&amp;title=Hybrid+method+based+on+topography+for+robust+detection+of+iris+center+and+eye+corners&amp;author=A.+Villanueva&amp;author=V.+Ponz&amp;author=L.+Sesma-Sanchez&amp;author=M.+Ariz&amp;author=S.+Porta&amp;volume=9&amp;publication_year=2013&amp;pages=1-20&amp;doi=10.1145/2501643.2501647&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B47-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B48-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">48. <span class="element-citation">SHRP2: Transportation Research Board of the National Academies of Science  . <span class="ref-journal">The 2nd Strategic Highway Research Program Naturalistic Driving Study Dataset.</span> Virginia Tech Transportation Institute; Blacksburg, VA, USA: 2018.  [(accessed on 20 September 2021)].  Available online:  <a href="https://insight.shrp2nds.us/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://insight.shrp2nds.us/</a> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=The+2nd+Strategic+Highway+Research+Program+Naturalistic+Driving+Study+Dataset&amp;publication_year=2018&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B48-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B49-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">49. <span class="element-citation">Maior C.B.S., das Chagas Moura M.J., Santana J.M.M., Lins I.D. Real-time classification for autonomous drowsiness detection using eye aspect ratio. <span><span class="ref-journal">Expert Syst. Appl. </span>2020;<span class="ref-vol">158</span>:113505.  doi:&nbsp;10.1016/j.eswa.2020.113505.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2020.113505" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Real-time+classification+for+autonomous+drowsiness+detection+using+eye+aspect+ratio&amp;author=C.B.S.+Maior&amp;author=M.J.+das+Chagas+Moura&amp;author=J.M.M.+Santana&amp;author=I.D.+Lins&amp;volume=158&amp;publication_year=2020&amp;pages=113505&amp;doi=10.1016/j.eswa.2020.113505&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B49-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B50-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">50. <span class="element-citation">Hashemi M., Mirrashid A., Shirazi A.B. Driver Safety Development: Real-Time Driver Drowsiness Detection System Based on Convolutional Neural Network. <span><span class="ref-journal">SN Comput. Sci. </span>2020;<span class="ref-vol">1</span>:1–10. doi:&nbsp;10.1007/s42979-020-00306-9.</span> [<a href="https://doi.org/10.1007%2Fs42979-020-00306-9" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=SN+Comput.+Sci.&amp;title=Driver+Safety+Development:+Real-Time+Driver+Drowsiness+Detection+System+Based+on+Convolutional+Neural+Network&amp;author=M.+Hashemi&amp;author=A.+Mirrashid&amp;author=A.B.+Shirazi&amp;volume=1&amp;publication_year=2020&amp;pages=1-10&amp;doi=10.1007/s42979-020-00306-9&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B50-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B51-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">51. <span class="element-citation">Zandi A.S., Quddus A., Prest L., Comeau F.J. Non-intrusive detection of drowsy driving based on eye tracking data. <span><span class="ref-journal">Transp. Res. Rec. </span>2019;<span class="ref-vol">2673</span>:247–257. doi:&nbsp;10.1177/0361198119847985.</span> [<a href="https://doi.org/10.1177%2F0361198119847985" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Transp.+Res.+Rec.&amp;title=Non-intrusive+detection+of+drowsy+driving+based+on+eye+tracking+data&amp;author=A.S.+Zandi&amp;author=A.+Quddus&amp;author=L.+Prest&amp;author=F.J.+Comeau&amp;volume=2673&amp;publication_year=2019&amp;pages=247-257&amp;doi=10.1177/0361198119847985&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B51-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B52-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">52. <span class="element-citation">Celecia A., Figueiredo K., Vellasco M., González R. A portable fuzzy driver drowsiness estimation system. <span><span class="ref-journal">Sensors. </span>2020;<span class="ref-vol">20</span>:4093.  doi:&nbsp;10.3390/s20154093.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7435375/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32717787" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs20154093" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=A+portable+fuzzy+driver+drowsiness+estimation+system&amp;author=A.+Celecia&amp;author=K.+Figueiredo&amp;author=M.+Vellasco&amp;author=R.+Gonz%C3%A1lez&amp;volume=20&amp;publication_year=2020&amp;pages=4093&amp;pmid=32717787&amp;doi=10.3390/s20154093&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B52-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B53-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">53. <span class="element-citation">Sagonas C., Tzimiropoulos G., Zafeiriou S., Pantic M. 300 faces in-the-wild challenge: The first facial landmark localization challenge; Proceedings of the IEEE International Conference on Computer Vision Workshops; Sydney, Australia. 2–8 December 2013; pp. 397–403. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision+Workshops&amp;title=300+faces+in-the-wild+challenge:+The+first+facial+landmark+localization+challenge&amp;author=C.+Sagonas&amp;author=G.+Tzimiropoulos&amp;author=S.+Zafeiriou&amp;author=M.+Pantic&amp;pages=397-403&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B53-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B54-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">54. <span class="element-citation">Alioua N., Amine A., Rziza M., Aboutajdine D. Driver’s fatigue and drowsiness detection to reduce traffic accidents on road; Proceedings of the International Conference on Computer Analysis of Images and Patterns; Seville, Spain. 29–31 August 2011; pp. 397–404. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+International+Conference+on+Computer+Analysis+of+Images+and+Patterns&amp;title=Driver%E2%80%99s+fatigue+and+drowsiness+detection+to+reduce+traffic+accidents+on+road&amp;author=N.+Alioua&amp;author=A.+Amine&amp;author=M.+Rziza&amp;author=D.+Aboutajdine&amp;pages=397-404&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B54-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B55-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">55. <span class="element-citation">Khunpisuth O., Chotchinasri T., Koschakosai V., Hnoohom N. Driver drowsiness detection using eye-closeness detection; Proceedings of the 2016 12th International Conference on Signal-Image Technology &amp; Internet-Based Systems (SITIS); Naples, Italy. 28 November–1 December 2016; pp. 661–668. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2016+12th+International+Conference+on+Signal-Image+Technology+&amp;+Internet-Based+Systems+(SITIS)&amp;title=Driver+drowsiness+detection+using+eye-closeness+detection&amp;author=O.+Khunpisuth&amp;author=T.+Chotchinasri&amp;author=V.+Koschakosai&amp;author=N.+Hnoohom&amp;pages=661-668&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B55-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B56-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">56. <span class="element-citation">Deng W., Wu R. Real-time driver-drowsiness detection system using facial features. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:118727–118738. doi:&nbsp;10.1109/ACCESS.2019.2936663.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2936663" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Real-time+driver-drowsiness+detection+system+using+facial+features&amp;author=W.+Deng&amp;author=R.+Wu&amp;volume=7&amp;publication_year=2019&amp;pages=118727-118738&amp;doi=10.1109/ACCESS.2019.2936663&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B56-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B57-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">57. <span class="element-citation">Liu Z., Luo P., Wang X., Tang X. Deep learning face attributes in the wild; Proceedings of the IEEE International Conference on Computer Vision; Santiago, Chile. 7–13 December 2015; pp. 3730–3738. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision&amp;title=Deep+learning+face+attributes+in+the+wild&amp;author=Z.+Liu&amp;author=P.+Luo&amp;author=X.+Wang&amp;author=X.+Tang&amp;pages=3730-3738&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B57-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B58-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">58. <span class="element-citation">Abtahi S., Omidyeganeh M., Shirmohammadi S., Hariri B. YawDD: A yawning detection dataset; Proceedings of the 5th ACM Multimedia Systems Conference; Singapore. 19 March 2014; pp. 24–28. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+5th+ACM+Multimedia+Systems+Conference&amp;title=YawDD:+A+yawning+detection+dataset&amp;author=S.+Abtahi&amp;author=M.+Omidyeganeh&amp;author=S.+Shirmohammadi&amp;author=B.+Hariri&amp;pages=24-28&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B58-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B59-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">59. <span class="element-citation">Dua M., Singla R., Raj S., Jangra A. Deep CNN models-based ensemble approach to driver drowsiness detection. <span><span class="ref-journal">Neural Comput. Appl. </span>2021;<span class="ref-vol">33</span>:3155–3168. doi:&nbsp;10.1007/s00521-020-05209-7.</span> [<a href="https://doi.org/10.1007%2Fs00521-020-05209-7" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neural+Comput.+Appl.&amp;title=Deep+CNN+models-based+ensemble+approach+to+driver+drowsiness+detection&amp;author=M.+Dua&amp;author=R.+Singla&amp;author=S.+Raj&amp;author=A.+Jangra&amp;volume=33&amp;publication_year=2021&amp;pages=3155-3168&amp;doi=10.1007/s00521-020-05209-7&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B59-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B63-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">63. <span class="element-citation">Yu J., Park S., Lee S., Jeon M. Driver drowsiness detection using condition-adaptive representation learning framework. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2018;<span class="ref-vol">20</span>:4206–4218. doi:&nbsp;10.1109/TITS.2018.2883823.</span> [<a href="https://doi.org/10.1109%2FTITS.2018.2883823" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=Driver+drowsiness+detection+using+condition-adaptive+representation+learning+framework&amp;author=J.+Yu&amp;author=S.+Park&amp;author=S.+Lee&amp;author=M.+Jeon&amp;volume=20&amp;publication_year=2018&amp;pages=4206-4218&amp;doi=10.1109/TITS.2018.2883823&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B63-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B68-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">68. <span class="element-citation">Wijnands J.S., Thompson J., Nice K.A., Aschwanden G.D., Stevenson M. Real-time monitoring of driver drowsiness on mobile platforms using 3D neural networks. <span><span class="ref-journal">Neural Comput. Appl. </span>2020;<span class="ref-vol">32</span>:9731–9743. doi:&nbsp;10.1007/s00521-019-04506-0.</span> [<a href="https://doi.org/10.1007%2Fs00521-019-04506-0" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neural+Comput.+Appl.&amp;title=Real-time+monitoring+of+driver+drowsiness+on+mobile+platforms+using+3D+neural+networks&amp;author=J.S.+Wijnands&amp;author=J.+Thompson&amp;author=K.A.+Nice&amp;author=G.D.+Aschwanden&amp;author=M.+Stevenson&amp;volume=32&amp;publication_year=2020&amp;pages=9731-9743&amp;doi=10.1007/s00521-019-04506-0&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B68-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B69-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">69. <span class="element-citation">Guo J.-M., Markoni H. Driver drowsiness detection using hybrid convolutional neural network and long short-term memory. <span><span class="ref-journal">Multimed. Tools Appl. </span>2019;<span class="ref-vol">78</span>:29059–29087. doi:&nbsp;10.1007/s11042-018-6378-6.</span> [<a href="https://doi.org/10.1007%2Fs11042-018-6378-6" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Multimed.+Tools+Appl.&amp;title=Driver+drowsiness+detection+using+hybrid+convolutional+neural+network+and+long+short-term+memory&amp;author=J.-M.+Guo&amp;author=H.+Markoni&amp;volume=78&amp;publication_year=2019&amp;pages=29059-29087&amp;doi=10.1007/s11042-018-6378-6&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B69-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B70-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">70. <span class="element-citation">Ed-Doughmi Y., Idrissi N., Hbali Y. Real-time system for driver fatigue detection based on a recurrent neuronal network. <span><span class="ref-journal">J. Imaging. </span>2020;<span class="ref-vol">6</span>:8.  doi:&nbsp;10.3390/jimaging6030008.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321037/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/34460605" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fjimaging6030008" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Imaging&amp;title=Real-time+system+for+driver+fatigue+detection+based+on+a+recurrent+neuronal+network&amp;author=Y.+Ed-Doughmi&amp;author=N.+Idrissi&amp;author=Y.+Hbali&amp;volume=6&amp;publication_year=2020&amp;pages=8&amp;pmid=34460605&amp;doi=10.3390/jimaging6030008&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B70-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B72-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">72. <span class="element-citation">Zhao Z., Zhou N., Zhang L., Yan H., Xu Y., Zhang Z. Driver fatigue detection based on convolutional neural networks using em-cnn. <span><span class="ref-journal">Comput. Intell. Neurosci. </span>2020;<span class="ref-vol">2020</span>:1–11. doi:&nbsp;10.1155/2020/7251280.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7688374/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/33293943" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1155%2F2020%2F7251280" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Comput.+Intell.+Neurosci.&amp;title=Driver+fatigue+detection+based+on+convolutional+neural+networks+using+em-cnn&amp;author=Z.+Zhao&amp;author=N.+Zhou&amp;author=L.+Zhang&amp;author=H.+Yan&amp;author=Y.+Xu&amp;volume=2020&amp;publication_year=2020&amp;pages=1-11&amp;pmid=33293943&amp;doi=10.1155/2020/7251280&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B72-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B42-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">42. <span class="element-citation">Lugt A.V. Signal detection by complex spatial filtering. <span><span class="ref-journal">IEEE Trans. Inf. Theory. </span>1964;<span class="ref-vol">10</span>:139–145. doi:&nbsp;10.1109/TIT.1964.1053650.</span> [<a href="https://doi.org/10.1109%2FTIT.1964.1053650" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Inf.+Theory&amp;title=Signal+detection+by+complex+spatial+filtering&amp;author=A.V.+Lugt&amp;volume=10&amp;publication_year=1964&amp;pages=139-145&amp;doi=10.1109/TIT.1964.1053650&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B42-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B43-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">43. <span class="element-citation">Xu P., Yu J., Sun Z., Zhou L., Cheng G., Hong C., Han F. Misalignment influence of components on the performance of an integrated zigzag Vander Lugt correlator. <span><span class="ref-journal">Optik. </span>2017;<span class="ref-vol">140</span>:178–185. doi:&nbsp;10.1016/j.ijleo.2017.04.012.</span> [<a href="https://doi.org/10.1016%2Fj.ijleo.2017.04.012" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Optik&amp;title=Misalignment+influence+of+components+on+the+performance+of+an+integrated+zigzag+Vander+Lugt+correlator&amp;author=P.+Xu&amp;author=J.+Yu&amp;author=Z.+Sun&amp;author=L.+Zhou&amp;author=G.+Cheng&amp;volume=140&amp;publication_year=2017&amp;pages=178-185&amp;doi=10.1016/j.ijleo.2017.04.012&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B43-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B60-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">60. <span class="element-citation">Sewell M. Ensemble learning. <span><span class="ref-journal">Res. Note. </span>2011;<span class="ref-vol">11</span>:1–34.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Res.+Note&amp;title=Ensemble+learning&amp;author=M.+Sewell&amp;volume=11&amp;publication_year=2011&amp;pages=1-34&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B60-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B61-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">61. <span class="element-citation">Rosebrock A. Softmax Classifiers Explained.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.pyimagesearch.com/2016/09/12/softmax-classifiers-explained/</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B61-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B62-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">62. <span class="element-citation">Hoang T., Pan B., Nguyen D., Wang Z. Generic gamma correction for accuracy enhancement in fringe-projection profilometry. <span><span class="ref-journal">Opt. Lett. </span>2010;<span class="ref-vol">35</span>:1992–1994. doi:&nbsp;10.1364/OL.35.001992.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/20548363" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1364%2FOL.35.001992" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Opt.+Lett.&amp;title=Generic+gamma+correction+for+accuracy+enhancement+in+fringe-projection+profilometry&amp;author=T.+Hoang&amp;author=B.+Pan&amp;author=D.+Nguyen&amp;author=Z.+Wang&amp;volume=35&amp;publication_year=2010&amp;pages=1992-1994&amp;pmid=20548363&amp;doi=10.1364/OL.35.001992&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B62-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B64-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">64. <span class="element-citation">Tuzel O., Porikli F., Meer P. Region covariance: A fast descriptor for detection and classification; Proceedings of the European conference on computer vision; Graz, Austria. 7–13 May 2006; pp. 589–600. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+European+conference+on+computer+vision&amp;title=Region+covariance:+A+fast+descriptor+for+detection+and+classification&amp;author=O.+Tuzel&amp;author=F.+Porikli&amp;author=P.+Meer&amp;pages=589-600&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B64-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B65-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">65. <span class="element-citation">Dalal N., Triggs B. Histograms of oriented gradients for human detection; Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05); San Diego, CA, USA. 20–25 June 2005; pp. 886–893. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2005+IEEE+Computer+Society+Conference+on+Computer+Vision+and+Pattern+Recognition+(CVPR%E2%80%9905)&amp;title=Histograms+of+oriented+gradients+for+human+detection&amp;author=N.+Dalal&amp;author=B.+Triggs&amp;pages=886-893&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B65-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B66-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">66. <span class="element-citation">Ahonen T., Hadid A., Pietikainen M. Face description with local binary patterns: Application to face recognition. <span><span class="ref-journal">IEEE Trans. Pattern Anal. Mach. Intell. </span>2006;<span class="ref-vol">28</span>:2037–2041. doi:&nbsp;10.1109/TPAMI.2006.244.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17108377" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTPAMI.2006.244" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Pattern+Anal.+Mach.+Intell.&amp;title=Face+description+with+local+binary+patterns:+Application+to+face+recognition&amp;author=T.+Ahonen&amp;author=A.+Hadid&amp;author=M.+Pietikainen&amp;volume=28&amp;publication_year=2006&amp;pages=2037-2041&amp;pmid=17108377&amp;doi=10.1109/TPAMI.2006.244&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B66-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B67-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">67. <span class="element-citation">Gu Q., Li Z., Han J. Generalized Fisher Score for Feature Selection.  [(accessed on 20 September 2021)].  Available online:  <a href="https://arxiv.org/abs/1202.3725" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://arxiv.org/abs/1202.3725</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B67-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B71-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">71. <span class="element-citation">Tran D., Bourdev L., Fergus R., Torresani L., Paluri M. Learning spatiotemporal features with 3d convolutional networks; Proceedings of the IEEE International Conference on Computer Vision; Santiago, Chile. 7–13 December 2015; pp. 4489–4497. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision&amp;title=Learning+spatiotemporal+features+with+3d+convolutional+networks&amp;author=D.+Tran&amp;author=L.+Bourdev&amp;author=R.+Fergus&amp;author=L.+Torresani&amp;author=M.+Paluri&amp;pages=4489-4497&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B71-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B73-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">73. <span class="element-citation">Kumar J.S., Bhuvaneswari P. Analysis of Electroencephalography (EEG) signals and its categorization—A study. <span><span class="ref-journal">Procedia Eng. </span>2012;<span class="ref-vol">38</span>:2525–2536. doi:&nbsp;10.1016/j.proeng.2012.06.298.</span> [<a href="https://doi.org/10.1016%2Fj.proeng.2012.06.298" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Procedia+Eng.&amp;title=Analysis+of+Electroencephalography+(EEG)+signals+and+its+categorization%E2%80%94A+study&amp;author=J.S.+Kumar&amp;author=P.+Bhuvaneswari&amp;volume=38&amp;publication_year=2012&amp;pages=2525-2536&amp;doi=10.1016/j.proeng.2012.06.298&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B73-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B74-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">74. <span class="element-citation">Khorovets A. What Is an Electrocardiogram (ECG)?  [(accessed on 20 September 2021)];<span><span class="ref-journal">Internet J. Adv. Nurs. Pract. </span>1999 <span class="ref-vol">4</span>:1–4.</span> Available online:  <a href="https://ispub.com/IJANP/4/2/12928" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://ispub.com/IJANP/4/2/12928</a> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Internet+J.+Adv.+Nurs.+Pract.&amp;title=What+Is+an+Electrocardiogram+(ECG)?&amp;author=A.+Khorovets&amp;volume=4&amp;publication_year=1999&amp;pages=1-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B74-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B75-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">75. <span class="element-citation">Castaneda D., Esparza A., Ghamari M., Soltanpur C., Nazeran H. A review on wearable photoplethysmography sensors and their potential future applications in health care. <span><span class="ref-journal">Int. J. Biosens. Bioelectron. </span>2018;<span class="ref-vol">4</span>:195. doi:&nbsp;10.15406/ijbsbe.2018.04.00125.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6426305/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/30906922" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.15406%2Fijbsbe.2018.04.00125" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Biosens.+Bioelectron.&amp;title=A+review+on+wearable+photoplethysmography+sensors+and+their+potential+future+applications+in+health+care&amp;author=D.+Castaneda&amp;author=A.+Esparza&amp;author=M.+Ghamari&amp;author=C.+Soltanpur&amp;author=H.+Nazeran&amp;volume=4&amp;publication_year=2018&amp;pages=195&amp;pmid=30906922&amp;doi=10.15406/ijbsbe.2018.04.00125&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B75-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B76-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">76. <span class="element-citation">Mejía-Mejía E., Budidha K., Abay T.Y., May J.M., Kyriacou P.A. Heart rate variability (HRV) and pulse rate variability (PRV) for the assessment of autonomic responses. <span><span class="ref-journal">Front. Physiol. </span>2020;<span class="ref-vol">11</span>:779.  doi:&nbsp;10.3389/fphys.2020.00779.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7390908/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32792970" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3389%2Ffphys.2020.00779" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Front.+Physiol.&amp;title=Heart+rate+variability+(HRV)+and+pulse+rate+variability+(PRV)+for+the+assessment+of+autonomic+responses&amp;author=E.+Mej%C3%ADa-Mej%C3%ADa&amp;author=K.+Budidha&amp;author=T.Y.+Abay&amp;author=J.M.+May&amp;author=P.A.+Kyriacou&amp;volume=11&amp;publication_year=2020&amp;pages=779&amp;pmid=32792970&amp;doi=10.3389/fphys.2020.00779&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B76-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B77-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">77. <span class="element-citation">The McGill Physiology Lab  Biological Signals Acquisition.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.medicine.mcgill.ca/physio/vlab/Other_exps/EOG/eogintro_n.htm" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.medicine.mcgill.ca/physio/vlab/Other_exps/EOG/eogintro_n.htm</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B77-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B78-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">78. <span class="element-citation">Chowdhury R., Reaz M.B.I., Mohd Ali M., Bakar A., Ashrif A., Chellappan K., Chang T.-G. Surface Electromyography Signal Processing and Classification Techniques. <span><span class="ref-journal">Sensors. </span>2013;<span class="ref-vol">13</span>:12431–12466. doi:&nbsp;10.3390/s130912431.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3821366/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24048337" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs130912431" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Surface+Electromyography+Signal+Processing+and+Classification+Techniques&amp;author=R.+Chowdhury&amp;author=M.B.I.+Reaz&amp;author=M.+Mohd+Ali&amp;author=A.+Bakar&amp;author=A.+Ashrif&amp;volume=13&amp;publication_year=2013&amp;pages=12431-12466&amp;pmid=24048337&amp;doi=10.3390/s130912431&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B78-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B79-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">79. <span class="element-citation">Li G., Lee B.-L., Chung W.-Y. Smartwatch-based wearable EEG system for driver drowsiness detection. <span><span class="ref-journal">IEEE Sens. J. </span>2015;<span class="ref-vol">15</span>:7169–7180. doi:&nbsp;10.1109/JSEN.2015.2473679.</span> [<a href="https://doi.org/10.1109%2FJSEN.2015.2473679" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Smartwatch-based+wearable+EEG+system+for+driver+drowsiness+detection&amp;author=G.+Li&amp;author=B.-L.+Lee&amp;author=W.-Y.+Chung&amp;volume=15&amp;publication_year=2015&amp;pages=7169-7180&amp;doi=10.1109/JSEN.2015.2473679&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B79-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B80-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">80. <span class="element-citation">Kaur R., Singh K. Drowsiness detection based on EEG signal analysis using EMD and trained neural network. <span><span class="ref-journal">Int. J. Sci. Res. </span>2013;<span class="ref-vol">10</span>:157–161.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Sci.+Res.&amp;title=Drowsiness+detection+based+on+EEG+signal+analysis+using+EMD+and+trained+neural+network&amp;author=R.+Kaur&amp;author=K.+Singh&amp;volume=10&amp;publication_year=2013&amp;pages=157-161&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B80-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B81-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">81. <span class="element-citation">Budak U., Bajaj V., Akbulut Y., Atila O., Sengur A. An effective hybrid model for EEG-based drowsiness detection. <span><span class="ref-journal">IEEE Sens. J. </span>2019;<span class="ref-vol">19</span>:7624–7631. doi:&nbsp;10.1109/JSEN.2019.2917850.</span> [<a href="https://doi.org/10.1109%2FJSEN.2019.2917850" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=An+effective+hybrid+model+for+EEG-based+drowsiness+detection&amp;author=U.+Budak&amp;author=V.+Bajaj&amp;author=Y.+Akbulut&amp;author=O.+Atila&amp;author=A.+Sengur&amp;volume=19&amp;publication_year=2019&amp;pages=7624-7631&amp;doi=10.1109/JSEN.2019.2917850&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B81-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B82-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">82. <span class="element-citation">Ichimaru Y., Moody G. Development of the polysomnographic database on CD-ROM. <span><span class="ref-journal">Psychiatry Clin. Neurosci. </span>1999;<span class="ref-vol">53</span>:175–177. doi:&nbsp;10.1046/j.1440-1819.1999.00527.x.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/10459681" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1046%2Fj.1440-1819.1999.00527.x" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychiatry+Clin.+Neurosci.&amp;title=Development+of+the+polysomnographic+database+on+CD-ROM&amp;author=Y.+Ichimaru&amp;author=G.+Moody&amp;volume=53&amp;publication_year=1999&amp;pages=175-177&amp;pmid=10459681&amp;doi=10.1046/j.1440-1819.1999.00527.x&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B82-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B83-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">83. <span class="element-citation">Taran S., Bajaj V. Drowsiness detection using adaptive hermite decomposition and extreme learning machine for electroencephalogram signals. <span><span class="ref-journal">IEEE Sens. J. </span>2018;<span class="ref-vol">18</span>:8855–8862. doi:&nbsp;10.1109/JSEN.2018.2869775.</span> [<a href="https://doi.org/10.1109%2FJSEN.2018.2869775" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Drowsiness+detection+using+adaptive+hermite+decomposition+and+extreme+learning+machine+for+electroencephalogram+signals&amp;author=S.+Taran&amp;author=V.+Bajaj&amp;volume=18&amp;publication_year=2018&amp;pages=8855-8862&amp;doi=10.1109/JSEN.2018.2869775&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B83-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B85-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">85. <span class="element-citation">Choi H.-S., Min S., Kim S., Bae H., Yoon J.-E., Hwang I., Oh D., Yun C.-H., Yoon S. Learning-based instantaneous drowsiness detection using wired and wireless electroencephalography. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:146390–146402. doi:&nbsp;10.1109/ACCESS.2019.2946053.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2946053" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Learning-based+instantaneous+drowsiness+detection+using+wired+and+wireless+electroencephalography&amp;author=H.-S.+Choi&amp;author=S.+Min&amp;author=S.+Kim&amp;author=H.+Bae&amp;author=J.-E.+Yoon&amp;volume=7&amp;publication_year=2019&amp;pages=146390-146402&amp;doi=10.1109/ACCESS.2019.2946053&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B85-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B87-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">87. <span class="element-citation">Chinara S. Automatic classification methods for detecting drowsiness using wavelet packet transform extracted time-domain features from single-channel EEG signal. <span><span class="ref-journal">J. Neurosci. Methods. </span>2021;<span class="ref-vol">347</span>:108927.  doi:&nbsp;10.1016/j.jneumeth.2020.108927.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32941920" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jneumeth.2020.108927" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Neurosci.+Methods&amp;title=Automatic+classification+methods+for+detecting+drowsiness+using+wavelet+packet+transform+extracted+time-domain+features+from+single-channel+EEG+signal&amp;author=S.+Chinara&amp;volume=347&amp;publication_year=2021&amp;pages=108927&amp;pmid=32941920&amp;doi=10.1016/j.jneumeth.2020.108927&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B87-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B89-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">89. <span class="element-citation">Kemp B., Zwinderman A.H., Tuk B., Kamphuisen H.A., Oberye J.J. Analysis of a sleep-dependent neuronal feedback loop: The slow-wave microcontinuity of the EEG. <span><span class="ref-journal">IEEE Trans. Biomed. Eng. </span>2000;<span class="ref-vol">47</span>:1185–1194. doi:&nbsp;10.1109/10.867928.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/11008419" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2F10.867928" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Biomed.+Eng.&amp;title=Analysis+of+a+sleep-dependent+neuronal+feedback+loop:+The+slow-wave+microcontinuity+of+the+EEG&amp;author=B.+Kemp&amp;author=A.H.+Zwinderman&amp;author=B.+Tuk&amp;author=H.A.+Kamphuisen&amp;author=J.J.+Oberye&amp;volume=47&amp;publication_year=2000&amp;pages=1185-1194&amp;pmid=11008419&amp;doi=10.1109/10.867928&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B89-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B90-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">90. <span class="element-citation">Kemp B. Sleep-EDF Database Expanded.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.physionet.org/content/sleep-edfx/1.0.0/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.physionet.org/content/sleep-edfx/1.0.0/</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B90-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B91-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">91. <span class="element-citation">Zheng W.-L., Lu B.-L. A multimodal approach to estimating vigilance using EEG and forehead EOG. <span><span class="ref-journal">J. Neural Eng. </span>2017;<span class="ref-vol">14</span>:026017. doi:&nbsp;10.1088/1741-2552/aa5a98.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28102833" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1088%2F1741-2552%2Faa5a98" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=J.+Neural+Eng.&amp;title=A+multimodal+approach+to+estimating+vigilance+using+EEG+and+forehead+EOG&amp;author=W.-L.+Zheng&amp;author=B.-L.+Lu&amp;volume=14&amp;publication_year=2017&amp;pages=026017&amp;pmid=28102833&amp;doi=10.1088/1741-2552/aa5a98&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B91-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B96-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">96. <span class="element-citation">Khare S.K., Bajaj V. Entropy-Based Drowsiness Detection Using Adaptive Variational Mode Decomposition. <span><span class="ref-journal">IEEE Sens. J. </span>2020;<span class="ref-vol">21</span>:6421–6428. doi:&nbsp;10.1109/JSEN.2020.3038440.</span> [<a href="https://doi.org/10.1109%2FJSEN.2020.3038440" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Entropy-Based+Drowsiness+Detection+Using+Adaptive+Variational+Mode+Decomposition&amp;author=S.K.+Khare&amp;author=V.+Bajaj&amp;volume=21&amp;publication_year=2020&amp;pages=6421-6428&amp;doi=10.1109/JSEN.2020.3038440&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B96-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B100-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">100. <span class="element-citation">Lee H., Lee J., Shin M. Using wearable ECG/PPG sensors for driver drowsiness detection based on distinguishable pattern of recurrence plots. <span><span class="ref-journal">Electronics. </span>2019;<span class="ref-vol">8</span>:192.  doi:&nbsp;10.3390/electronics8020192.</span> [<a href="https://doi.org/10.3390%2Felectronics8020192" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Electronics&amp;title=Using+wearable+ECG/PPG+sensors+for+driver+drowsiness+detection+based+on+distinguishable+pattern+of+recurrence+plots&amp;author=H.+Lee&amp;author=J.+Lee&amp;author=M.+Shin&amp;volume=8&amp;publication_year=2019&amp;pages=192&amp;doi=10.3390/electronics8020192&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B100-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B101-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">101. <span class="element-citation">Koh S., Cho B.R., Lee J.-i., Kwon S.-O., Lee S., Lim J.B., Lee S.B., Kweon H.-D. Driver drowsiness detection via PPG biosignals by using multimodal head support; Proceedings of the 2017 4th international conference on control, decision and information technologies (CoDIT); Barcelona, Spain. 5–7 April 2017; pp. 383–388. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2017+4th+international+conference+on+control,+decision+and+information+technologies+(CoDIT)&amp;title=Driver+drowsiness+detection+via+PPG+biosignals+by+using+multimodal+head+support&amp;author=S.+Koh&amp;author=B.R.+Cho&amp;author=J.-i.+Lee&amp;author=S.-O.+Kwon&amp;author=S.+Lee&amp;pages=383-388&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B101-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B102-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">102. <span class="element-citation">Kundinger T., Sofra N., Riener A. Assessment of the potential of wrist-worn wearable sensors for driver drowsiness detection. <span><span class="ref-journal">Sensors. </span>2020;<span class="ref-vol">20</span>:1029.  doi:&nbsp;10.3390/s20041029.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070962/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/32075030" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs20041029" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Assessment+of+the+potential+of+wrist-worn+wearable+sensors+for+driver+drowsiness+detection&amp;author=T.+Kundinger&amp;author=N.+Sofra&amp;author=A.+Riener&amp;volume=20&amp;publication_year=2020&amp;pages=1029&amp;doi=10.3390/s20041029&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B102-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B103-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">103. <span class="element-citation">Fujiwara K., Abe E., Kamata K., Nakayama C., Suzuki Y., Yamakawa T., Hiraoka T., Kano M., Sumi Y., Masuda F. Heart rate variability-based driver drowsiness detection and its validation with EEG. <span><span class="ref-journal">IEEE Trans. Biomed. Eng. </span>2018;<span class="ref-vol">66</span>:1769–1778. doi:&nbsp;10.1109/TBME.2018.2879346.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/30403616" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTBME.2018.2879346" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Biomed.+Eng.&amp;title=Heart+rate+variability-based+driver+drowsiness+detection+and+its+validation+with+EEG&amp;author=K.+Fujiwara&amp;author=E.+Abe&amp;author=K.+Kamata&amp;author=C.+Nakayama&amp;author=Y.+Suzuki&amp;volume=66&amp;publication_year=2018&amp;pages=1769-1778&amp;pmid=30403616&amp;doi=10.1109/TBME.2018.2879346&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B103-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B104-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">104. <span class="element-citation">Guede-Fernandez F., Fernandez-Chimeno M., Ramos-Castro J., Garcia-Gonzalez M.A. Driver drowsiness detection based on respiratory signal analysis. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:81826–81838. doi:&nbsp;10.1109/ACCESS.2019.2924481.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2924481" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Driver+drowsiness+detection+based+on+respiratory+signal+analysis&amp;author=F.+Guede-Fernandez&amp;author=M.+Fernandez-Chimeno&amp;author=J.+Ramos-Castro&amp;author=M.A.+Garcia-Gonzalez&amp;volume=7&amp;publication_year=2019&amp;pages=81826-81838&amp;doi=10.1109/ACCESS.2019.2924481&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B104-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B107-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">107. <span class="element-citation">Sahayadhas A., Sundaraj K., Murugappan M., Palaniappan R. Physiological signal based detection of driver hypovigilance using higher order spectra. <span><span class="ref-journal">Expert Syst. Appl. </span>2015;<span class="ref-vol">42</span>:8669–8677. doi:&nbsp;10.1016/j.eswa.2015.07.021.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2015.07.021" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Physiological+signal+based+detection+of+driver+hypovigilance+using+higher+order+spectra&amp;author=A.+Sahayadhas&amp;author=K.+Sundaraj&amp;author=M.+Murugappan&amp;author=R.+Palaniappan&amp;volume=42&amp;publication_year=2015&amp;pages=8669-8677&amp;doi=10.1016/j.eswa.2015.07.021&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B107-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B108-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">108. <span class="element-citation">Fu R., Wang H. Detection of driving fatigue by using noncontact EMG and ECG signals measurement system. <span><span class="ref-journal">Int. J. Neural Syst. </span>2014;<span class="ref-vol">24</span>:1450006. doi:&nbsp;10.1142/S0129065714500063.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24552510" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1142%2FS0129065714500063" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Neural+Syst.&amp;title=Detection+of+driving+fatigue+by+using+noncontact+EMG+and+ECG+signals+measurement+system&amp;author=R.+Fu&amp;author=H.+Wang&amp;volume=24&amp;publication_year=2014&amp;pages=1450006&amp;pmid=24552510&amp;doi=10.1142/S0129065714500063&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B108-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B109-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">109. <span class="element-citation">Awais M., Badruddin N., Drieberg M. A hybrid approach to detect driver drowsiness utilizing physiological signals to improve system performance and wearability. <span><span class="ref-journal">Sensors. </span>2017;<span class="ref-vol">17</span>:1991.  doi:&nbsp;10.3390/s17091991.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5620623/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28858220" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs17091991" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=A+hybrid+approach+to+detect+driver+drowsiness+utilizing+physiological+signals+to+improve+system+performance+and+wearability&amp;author=M.+Awais&amp;author=N.+Badruddin&amp;author=M.+Drieberg&amp;volume=17&amp;publication_year=2017&amp;pages=1991&amp;pmid=28858220&amp;doi=10.3390/s17091991&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B109-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B110-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">110. <span class="element-citation">Khushaba R.N., Kodagoda S., Lal S., Dissanayake G. Driver drowsiness classification using fuzzy wavelet-packet-based feature-extraction algorithm. <span><span class="ref-journal">IEEE Trans. Biomed. Eng. </span>2010;<span class="ref-vol">58</span>:121–131. doi:&nbsp;10.1109/TBME.2010.2077291.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/20858575" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTBME.2010.2077291" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Biomed.+Eng.&amp;title=Driver+drowsiness+classification+using+fuzzy+wavelet-packet-based+feature-extraction+algorithm&amp;author=R.N.+Khushaba&amp;author=S.+Kodagoda&amp;author=S.+Lal&amp;author=G.+Dissanayake&amp;volume=58&amp;publication_year=2010&amp;pages=121-131&amp;pmid=20858575&amp;doi=10.1109/TBME.2010.2077291&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B110-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B84-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">84. <span class="element-citation">Chen L.-l., Zhao Y., Zhang J., Zou J.-z. Automatic detection of alertness/drowsiness from physiological signals using wavelet-based nonlinear features and machine learning. <span><span class="ref-journal">Expert Syst. Appl. </span>2015;<span class="ref-vol">42</span>:7344–7355. doi:&nbsp;10.1016/j.eswa.2015.05.028.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2015.05.028" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Automatic+detection+of+alertness/drowsiness+from+physiological+signals+using+wavelet-based+nonlinear+features+and+machine+learning&amp;author=L.-l.+Chen&amp;author=Y.+Zhao&amp;author=J.+Zhang&amp;author=J.-z.+Zou&amp;volume=42&amp;publication_year=2015&amp;pages=7344-7355&amp;doi=10.1016/j.eswa.2015.05.028&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B84-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B86-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">86. <span class="element-citation">Thomson D.J. Spectrum estimation and harmonic analysis. <span><span class="ref-journal">Proc. IEEE. </span>1982;<span class="ref-vol">70</span>:1055–1096. doi:&nbsp;10.1109/PROC.1982.12433.</span> [<a href="https://doi.org/10.1109%2FPROC.1982.12433" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proc.+IEEE&amp;title=Spectrum+estimation+and+harmonic+analysis&amp;author=D.J.+Thomson&amp;volume=70&amp;publication_year=1982&amp;pages=1055-1096&amp;doi=10.1109/PROC.1982.12433&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B86-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B88-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">88. <span class="element-citation">Percival D.B., Walden A.T.  <span class="ref-journal">Wavelet Methods for Time Series Analysis.</span> Volume 4 Cambridge University Press; Cambridge, UK: 2000.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Wavelet+Methods+for+Time+Series+Analysis&amp;author=D.B.+Percival&amp;author=A.T.+Walden&amp;publication_year=2000&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B88-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B92-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">92. <span class="element-citation">Higuchi T. Approach to an irregular time series on the basis of the fractal theory. <span><span class="ref-journal">Phys. D Nonlinear Phenom. </span>1988;<span class="ref-vol">31</span>:277–283. doi:&nbsp;10.1016/0167-2789(88)90081-4.</span> [<a href="https://doi.org/10.1016%2F0167-2789(88)90081-4" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Phys.+D+Nonlinear+Phenom.&amp;title=Approach+to+an+irregular+time+series+on+the+basis+of+the+fractal+theory&amp;author=T.+Higuchi&amp;volume=31&amp;publication_year=1988&amp;pages=277-283&amp;doi=10.1016/0167-2789(88)90081-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B92-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B93-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">93. <span class="element-citation">Hjorth B. EEG analysis based on time domain properties. <span><span class="ref-journal">Electroencephalogr. Clin. Neurophysiol. </span>1970;<span class="ref-vol">29</span>:306–310. doi:&nbsp;10.1016/0013-4694(70)90143-4.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/4195653" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2F0013-4694(70)90143-4" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;title=EEG+analysis+based+on+time+domain+properties&amp;author=B.+Hjorth&amp;volume=29&amp;publication_year=1970&amp;pages=306-310&amp;pmid=4195653&amp;doi=10.1016/0013-4694(70)90143-4&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B93-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B94-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">94. <span class="element-citation">Wilcoxon F.  <span class="ref-journal">Breakthroughs in Statistics.</span> Springer; Berlin/Heidelberg, Germany: 1992. Individual comparisons by ranking methods. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Breakthroughs+in+Statistics&amp;author=F.+Wilcoxon&amp;publication_year=1992&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B94-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B95-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">95. <span class="element-citation">Wilkinson B. A statistical consideration in psychological research. <span><span class="ref-journal">Psychol. Bull. </span>1951;<span class="ref-vol">48</span>:156. doi:&nbsp;10.1037/h0059111.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/14834286" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1037%2Fh0059111" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychol.+Bull.&amp;title=A+statistical+consideration+in+psychological+research&amp;author=B.+Wilkinson&amp;volume=48&amp;publication_year=1951&amp;pages=156&amp;pmid=14834286&amp;doi=10.1037/h0059111&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B95-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B97-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">97. <span class="element-citation">Bandt C., Pompe B. Permutation entropy: A natural complexity measure for time series. <span><span class="ref-journal">Phys. Rev. Lett. </span>2002;<span class="ref-vol">88</span>:174102.  doi:&nbsp;10.1103/PhysRevLett.88.174102.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/12005759" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1103%2FPhysRevLett.88.174102" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Phys.+Rev.+Lett.&amp;title=Permutation+entropy:+A+natural+complexity+measure+for+time+series&amp;author=C.+Bandt&amp;author=B.+Pompe&amp;volume=88&amp;publication_year=2002&amp;pages=174102&amp;pmid=12005759&amp;doi=10.1103/PhysRevLett.88.174102&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B97-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B98-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">98. <span class="element-citation">Borowska M. Entropy-based algorithms in the analysis of biomedical signals. <span><span class="ref-journal">Stud. Log. Gramm. Rhetor. </span>2015;<span class="ref-vol">43</span>:21–32. doi:&nbsp;10.1515/slgr-2015-0039.</span> [<a href="https://doi.org/10.1515%2Fslgr-2015-0039" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Stud.+Log.+Gramm.+Rhetor.&amp;title=Entropy-based+algorithms+in+the+analysis+of+biomedical+signals&amp;author=M.+Borowska&amp;volume=43&amp;publication_year=2015&amp;pages=21-32&amp;doi=10.1515/slgr-2015-0039&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B98-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B99-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">99. <span class="element-citation">Aydın S., Saraoğlu H.M., Kara S. Log energy entropy-based EEG classification with multilayer neural networks in seizure. <span><span class="ref-journal">Ann. Biomed. Eng. </span>2009;<span class="ref-vol">37</span>:2626. doi:&nbsp;10.1007/s10439-009-9795-x.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/19757057" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1007%2Fs10439-009-9795-x" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Ann.+Biomed.+Eng.&amp;title=Log+energy+entropy-based+EEG+classification+with+multilayer+neural+networks+in+seizure&amp;author=S.+Ayd%C4%B1n&amp;author=H.M.+Sarao%C4%9Flu&amp;author=S.+Kara&amp;volume=37&amp;publication_year=2009&amp;pages=2626&amp;pmid=19757057&amp;doi=10.1007/s10439-009-9795-x&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B99-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B105-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">105. <span class="element-citation">Kamen G., Kinesiology E.  <span class="ref-journal">Research Methods in Biomechanics.</span> Human Kinetics Publ; Champaign, IL, USA: 2004.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Research+Methods+in+Biomechanics&amp;author=G.+Kamen&amp;author=E.+Kinesiology&amp;publication_year=2004&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B105-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B106-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">106. <span class="element-citation">Reaz M., Hussain M., Mohd-Yasin F. Techniques of EMG signal analysis: Detection, processing, classification and applications (Correction) <span><span class="ref-journal">Biol. Proced. Online. </span>2006;<span class="ref-vol">8</span> doi:&nbsp;10.1251/bpo124.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1622762/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/19565309" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1251%2Fbpo124" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Biol.+Proced.+Online&amp;title=Techniques+of+EMG+signal+analysis:+Detection,+processing,+classification+and+applications+(Correction)&amp;author=M.+Reaz&amp;author=M.+Hussain&amp;author=F.+Mohd-Yasin&amp;volume=8&amp;publication_year=2006&amp;doi=10.1251/bpo124&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B106-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B111-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">111. <span class="element-citation">Cai D., He X., Han J. SRDA: An efficient algorithm for large-scale discriminant analysis. <span><span class="ref-journal">IEEE Trans. Knowl. Data Eng. </span>2007;<span class="ref-vol">20</span>:1–12. doi:&nbsp;10.1109/TKDE.2007.190669.</span> [<a href="https://doi.org/10.1109%2FTKDE.2007.190669" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Knowl.+Data+Eng.&amp;title=SRDA:+An+efficient+algorithm+for+large-scale+discriminant+analysis&amp;author=D.+Cai&amp;author=X.+He&amp;author=J.+Han&amp;volume=20&amp;publication_year=2007&amp;pages=1-12&amp;doi=10.1109/TKDE.2007.190669&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B111-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B112-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">112. <span class="element-citation">Cai D., He X., Han J. Efficient kernel discriminant analysis via spectral regression; Proceedings of the Seventh IEEE International Conference on Data Mining (ICDM 2007); Omaha, NE, USA. 28–31 October 2007; pp. 427–432. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+Seventh+IEEE+International+Conference+on+Data+Mining+(ICDM+2007)&amp;title=Efficient+kernel+discriminant+analysis+via+spectral+regression&amp;author=D.+Cai&amp;author=X.+He&amp;author=J.+Han&amp;pages=427-432&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B112-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B113-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">113. <span class="element-citation">McDonald A.D., Schwarz C., Lee J.D., Brown T.L. Real-time detection of drowsiness related lane departures using steering wheel angle; Proceedings of the Human Factors and Ergonomics Society Annual Meeting; Boston, MA, USA. 22–26 October 2012; pp. 2201–2205. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+Human+Factors+and+Ergonomics+Society+Annual+Meeting&amp;title=Real-time+detection+of+drowsiness+related+lane+departures+using+steering+wheel+angle&amp;author=A.D.+McDonald&amp;author=C.+Schwarz&amp;author=J.D.+Lee&amp;author=T.L.+Brown&amp;pages=2201-2205&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B113-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B114-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">114. <span class="element-citation">Ma J., Murphey Y.L., Zhao H. Real time drowsiness detection based on lateral distance using wavelet transform and neural network; Proceedings of the 2015 IEEE symposium series on computational intelligence; Cape Town, South Africa. 7–10 December 2015; pp. 411–418. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+2015+IEEE+symposium+series+on+computational+intelligence&amp;title=Real+time+drowsiness+detection+based+on+lateral+distance+using+wavelet+transform+and+neural+network&amp;author=J.+Ma&amp;author=Y.L.+Murphey&amp;author=H.+Zhao&amp;pages=411-418&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B114-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B117-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">117. <span class="element-citation">Li Z., Li S.E., Li R., Cheng B., Shi J. Online detection of driver fatigue using steering wheel angles for real driving conditions. <span><span class="ref-journal">Sensors. </span>2017;<span class="ref-vol">17</span>:495.  doi:&nbsp;10.3390/s17030495.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5375781/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28257094" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs17030495" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Online+detection+of+driver+fatigue+using+steering+wheel+angles+for+real+driving+conditions&amp;author=Z.+Li&amp;author=S.E.+Li&amp;author=R.+Li&amp;author=B.+Cheng&amp;author=J.+Shi&amp;volume=17&amp;publication_year=2017&amp;pages=495&amp;pmid=28257094&amp;doi=10.3390/s17030495&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B117-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B118-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">118. <span class="element-citation">Arefnezhad S., Samiee S., Eichberger A., Nahvi A. Driver drowsiness detection based on steering wheel data applying adaptive neuro-fuzzy feature selection. <span><span class="ref-journal">Sensors. </span>2019;<span class="ref-vol">19</span>:943.  doi:&nbsp;10.3390/s19040943.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6412352/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/30813386" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs19040943" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Driver+drowsiness+detection+based+on+steering+wheel+data+applying+adaptive+neuro-fuzzy+feature+selection&amp;author=S.+Arefnezhad&amp;author=S.+Samiee&amp;author=A.+Eichberger&amp;author=A.+Nahvi&amp;volume=19&amp;publication_year=2019&amp;pages=943&amp;doi=10.3390/s19040943&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B118-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B119-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">119. <span class="element-citation">Chai M. Drowsiness monitoring based on steering wheel status. <span><span class="ref-journal">Transp. Res. Part D Transp. Environ. </span>2019;<span class="ref-vol">66</span>:95–103. doi:&nbsp;10.1016/j.trd.2018.07.007.</span> [<a href="https://doi.org/10.1016%2Fj.trd.2018.07.007" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Transp.+Res.+Part+D+Transp.+Environ.&amp;title=Drowsiness+monitoring+based+on+steering+wheel+status&amp;author=M.+Chai&amp;volume=66&amp;publication_year=2019&amp;pages=95-103&amp;doi=10.1016/j.trd.2018.07.007&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B119-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B115-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">115. <span class="element-citation">Brown T., Lee J., Schwarz C., Fiorentino D., McDonald A.  <span class="ref-journal">Final Report: Advanced Countermeasures for Multiple Impairments.</span> National Highway Traffic Safety Administration; Washington, DC, USA: 2011.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Final+Report:+Advanced+Countermeasures+for+Multiple+Impairments&amp;author=T.+Brown&amp;author=J.+Lee&amp;author=C.+Schwarz&amp;author=D.+Fiorentino&amp;author=A.+McDonald&amp;publication_year=2011&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B115-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B116-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">116. <span class="element-citation">Murphey Y.L., Kochhar D., Chen F., Huang Y., Wang Y.  <span class="ref-journal">A Transportable Instrumentation Package for In-Vehicle On-Road Data Collection for Driver Research.</span> SAE; Warrendale, PA, USA: 2013.  Technical Paper: 0148-7191. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=A+Transportable+Instrumentation+Package+for+In-Vehicle+On-Road+Data+Collection+for+Driver+Research&amp;author=Y.L.+Murphey&amp;author=D.+Kochhar&amp;author=F.+Chen&amp;author=Y.+Huang&amp;author=Y.+Wang&amp;publication_year=2013&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B116-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B120-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">120. <span class="element-citation">Wang X., Xu C. Driver drowsiness detection based on non-intrusive metrics considering individual specifics. <span><span class="ref-journal">Accid. Anal. Prev. </span>2016;<span class="ref-vol">95</span>:350–357. doi:&nbsp;10.1016/j.aap.2015.09.002.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/26433567" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.aap.2015.09.002" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Accid.+Anal.+Prev.&amp;title=Driver+drowsiness+detection+based+on+non-intrusive+metrics+considering+individual+specifics&amp;author=X.+Wang&amp;author=C.+Xu&amp;volume=95&amp;publication_year=2016&amp;pages=350-357&amp;pmid=26433567&amp;doi=10.1016/j.aap.2015.09.002&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B120-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B121-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">121. <span class="element-citation">Zhang C., Wu X., Zheng X., Yu S. Driver drowsiness detection using multi-channel second order blind identifications. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:11829–11843. doi:&nbsp;10.1109/ACCESS.2019.2891971.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2891971" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Driver+drowsiness+detection+using+multi-channel+second+order+blind+identifications&amp;author=C.+Zhang&amp;author=X.+Wu&amp;author=X.+Zheng&amp;author=S.+Yu&amp;volume=7&amp;publication_year=2019&amp;pages=11829-11843&amp;doi=10.1109/ACCESS.2019.2891971&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B121-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B122-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">122. <span class="element-citation">de Naurois C.J., Bourdin C., Stratulat A., Diaz E., Vercher J.-L. Detection and prediction of driver drowsiness using artificial neural network models. <span><span class="ref-journal">Accid. Anal. Prev. </span>2019;<span class="ref-vol">126</span>:95–104. doi:&nbsp;10.1016/j.aap.2017.11.038.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/29203032" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.aap.2017.11.038" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Accid.+Anal.+Prev.&amp;title=Detection+and+prediction+of+driver+drowsiness+using+artificial+neural+network+models&amp;author=C.J.+de+Naurois&amp;author=C.+Bourdin&amp;author=A.+Stratulat&amp;author=E.+Diaz&amp;author=J.-L.+Vercher&amp;volume=126&amp;publication_year=2019&amp;pages=95-104&amp;pmid=29203032&amp;doi=10.1016/j.aap.2017.11.038&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B122-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B123-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">123. <span class="element-citation">Nguyen T., Ahn S., Jang H., Jun S.C., Kim J.G. Utilization of a combined EEG/NIRS system to predict driver drowsiness. <span><span class="ref-journal">Sci. Rep. </span>2017;<span class="ref-vol">7</span>:1–10. doi:&nbsp;10.1038/srep43933.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5339693/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28266633" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1038%2Fsrep43933" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sci.+Rep.&amp;title=Utilization+of+a+combined+EEG/NIRS+system+to+predict+driver+drowsiness&amp;author=T.+Nguyen&amp;author=S.+Ahn&amp;author=H.+Jang&amp;author=S.C.+Jun&amp;author=J.G.+Kim&amp;volume=7&amp;publication_year=2017&amp;pages=1-10&amp;pmid=28127051&amp;doi=10.1038/srep43933&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B123-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B124-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">124. <span class="element-citation">Barua S., Ahmed M.U., Ahlström C., Begum S. Automatic driver sleepiness detection using EEG, EOG and contextual information. <span><span class="ref-journal">Expert Syst. Appl. </span>2019;<span class="ref-vol">115</span>:121–135. doi:&nbsp;10.1016/j.eswa.2018.07.054.</span> [<a href="https://doi.org/10.1016%2Fj.eswa.2018.07.054" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Expert+Syst.+Appl.&amp;title=Automatic+driver+sleepiness+detection+using+EEG,+EOG+and+contextual+information&amp;author=S.+Barua&amp;author=M.U.+Ahmed&amp;author=C.+Ahlstr%C3%B6m&amp;author=S.+Begum&amp;volume=115&amp;publication_year=2019&amp;pages=121-135&amp;doi=10.1016/j.eswa.2018.07.054&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B124-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B125-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">125. <span class="element-citation">Dasgupta A., Rahman D., Routray A. A smartphone-based drowsiness detection and warning system for automotive drivers. <span><span class="ref-journal">IEEE Trans. Intell. Transp. Syst. </span>2018;<span class="ref-vol">20</span>:4045–4054. doi:&nbsp;10.1109/TITS.2018.2879609.</span> [<a href="https://doi.org/10.1109%2FTITS.2018.2879609" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Intell.+Transp.+Syst.&amp;title=A+smartphone-based+drowsiness+detection+and+warning+system+for+automotive+drivers&amp;author=A.+Dasgupta&amp;author=D.+Rahman&amp;author=A.+Routray&amp;volume=20&amp;publication_year=2018&amp;pages=4045-4054&amp;doi=10.1109/TITS.2018.2879609&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B125-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B126-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">126. <span class="element-citation">INVEDRIFAC—A Video and Image Database of Faces of In-vehicle Automotive Drivers, India. 2019.  [(accessed on 20 September 2021)].  Available online:  <a href="https://sites.google.com/site/invedrifac/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">https://sites.google.com/site/invedrifac/</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B126-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B127-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">127. <span class="element-citation">Gwak J., Hirao A., Shino M. An investigation of early detection of driver drowsiness using ensemble machine learning based on hybrid sensing. <span><span class="ref-journal">Appl. Sci. </span>2020;<span class="ref-vol">10</span>:2890.  doi:&nbsp;10.3390/app10082890.</span> [<a href="https://doi.org/10.3390%2Fapp10082890" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Appl.+Sci.&amp;title=An+investigation+of+early+detection+of+driver+drowsiness+using+ensemble+machine+learning+based+on+hybrid+sensing&amp;author=J.+Gwak&amp;author=A.+Hirao&amp;author=M.+Shino&amp;volume=10&amp;publication_year=2020&amp;pages=2890&amp;doi=10.3390/app10082890&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B127-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B128-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">128. <span class="element-citation">Zilberg E., Xu Z.M., Burton D., Karrar M., Lal S. Methodology and initial analysis results for development of non-invasive and hybrid driver drowsiness detection systems; Proceedings of the the 2nd International Conference on Wireless Broadband and Ultra Wideband Communications (AusWireless 2007); Sydney, Australia. 27–30 August 2007; p. 16. [<a href="https://doi.org/10.1109%2FAUSWIRELESS.2007.44" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+the+2nd+International+Conference+on+Wireless+Broadband+and+Ultra+Wideband+Communications+(AusWireless+2007)&amp;title=Methodology+and+initial+analysis+results+for+development+of+non-invasive+and+hybrid+driver+drowsiness+detection+systems&amp;author=E.+Zilberg&amp;author=Z.M.+Xu&amp;author=D.+Burton&amp;author=M.+Karrar&amp;author=S.+Lal&amp;pages=16&amp;doi=10.1109/AUSWIRELESS.2007.44&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B128-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B129-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">129. <span class="element-citation">Volvo  Volvo Cars Introduces New Systems for Alerting Tired and Distracted Drivers.  [(accessed on 20 September 2021)].  Available online:  <a href="https://www.media.volvocars.com/us/en-us/media/pressreleases/12130" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.media.volvocars.com/us/en-us/media/pressreleases/12130</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B129-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B130-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">130. <span class="element-citation">Altameem A., Kumar A., Poonia R.C., Kumar S., Saudagar A.K.J. Early Identification and Detection of Driver Drowsiness by Hybrid Machine Learning. <span><span class="ref-journal">IEEE Access. </span>2021;<span class="ref-vol">9</span>:162805–162819. doi:&nbsp;10.1109/ACCESS.2021.3131601.</span> [<a href="https://doi.org/10.1109%2FACCESS.2021.3131601" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=Early+Identification+and+Detection+of+Driver+Drowsiness+by+Hybrid+Machine+Learning&amp;author=A.+Altameem&amp;author=A.+Kumar&amp;author=R.C.+Poonia&amp;author=S.+Kumar&amp;author=A.K.J.+Saudagar&amp;volume=9&amp;publication_year=2021&amp;pages=162805-162819&amp;doi=10.1109/ACCESS.2021.3131601&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B130-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B131-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">131. <span class="element-citation">Doudou M., Bouabdallah A., Berge-Cherfaoui V. Driver drowsiness measurement technologies: Current research, market solutions, and challenges. <span><span class="ref-journal">Int. J. Intell. Transp. Syst. Res. </span>2020;<span class="ref-vol">18</span>:297–319. doi:&nbsp;10.1007/s13177-019-00199-w.</span> [<a href="https://doi.org/10.1007%2Fs13177-019-00199-w" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int.+J.+Intell.+Transp.+Syst.+Res.&amp;title=Driver+drowsiness+measurement+technologies:+Current+research,+market+solutions,+and+challenges&amp;author=M.+Doudou&amp;author=A.+Bouabdallah&amp;author=V.+Berge-Cherfaoui&amp;volume=18&amp;publication_year=2020&amp;pages=297-319&amp;doi=10.1007/s13177-019-00199-w&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B131-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B132-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">132. <span class="element-citation">Kashevnik A., Lashkov I., Ponomarev A., Teslya N., Gurtov A. Cloud-based driver monitoring system using a smartphone. <span><span class="ref-journal">IEEE Sens. J. </span>2020;<span class="ref-vol">20</span>:6701–6715. doi:&nbsp;10.1109/JSEN.2020.2975382.</span> [<a href="https://doi.org/10.1109%2FJSEN.2020.2975382" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+J.&amp;title=Cloud-based+driver+monitoring+system+using+a+smartphone&amp;author=A.+Kashevnik&amp;author=I.+Lashkov&amp;author=A.+Ponomarev&amp;author=N.+Teslya&amp;author=A.+Gurtov&amp;volume=20&amp;publication_year=2020&amp;pages=6701-6715&amp;doi=10.1109/JSEN.2020.2975382&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B132-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B133-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">133. <span class="element-citation">Tamanani R., Muresan R., Al-Dweik A. Estimation of Driver Vigilance Status Using Real-Time Facial Expression and Deep Learning. <span><span class="ref-journal">IEEE Sens. Lett. </span>2021;<span class="ref-vol">5</span>:1–4. doi:&nbsp;10.1109/LSENS.2021.3070419.</span> [<a href="https://doi.org/10.1109%2FLSENS.2021.3070419" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Sens.+Lett.&amp;title=Estimation+of+Driver+Vigilance+Status+Using+Real-Time+Facial+Expression+and+Deep+Learning&amp;author=R.+Tamanani&amp;author=R.+Muresan&amp;author=A.+Al-Dweik&amp;volume=5&amp;publication_year=2021&amp;pages=1-4&amp;doi=10.1109/LSENS.2021.3070419&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B133-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B134-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">134. <span class="element-citation">Abbas Q., Alsheddy A. Driver fatigue detection systems using multi-sensors, smartphone, and cloud-based computing platforms: A comparative analysis. <span><span class="ref-journal">Sensors. </span>2021;<span class="ref-vol">21</span>:56.  doi:&nbsp;10.3390/s21010056.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7796320/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/33374270" ref="reftype=pubmed&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fs21010056" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Driver+fatigue+detection+systems+using+multi-sensors,+smartphone,+and+cloud-based+computing+platforms:+A+comparative+analysis&amp;author=Q.+Abbas&amp;author=A.+Alsheddy&amp;volume=21&amp;publication_year=2021&amp;pages=56&amp;doi=10.3390/s21010056&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B134-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B135-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">135. <span class="element-citation">Chang W.-J., Chen L.-B., Chiou Y.-Z. Design and implementation of a drowsiness-fatigue-detection system based on wearable smart glasses to increase road safety. <span><span class="ref-journal">IEEE Trans. Consum. Electron. </span>2018;<span class="ref-vol">64</span>:461–469. doi:&nbsp;10.1109/TCE.2018.2872162.</span> [<a href="https://doi.org/10.1109%2FTCE.2018.2872162" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Consum.+Electron.&amp;title=Design+and+implementation+of+a+drowsiness-fatigue-detection+system+based+on+wearable+smart+glasses+to+increase+road+safety&amp;author=W.-J.+Chang&amp;author=L.-B.+Chen&amp;author=Y.-Z.+Chiou&amp;volume=64&amp;publication_year=2018&amp;pages=461-469&amp;doi=10.1109/TCE.2018.2872162&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B135-sensors-22-02069">Ref list</a>]</div><div id="body-link-popper-B136-sensors-22-02069" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 446px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">136. <span class="element-citation">Dong N., Li Y., Gao Z., Ip W.H., Yung K.L. A WPCA-based method for detecting fatigue driving from EEG-based internet of vehicles system. <span><span class="ref-journal">IEEE Access. </span>2019;<span class="ref-vol">7</span>:124702–124711. doi:&nbsp;10.1109/ACCESS.2019.2937914.</span> [<a href="https://doi.org/10.1109%2FACCESS.2019.2937914" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Access&amp;title=A+WPCA-based+method+for+detecting+fatigue+driving+from+EEG-based+internet+of+vehicles+system&amp;author=N.+Dong&amp;author=Y.+Li&amp;author=Z.+Gao&amp;author=W.H.+Ip&amp;author=K.L.+Yung&amp;volume=7&amp;publication_year=2019&amp;pages=124702-124711&amp;doi=10.1109/ACCESS.2019.2937914&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8914892&amp;issue-id=402841&amp;journal-id=1660&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#B136-sensors-22-02069">Ref list</a>]</div></div></div>
            
        </section>
    </article>
    <aside class="usa-width-one-fourth usa-layout-docs-sidenav pmc-sidebar">
         
  

<div class="scroller">

    
        <section>
                <h6>Other Formats</h6>
                <ul class="pmc-sidebar__formats">
                  <li class="pdf-link other_item"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/pdf/sensors-22-02069.pdf" class="int-view">PDF (1.5M)</a></li>
                </ul>
        </section>
    
    <section>
        <h6>Actions</h6>
        <ul class="pmc-sidebar__actions">
            <li>
                <button role="button" class="citation-button citation-dialog-trigger ctxp" aria-label="Open dialog with citation text in different styles" data-ga-category="save_share" data-ga-action="cite" data-ga-label="open" data-all-citations-url="/pmc/resources/citations/8914892/" data-citation-style="nlm" data-download-format-link="/pmc/resources/citations/8914892/export/">
                    <span class="button-label">Cite</span>
                </button>
            </li>
            <li>
                
                    

<link type="text/css" href="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/overlay-block.css">
<div class="collections-button-container" data-article-id="8914892" data-article-db="pmc">
  <button class="collections-button collections-dialog-trigger collections-button-empty" aria-label="Save article in MyNCBI collections." data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_button" data-collections-open-dialog-enabled="false" data-collections-open-dialog-url="https://www.ncbi.nlm.nih.gov/account?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F%23open-collections-dialog" data-in-collections="false">
      <span class="button-label">Collections</span>
  </button>
  <div class="overlay collections-dialog-overlay" role="dialog">
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true" role="document">
    <div class="title">Add to Collections</div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form" class="collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors" data-existing-collections-url="/pmc/list-existing-collections/" data-add-to-existing-collection-url="/pmc/add-to-existing-collection/" data-create-and-add-to-new-collection-url="/pmc/create-and-add-to-new-collection/" data-myncbi-max-collection-name-length="100" data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

  <input type="hidden" name="csrfmiddlewaretoken" value="HCWL2GAfmC2WnH2jRYA8utMhSQWf2vdItBFHdVmdco7ExVsLpNZjxQHq4h9TCIWX">

  

  <div class="choice-group" role="radiogroup">
    <ul class="radio-group-items">
      <li>
        <input type="radio" id="collections-action-dialog-new-aside " class="collections-new" name="collections" value="new" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_new">
        <label for="collections-action-dialog-new-aside ">Create a new collection</label>
      </li>
      <li>
        <input type="radio" id="collections-action-dialog-existing-aside " class="collections-existing" name="collections" value="existing" checked="true" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_existing">
        <label for="collections-action-dialog-existing-aside ">Add to an existing collection</label>
      </li>
    </ul>
  </div>

  <div class="controls-wrapper">
    <div class="action-panel-control-wrap new-collections-controls">
      <label for="collections-action-dialog-add-to-new" class="action-panel-label required-field-asterisk">
        Name your collection:
      </label>
      <input type="text" name="add-to-new-collection" id="collections-action-dialog-add-to-new" class="collections-action-add-to-new" pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/" maxlength="" data-ga-category="collections_button" data-ga-action="create_collection" data-ga-label="non_favorties_collection">
      <div class="collections-new-name-too-long usa-input-error-message selection-validation-message">
        Name must be less than  characters
      </div>
    </div>
    <div class="action-panel-control-wrap existing-collections-controls">
      <label for="collections-action-dialog-add-to-existing" class="action-panel-label">
        Choose a collection:
      </label>
      <select id="collections-action-dialog-add-to-existing" class="action-panel-selector collections-action-add-to-existing" data-ga-category="collections_button" data-ga-action="select_collection" data-ga-label="($(&#39;.collections-action-add-to-existing&#39;).val() === &#39;Favorites&#39;) ? &#39;Favorites&#39; : &#39;non_favorites_collection&#39;">
      </select>
      <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
        Unable to load your collection due to an error<br>
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#">Please try again</a>
      </div>
    </div>
  </div>

  <div class="action-panel-actions">
    <button class="action-panel-submit" type="submit" data-loading-label="Adding..." data-pinger-ignore="" data-ga-category="collections_button" data-ga-action="click" data-ga-label="add">
      Add
    </button>
    <button class="action-panel-cancel" aria-label="Close &#39;Add to Collections&#39; panel" ref="linksrc=close_collections_panel" aria-controls="collections-action-panel" aria-expanded="false" data-ga-category="collections_button" data-ga-action="click" data-ga-label="cancel">
      Cancel
    </button>
  </div>
</form>
    </div>
  </div>
</div>
</div>
                
            </li>

        </ul>
    </section>
    
        <section class="social-sharing">
            <h6>Share</h6>
            <ul class="pmc-sidebar__share">
                <li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F&amp;text=A%20Review%20of%20Recent%20Developments%20in%20Driver%20Drowsiness%20Detection%20Systems" alt="Share on Twitter" aria-expanded="false" aria-haspopup="true"><i class="fa fa-twitter fa-stack-1x">&nbsp;</i></a></li> 
<li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8914892%2F" alt="Share on Facebook" aria-expanded="false" aria-haspopup="true"><i class="fa fa-facebook fa-stack-1x">&nbsp;</i></a></li>
                <li>
                    <div class="share-permalink dropdown-block">
                        <button class="trigger" alt="Show article permalink" aria-expanded="false" aria-haspopup="true">
                            <i class="fa-stack fa-lg">
                                <i class="fa fa-link fa-stack-1x">&nbsp;</i>
                            </i>
                        </button>
                        <div class="dropdown dropdown-container" aria-hidden="true">
                              <div class="title">
                                Permalink
                              </div>
                              <div class="content">
                                  <input type="text" class="permalink-text" value="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/" aria-label="Article permalink"><button class="permalink-copy-button usa-button-primary" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                                      <span class="button-title">Copy</span>
                                  </button>
                              </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    
    <section>
        <h6>RESOURCES</h6>
        <ul class="pmc-sidebar__resources">
        
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_similar_articles" data-ga-label="/pmc/articles/PMC8914892/" class="usa-accordion-button" aria-controls="similar-articles-accordion-aside" aria-expanded="false" data-action-open="open_similar_articles" data-action-close="close_similar_articles">
                        Similar articles
                    </button>
                    <div data-source-url="/pmc/resources/similar-article-links/35271215/" class="usa-accordion-content pmc-sidebar__resources--citations" id="similar-articles-accordion-aside" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_cited_by" data-ga-label="/pmc/articles/PMC8914892/" class="usa-accordion-button" aria-controls="cited-by-accordion-aside" aria-expanded="false" data-action-open="open_cited_by" data-action-close="close_cited_by">
                        Cited by other articles
                    </button>
                    <div data-source-url="/pmc/resources/cited-by-links/35271215/" class="usa-accordion-content pmc-sidebar__resources--citations" id="cited-by-accordion-aside" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_NCBI_links" data-ga-label="/pmc/articles/PMC8914892/" class="usa-accordion-button" aria-controls="links-accordion-aside" aria-expanded="false" data-action-open="open_NCBI_links" data-action-close="close_NCBI_link">
                        Links to NCBI Databases
                    </button>
                    <div data-source-url="/pmc/resources/db-links/8914892/" class="usa-accordion-content" id="links-accordion-aside" aria-hidden="true"></div>
                </div>
            </li>

            
        
        </ul>
    </section>

 </div>

    </aside>
</main>

    <div class="overlay citation-dialog-overlay" role="dialog" aria-label="Citation Dialog">
  <div class="dialog citation-dialog" role="document">
    <button class="close-overlay" tabindex="1" data-pinger-ignore="true">[x]</button>
    <div class="title">Cite</div>
    <div class="citation-text-block">
  <div class="citation-text"></div>
  <div class="citation-actions">
    <button class="copy-button dialog-focus" data-ga-category="save_share" data-ga-action="cite" data-ga-label="copy" tabindex="2">
      Copy
    </button>

      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914892/#" class="export-button" data-ga-category="save_share" data-ga-action="cite" data-ga-label="download" title="Download a file for external citation management software" tabindex="3">
          <span class="title">Download .nbib</span>
          <span class="title-mobile">.nbib</span>
      </a>


    

<div class="citation-style-selector-wrapper">
  <label class="selector-label">Format:</label>
  <select aria-label="Format" class="citation-style-selector" tabindex="4">
    
      <option data-style-url-name="ama" value="AMA">
        AMA
      </option>
    
      <option data-style-url-name="apa" value="APA">
        APA
      </option>
    
      <option data-style-url-name="mla" value="MLA">
        MLA
      </option>
    
      <option data-style-url-name="nlm" value="NLM" selected="selected">
        NLM
      </option>
    
  </select>
</div>
  </div>
<div class="dots-loading-indicator citation-loading-indicator">
        <div class="dot dot-1"></div>
        <div class="dot dot-2"></div>
        <div class="dot dot-3"></div>
      </div></div>
  </div>
</div>

     <!-- ========== BEGIN FOOTER ========== -->
 <footer>
      <section class="icon-section">
        <div id="icon-section-header" class="icon-section_header">Follow NCBI</div>
        <div class="grid-container container">
          <div class="icon-section_container">
            <a class="footer-icon" id="footer_twitter" href="https://twitter.com/ncbi" aria-label="Twitter" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <defs>
                  <style>
                    .cls-11 {
                      fill: #737373;
                    }
                  </style>
                </defs>
                <title>Twitter</title>
                <path class="cls-11" d="M250.11,105.48c-7,3.14-13,3.25-19.27.14,8.12-4.86,8.49-8.27,11.43-17.46a78.8,78.8,0,0,1-25,9.55,39.35,39.35,0,0,0-67,35.85,111.6,111.6,0,0,1-81-41.08A39.37,39.37,0,0,0,81.47,145a39.08,39.08,0,0,1-17.8-4.92c0,.17,0,.33,0,.5a39.32,39.32,0,0,0,31.53,38.54,39.26,39.26,0,0,1-17.75.68,39.37,39.37,0,0,0,36.72,27.3A79.07,79.07,0,0,1,56,223.34,111.31,111.31,0,0,0,116.22,241c72.3,0,111.83-59.9,111.83-111.84,0-1.71,0-3.4-.1-5.09C235.62,118.54,244.84,113.37,250.11,105.48Z">
                </path>
              </svg></a>
            <a class="footer-icon" id="footer_facebook" href="https://www.facebook.com/ncbi.nlm" aria-label="Facebook" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <title>Facebook</title>
                <path class="cls-11" d="M210.5,115.12H171.74V97.82c0-8.14,5.39-10,9.19-10h27.14V52l-39.32-.12c-35.66,0-42.42,26.68-42.42,43.77v19.48H99.09v36.32h27.24v109h45.41v-109h35Z">
                </path>
              </svg></a>
            <a class="footer-icon" id="footer_linkedin" href="https://www.linkedin.com/company/ncbinlm" aria-label="LinkedIn"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <title>LinkedIn</title>
                <path class="cls-11" d="M101.64,243.37H57.79v-114h43.85Zm-22-131.54h-.26c-13.25,0-21.82-10.36-21.82-21.76,0-11.65,8.84-21.15,22.33-21.15S101.7,78.72,102,90.38C102,101.77,93.4,111.83,79.63,111.83Zm100.93,52.61A17.54,17.54,0,0,0,163,182v61.39H119.18s.51-105.23,0-114H163v13a54.33,54.33,0,0,1,34.54-12.66c26,0,44.39,18.8,44.39,55.29v58.35H198.1V182A17.54,17.54,0,0,0,180.56,164.44Z">
                </path>
              </svg></a>
            <a class="footer-icon" id="footer_github" href="https://github.com/ncbi" aria-label="GitHub"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <defs>
                  <style>
                    .cls-11,
                    .cls-12 {
                      fill: #737373;
                    }

                    .cls-11 {
                      fill-rule: evenodd;
                    }
                  </style>
                </defs>
                <title>GitHub</title>
                <path class="cls-11" d="M151.36,47.28a105.76,105.76,0,0,0-33.43,206.1c5.28,1,7.22-2.3,7.22-5.09,0-2.52-.09-10.85-.14-19.69-29.42,6.4-35.63-12.48-35.63-12.48-4.81-12.22-11.74-15.47-11.74-15.47-9.59-6.56.73-6.43.73-6.43,10.61.75,16.21,10.9,16.21,10.9,9.43,16.17,24.73,11.49,30.77,8.79,1-6.83,3.69-11.5,6.71-14.14C108.57,197.1,83.88,188,83.88,147.51a40.92,40.92,0,0,1,10.9-28.39c-1.1-2.66-4.72-13.42,1-28,0,0,8.88-2.84,29.09,10.84a100.26,100.26,0,0,1,53,0C198,88.3,206.9,91.14,206.9,91.14c5.76,14.56,2.14,25.32,1,28a40.87,40.87,0,0,1,10.89,28.39c0,40.62-24.74,49.56-48.29,52.18,3.79,3.28,7.17,9.71,7.17,19.58,0,14.15-.12,25.54-.12,29,0,2.82,1.9,6.11,7.26,5.07A105.76,105.76,0,0,0,151.36,47.28Z">
                </path>
                <path class="cls-12" d="M85.66,199.12c-.23.52-1.06.68-1.81.32s-1.2-1.06-.95-1.59,1.06-.69,1.82-.33,1.21,1.07.94,1.6Zm-1.3-1">
                </path>
                <path class="cls-12" d="M90,203.89c-.51.47-1.49.25-2.16-.49a1.61,1.61,0,0,1-.31-2.19c.52-.47,1.47-.25,2.17.49s.82,1.72.3,2.19Zm-1-1.08">
                </path>
                <path class="cls-12" d="M94.12,210c-.65.46-1.71,0-2.37-.91s-.64-2.07,0-2.52,1.7,0,2.36.89.65,2.08,0,2.54Zm0,0"></path>
                <path class="cls-12" d="M99.83,215.87c-.58.64-1.82.47-2.72-.41s-1.18-2.06-.6-2.7,1.83-.46,2.74.41,1.2,2.07.58,2.7Zm0,0">
                </path>
                <path class="cls-12" d="M107.71,219.29c-.26.82-1.45,1.2-2.64.85s-2-1.34-1.74-2.17,1.44-1.23,2.65-.85,2,1.32,1.73,2.17Zm0,0">
                </path>
                <path class="cls-12" d="M116.36,219.92c0,.87-1,1.59-2.24,1.61s-2.29-.68-2.3-1.54,1-1.59,2.26-1.61,2.28.67,2.28,1.54Zm0,0">
                </path>
                <path class="cls-12" d="M124.42,218.55c.15.85-.73,1.72-2,1.95s-2.37-.3-2.52-1.14.73-1.75,2-2,2.37.29,2.53,1.16Zm0,0"></path>
              </svg></a>
            <a class="footer-icon" id="footer_blog" href="https://ncbiinsights.ncbi.nlm.nih.gov/" aria-label="Blog">
              <svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><style>.cls-1{fill:#737373;}</style></defs><path class="cls-1" d="M14,30a4,4,0,1,1-4-4,4,4,0,0,1,4,4Zm11,3A19,19,0,0,0,7.05,15a1,1,0,0,0-1,1v3a1,1,0,0,0,.93,1A14,14,0,0,1,20,33.07,1,1,0,0,0,21,34h3a1,1,0,0,0,1-1Zm9,0A28,28,0,0,0,7,6,1,1,0,0,0,6,7v3a1,1,0,0,0,1,1A23,23,0,0,1,29,33a1,1,0,0,0,1,1h3A1,1,0,0,0,34,33Z"></path></svg>
            </a>
          </div>
        </div>
      </section>

      <section class="container-fluid bg-primary">
        <div class="container pt-5">
          <div class="row mt-3">
            <div class="col-lg-3 col-12">
              <p><a class="text-white" href="https://www.nlm.nih.gov/socialmedia/index.html">Connect with NLM</a></p>
              <ul class="list-inline social_media">
                <li class="list-inline-item"><a href="https://twitter.com/NLM_NIH" aria-label="Twitter" target="_blank" rel="noopener noreferrer" role="button" aria-expanded="false" aria-haspopup="true"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 249 249" style="enable-background:new 0 0 249 249;" xml:space="preserve">
                      <style type="text/css">
                        .st20 {
                          fill: #FFFFFF;
                        }

                        .st30 {
                          fill: none;
                          stroke: #FFFFFF;
                          stroke-width: 8;
                          stroke-miterlimit: 10;
                        }
                      </style>
                      <title>SM-Twitter</title>
                      <g>
                        <g>
                          <g>
                            <path class="st20" d="M192.9,88.1c-5,2.2-9.2,2.3-13.6,0.1c5.7-3.4,6-5.8,8.1-12.3c-5.4,3.2-11.4,5.5-17.6,6.7
                                                c-10.5-11.2-28.1-11.7-39.2-1.2c-7.2,6.8-10.2,16.9-8,26.5c-22.3-1.1-43.1-11.7-57.2-29C58,91.6,61.8,107.9,74,116
                                                c-4.4-0.1-8.7-1.3-12.6-3.4c0,0.1,0,0.2,0,0.4c0,13.2,9.3,24.6,22.3,27.2c-4.1,1.1-8.4,1.3-12.5,0.5c3.6,11.3,14,19,25.9,19.3
                                                c-11.6,9.1-26.4,13.2-41.1,11.5c12.7,8.1,27.4,12.5,42.5,12.5c51,0,78.9-42.2,78.9-78.9c0-1.2,0-2.4-0.1-3.6
                                                C182.7,97.4,189.2,93.7,192.9,88.1z"></path>
                          </g>
                        </g>
                        <circle class="st30" cx="124.4" cy="128.8" r="108.2"></circle>
                      </g>
                    </svg></a></li>
                <li class="list-inline-item"><a href="https://www.facebook.com/nationallibraryofmedicine" aria-label="Facebook" rel="noopener noreferrer" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">
                    <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 249 249" style="enable-background:new 0 0 249 249;" xml:space="preserve">
                      <style type="text/css">
                        .st10 {
                          fill: #FFFFFF;
                        }

                        .st110 {
                          fill: none;
                          stroke: #FFFFFF;
                          stroke-width: 8;
                          stroke-miterlimit: 10;
                        }
                      </style>
                      <title>SM-Facebook</title>
                      <g>
                        <g>
                          <path class="st10" d="M159,99.1h-24V88.4c0-5,3.3-6.2,5.7-6.2h16.8V60l-24.4-0.1c-22.1,0-26.2,16.5-26.2,27.1v12.1H90v22.5h16.9
                                                      v67.5H135v-67.5h21.7L159,99.1z"></path>
                        </g>
                      </g>
                      <circle class="st110" cx="123.6" cy="123.2" r="108.2"></circle>
                    </svg>
                  </a></li>
                <li class="list-inline-item"><a href="https://www.youtube.com/user/NLMNIH" aria-label="Youtube" target="_blank" rel="noopener noreferrer" role="button" aria-expanded="false" aria-haspopup="true"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 249 249" style="enable-background:new 0 0 249 249;" xml:space="preserve">
                      <title>SM-Youtube</title>
                      <style type="text/css">
                        .st4 {
                          fill: none;
                          stroke: #FFFFFF;
                          stroke-width: 8;
                          stroke-miterlimit: 10;
                        }

                        .st5 {
                          fill: #FFFFFF;
                        }
                      </style>
                      <circle class="st4" cx="124.2" cy="123.4" r="108.2"></circle>
                      <g transform="translate(0,-952.36218)">
                        <path class="st5" d="M88.4,1037.4c-10.4,0-18.7,8.3-18.7,18.7v40.1c0,10.4,8.3,18.7,18.7,18.7h72.1c10.4,0,18.7-8.3,18.7-18.7
                                            v-40.1c0-10.4-8.3-18.7-18.7-18.7H88.4z M115.2,1058.8l29.4,17.4l-29.4,17.4V1058.8z"></path>
                      </g>
                    </svg></a></li>
              </ul>
            </div>
            <div class="col-lg-3 col-12">
              <p class="address_footer text-white">National Library of Medicine<br>
                <a href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/@38.9959508,-77.101021,17z/data=!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb:0x19156f88b27635b8!8m2!3d38.9959508!4d-77.0988323" class="text-white" target="_blank" rel="noopener noreferrer" role="button" aria-expanded="false" aria-haspopup="true">8600 Rockville Pike<br>
                  Bethesda, MD 20894</a></p>
            </div>
            <div class="col-lg-3 col-12 centered-lg">
              <p><a href="https://www.nlm.nih.gov/web_policies.html" class="text-white">Web Policies</a><br>
                <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="text-white">FOIA</a><br>
                <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="text-white" id="vdp">HHS Vulnerability Disclosure</a></p>
            </div>
            <div class="col-lg-3 col-12 centered-lg">
              <p><a class="supportLink text-white" href="https://support.nlm.nih.gov/?pagename=pmc-frontend%3Apmc%3Aarticle%3A%2Farticles%2FPMC8914892%2F" data-pinger-pagename-param="true">Help</a><br>
                <a href="https://www.nlm.nih.gov/accessibility.html" class="text-white">Accessibility</a><br>
                <a href="https://www.nlm.nih.gov/careers/careers.html" class="text-white">Careers</a></p>
            </div>
          </div>
          <div class="row">
            <div class="col-lg-12 centered-lg">
              <nav class="bottom-links">
                <ul class="mt-3">
                  <li>
                    <a class="text-white" href="https://www.nlm.nih.gov/">NLM</a>
                  </li>
                  <li>
                    <a class="text-white" href="https://www.nih.gov/">NIH</a>
                  </li>
                  <li>
                    <a class="text-white" href="https://www.hhs.gov/">HHS</a>
                  </li>
                  <li>
                    <a class="text-white" href="https://www.usa.gov/">USA.gov</a>
                  </li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </section>
    </footer>
 <!-- ========== END FOOTER ========== -->
  <!-- javascript to inject NWDS meta tags. Note: value of nwds_version is updated by "npm version" command -->
 
  <script type="text/javascript">
    var nwds_version = "1.1.9-2";

    var meta_nwds_ver = document.createElement('meta');
    meta_nwds_ver.name = 'ncbi_nwds_ver';
    meta_nwds_ver.content = nwds_version;
    document.getElementsByTagName('head')[0].appendChild(meta_nwds_ver);

    var meta_nwds = document.createElement('meta');
    meta_nwds.name = 'ncbi_nwds';
    meta_nwds.content = 'yes';
    document.getElementsByTagName('head')[0].appendChild(meta_nwds);

	var alertsUrl = "/core/alerts/alerts.js";
	if (typeof ncbiBaseUrl !== 'undefined') {
		alertsUrl = ncbiBaseUrl + alertsUrl;
	}
  </script>



  
    <!-- JavaScript -->
    <script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.0f72d6a64937.js.download"></script>
  
  
    <script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/jquery-3.5.0.min.js.download" integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous">
    </script>
    <script>
        var fallbackJquery = "/pmc/static/base/js/jquery-3.5.0.min.js";
        window.jQuery || document.write("<script src=" + fallbackJquery + ">\x3C/script>")
    </script>
  

  <script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.a212a9fcf845.js.download"></script>
<script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.7999321d1aac.js.download"></script>
<script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.7ca436b2ea51.js.download"></script>
<script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.f8422046fbe0.js.download"></script>
<script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.ff40c7d85ff8.js.download"></script>
<script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.a6a84a0ad361.js.download"></script>

<script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/base.038d36e4e31104b40a19.js.download"></script>

    <script type="text/javascript">
        if(typeof jQuery !=='undefined') {
            jQuery.migrateMute = true;
        }
    </script>
    <script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/jquery-migrate-1.4.1.js.download"></script>
    <script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/jig.nojquery.min.js.download">//</script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/common.min.js.download">//</script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/NcbiTagServer.min.js.download">//</script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/crb.min.js.download">//</script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/jactions.min.js.download">//</script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/MathJax.js.download"></script><script type="text/javascript">window.name="mainwindow";</script>

    <script type="text/javascript">var exports = {};</script>
    <script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.340a3b9cce7f.js.download"></script><div class="fake-body-scroll"></div>
<script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/output.228f96f3298e.js.download"></script>
    <script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/article.b7dd20e527283dd68f45.js.download"></script>
    <script type="text/javascript">
        window.ncbi.pmc.articlePage.init({ pageURL: '/pmc/articles/PMC8914892/', citeCookieName: 'pmc-cf'});
    </script><div class="fake-body-scroll"></div><div class="fake-body-scroll"></div>


  
  
  <script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/pinger.js.download"> </script><div id="ZN_dikYWqsjiUWN0Q5"></div>


  
      
  



<div style="display: none; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic">External link. Please review our <a href="https://www.nlm.nih.gov/privacy.html">privacy policy</a>.</div><script type="text/javascript" id="_fed_an_ua_tag" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/Universal-Federated-Analytics-Min.js.download"></script><script type="text/javascript" src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/saved_resource"></script><script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/CoreModule.js.download" defer=""></script><script src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/FeedbackButtonModule.js.download" defer=""></script><style type="text/css">.QSIFeedbackButton div,.QSIFeedbackButton dl,.QSIFeedbackButton dt,.QSIFeedbackButton dd,.QSIFeedbackButton ul,.QSIFeedbackButton ol,.QSIFeedbackButton li,.QSIFeedbackButton h1,.QSIFeedbackButton h2,.QSIFeedbackButton h3,.QSIFeedbackButton h4,.QSIFeedbackButton h5,.QSIFeedbackButton h6,.QSIFeedbackButton span,.QSIFeedbackButton pre,.QSIFeedbackButton form,.QSIFeedbackButton fieldset,.QSIFeedbackButton textarea,.QSIFeedbackButton p,.QSIFeedbackButton blockquote,.QSIFeedbackButton tr,.QSIFeedbackButton th,.QSIFeedbackButton td{ margin: 0; padding: 0;background-color: transparent; border: 0; font-size: 12px; line-height: normal; vertical-align:baseline; box-shadow: none; }.QSIFeedbackButton img{ height: auto; width: auto; margin: 0; padding: 0 }.QSIFeedbackButton ul,.QSIFeedbackButton ol{ margin: 12px 0; padding-left: 40px; }.QSIFeedbackButton ul li{ list-style-type: disc; }.QSIFeedbackButton ol li{ list-style-type: decimal; }.QSIFeedbackButton .scrollable{ -webkit-overflow-scrolling: touch; }.QSIFeedbackButton table{ border-collapse: collapse; border-spacing: 0; }.QSIFeedbackButton table td{ padding: 2px; }.QSIFeedbackButton iframe{ max-height: none; }.QSIFeedbackButton *{ box-sizing: content-box; }</style><div class="QSIFeedbackButton" style="position: fixed; visibility: hidden; inset: 0px; display: flex; flex-direction: column; justify-content: flex-end; align-items: flex-start; margin: 0px; padding: 0px; z-index: 2000000000;"><button role="button" aria-label="Tell us what you think!" id="QSIFeedbackButton-btn" style="position: fixed; visibility: visible; cursor: pointer; border: none; background-color: transparent; padding: 0px; margin: 0px; bottom: 84px; right: -1px; width: 52px;"><img src="./A Review of Recent Developments in Driver Drowsiness Detection Systems - PMC_files/Feedback+Button_vt.png" alt="Tell us what you think!" style="max-width: 110px; max-height: 110px; display: block;"></button></div><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; min-width: 0px; max-width: none; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_Main, sans-serif;"></div></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration><grammarly-citation-builder data-grammarly-shadow-root="true" class="dnXmp"></grammarly-citation-builder></html>